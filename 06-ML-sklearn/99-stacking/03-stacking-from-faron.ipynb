{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Faron\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = \"id\"\n",
    "TARGET = \"loss\"\n",
    "NFOLDS = 4\n",
    "SEED = 0\n",
    "NROWS = None\n",
    "DATA_DIR = \"./data/Allstate-Claims-Severity好事达保险索赔严重性\"\n",
    "\n",
    "TRAIN_FILE = \"{0}/train.csv\".format(DATA_DIR)\n",
    "TEST_FILE = \"{0}/test.csv\".format(DATA_DIR)\n",
    "SUBMISSION_FILE = \"{0}/sample_submission.csv\".format(DATA_DIR)\n",
    "\n",
    "train = pd.read_csv(TRAIN_FILE, nrows=NROWS)\n",
    "test = pd.read_csv(TEST_FILE, nrows=NROWS)\n",
    "print(train[TARGET])\n",
    "y_train = train[TARGET].ravel()\n",
    "print(y_train)\n",
    "train.drop([ID, TARGET], axis=1, inplace=True)\n",
    "test.drop([ID], axis=1, inplace=True)\n",
    "\n",
    "print(\"{}{}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test \n",
    "print(train[\"cat1\"])\n",
    "print(type(pd.factorize(train[\"cat1\"], sort=True)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "print(ntrain, ntest)\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "features = train.columns\n",
    "cats = [feat for feat in features if 'cat' in feat]\n",
    "for feat in cats:\n",
    "    train_test[feat] = pd.factorize(train_test[feat], sort=True)[0]\n",
    "\n",
    "print(train_test.head())\n",
    "\n",
    "x_train = np.array(train_test.iloc[:ntrain,:])\n",
    "x_test = np.array(train_test.iloc[ntrain:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=100)\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "#     'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 7,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'mae',\n",
    "    'nrounds': 350\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, np.log(y_train))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.exp(self.clf.predict(x))\n",
    "\n",
    "\n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=np.log(y_train))\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.exp(self.gbdt.predict(xgb.DMatrix(x)))\n",
    "\n",
    "\n",
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "et = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "\n",
    "xg_oof_train, xg_oof_test = get_oof(xg)\n",
    "et_oof_train, et_oof_test = get_oof(et)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf)\n",
    "\n",
    "print(\"XG-CV: {}\".format(mean_absolute_error(y_train, xg_oof_train)))\n",
    "print(\"ET-CV: {}\".format(mean_absolute_error(y_train, et_oof_train)))\n",
    "print(\"RF-CV: {}\".format(mean_absolute_error(y_train, rf_oof_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xg_oof_train.shape)\n",
    "print(et_oof_train.shape)\n",
    "print(rf_oof_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train), axis=1)\n",
    "x_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test), axis=1)\n",
    "\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost 自带的读取格式\n",
    "dtrain = xgb.DMatrix(x_train, label=np.log(y_train))\n",
    "dtest = xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.8,\n",
    "#     'silent': 1,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 4,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'mae',\n",
    "}\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y), np.exp(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=500, nfold=4, seed=SEED, stratified=False,\n",
    "             early_stopping_rounds=25, verbose_eval=10, show_stdv=True, feval=xg_eval_mae, maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "\n",
    "print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt = xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "submission = pd.read_csv(SUBMISSION_FILE)\n",
    "submission.iloc[:, 1] = np.exp(gbdt.predict(dtest))\n",
    "submission.to_csv('./data/Allstate-Claims-Severity好事达保险索赔严重性/xgstacker_starter_v2.sub.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
