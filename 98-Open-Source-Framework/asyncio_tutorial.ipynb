{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结合多进程和 Asyncio 以提高性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_to_num(final_num: int) -> int:\n",
    "    start = time.monotonic()\n",
    "\n",
    "    result = 0\n",
    "    for i in range(0, final_num+1, 1):\n",
    "        result += i\n",
    "\n",
    "    print(f\"The method with {final_num} completed in {time.monotonic() - start:.2f} second(s).\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "def main():\n",
    "    # We initialize the two processes with two parameters, from largest to smallest\n",
    "    process_a = Process(target=sum_to_num, args=(200_000_000,))\n",
    "    process_b = Process(target=sum_to_num, args=(50_000_000,))\n",
    "\n",
    "    # And then let them start executing\n",
    "    process_a.start()\n",
    "    process_b.start()\n",
    "\n",
    "    # Note that the join method is blocking and gets results sequentially\n",
    "    start_a = time.monotonic()\n",
    "    process_a.join()\n",
    "    print(f\"Process_a completed in {time.monotonic() - start_a:.2f} seconds\")\n",
    "\n",
    "    # Because when we wait process_a for join. The process_b has joined already.\n",
    "    # so the time counter is 0 seconds.\n",
    "    start_b = time.monotonic()\n",
    "    process_b.join()\n",
    "    print(f\"Process_b completed in {time.monotonic() - start_b:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建并启动多个进程，调用每个进程的start和join方法。但是，这里存在一些问题：\n",
    "\n",
    "1. join 方法不能返回任务执行的结果。\n",
    "2. join 方法阻塞主进程并按顺序执行它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进程池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "def main():\n",
    "    with Pool() as pool:\n",
    "        result_a = pool.apply(sum_to_num, args=(200_000_000,))\n",
    "        result_b = pool.apply(sum_to_num, args=(50_000_000,))\n",
    "\n",
    "        print(f\"sum_to_num with 200_000_000 got a result of {result_a}.\")\n",
    "        print(f\"sum_to_num with 50_000_000 got a result of {result_b}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pool 的 apply 方法是同步的，这意味着您必须等待之前的 apply 任务完成才能开始执行下一个 apply 任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 apply_async 方法异步创建任务。但是同样，您需要使用 get 方法来阻塞地获取结果。它让我们回到 join 方法的问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with Pool() as pool:\n",
    "        result_a = pool.apply_async(sum_to_num, args=(200_000_000,))\n",
    "        result_b = pool.apply_async(sum_to_num, args=(50_000_000,))\n",
    "\n",
    "        print(f\"sum_to_num with 200_000_000 got a result of {result_a.get()}.\")\n",
    "        print(f\"sum_to_num with 50_000_000 got a result of {result_b.get()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProcessPoolExecutor\n",
    "那么，使用 concurrent.futures.ProcesssPoolExecutor 来执行我们的 CPU 绑定任务呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent .futures import ProcessPoolExecutor\n",
    "def main():\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        numbers = [200_000_000, 50_000_000]\n",
    "        for result in executor.map(sum_to_num, numbers):\n",
    "            print(f\"sum_to_num got a result which is {result}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一切看起来都很棒，并且就像 asyncio.as_completed 一样被调用。但是它们仍按启动顺序获取。可以使用 asyncio 来处理 IO-bound 任务，它的 run_in_executor 方法可以像 asyncio 一样调用多进程任务。不仅统一了并发和并行的API，还解决了我们上面遇到的各种问题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## asyncio 的 run_in_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    loop = asyncio.get_running_loop()\n",
    "    tasks = []\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        for number in [200_000_000, 50_000_000]:\n",
    "            tasks.append(loop.run_in_executor(executor, sum_to_num, number))\n",
    "        \n",
    "        # Or we can just use the method asyncio.gather(*tasks)\n",
    "        for done in asyncio.as_completed(tasks):\n",
    "            result = await done\n",
    "            print(f\"sum_to_num got a result which is {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
