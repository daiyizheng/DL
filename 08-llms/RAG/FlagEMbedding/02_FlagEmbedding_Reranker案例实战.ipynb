{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reranker应用\n",
    "## FlagEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "MODEL_PATH = \"/slurm/resources/weights/huggingface/BAAI/bge-reranker-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.625, 6.8515625]\n"
     ]
    }
   ],
   "source": [
    "reranker = FlagReranker(MODEL_PATH, use_fp16=True)\n",
    "\n",
    "samples = [['什么是长城？', '你好'], \n",
    "           ['什么是长城？', '长城，又称万里长城，是中国古代的军事防御工程，是一道位于中国北部的长城。']]\n",
    "\n",
    "scores = reranker.compute_score(samples)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-7.6202,  6.8509])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(samples, \n",
    "                       padding=True, \n",
    "                       truncation=True, \n",
    "                       return_tensors=\"pt\", \n",
    "                       max_length=512)\n",
    "    \n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1,).float()\n",
    "    \n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranker微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个重排序器基于[xlm-roberta-base](https://huggingface.co/FacebookAI/xlm-roberta-base)模型进行初始化，并使用了多个多语言数据集进行训练，主要包括中文、英文和其他语言的文本对。  \n",
    "\n",
    "- 训练数据  \n",
    "-- 中文数据集：总计788,491个文本对，来源于T2ranking、MMmarco、dulreader、Cmedqa-v2和nli-zh。  \n",
    "-- 英文数据集：总计933,090个文本对，来源于msmarco、nq、hotpotqa和NLI。  \n",
    "-- 其他语言数据集：总计97,458个文本对，涵盖阿拉伯语、孟加拉语、英语、芬兰语、印尼语、日语、韩语、俄语、斯瓦希里语、泰卢固语、泰语，数据来源于Mr.TyDi。   \n",
    "\n",
    "- 跨语言检索数据集   \n",
    "-- 为了增强跨语言检索能力，构建了两个基于MMarco的跨语言检索数据集：   \n",
    "-- 从英文查询检索中文段落：随机抽样100,000个英文查询。  \n",
    "-- 从中文查询检索英文段落：随机抽样100,000个中文查询。   \n",
    "数据集发布于[Shitao/bge-reranker-data](https://huggingface.co/datasets/Shitao/bge-reranker-data/tree/main/data_v1)。   \n",
    " \n",
    "- 模型性能  \n",
    "-- 主要支持语言：中文和英文。   \n",
    "-- 低资源语言性能：对于其他低资源语言，可能会出现性能下降的情况。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  微调数据格式  \n",
    "\n",
    "与Embedding微调数据格式一致（难负例采样）  \n",
    "\n",
    "```shell\n",
    "{\"query\": \"五个女人穿着人字拖沿着海滩走。\", \n",
    " \"pos\": [\"一些穿着人字拖的女性正在海滩上行走\"], \n",
    " \"neg\": [\"那个男人在谈论夏威夷。\", \"一名运动员正在参加1500米游泳比赛。\", \"战斗结束了。\", \"一个男人在山上滑雪。\", \"在公立学校，资金是我们的一个问题。\", \"我十八岁时面临一个严重的问题。\", \"一个穿着背心的男人坐在车里。\", \"乔治·布什告诉共和党人，他绝不会让他们考虑这个愚蠢的想法，违背了他顶级顾问的建议。\"]}\n",
    "\n",
    "{\"query\": \"一个女人站在高崖上单腿站立，俯瞰一条河流。\", \n",
    " \"pos\": [\"一个女人站在悬崖上。\"], \n",
    " \"neg\": [\"一些穿着人字拖的女性正在海滩上行走\", \"那个男人在谈论夏威夷。\", \"我十八岁时面临一个严重的问题。\", \"他们因为退休而不是因为贷款而卖掉了他们的家。\", \"两个男性正在表演。\", \"她不会去法院清除自己的记录。\", \"孩子穿着黑色。\", \"有人密谋攻击Conrad，击中他的头部。\"]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练\n",
    "\n",
    "**1. 多块GPU的情况**  \n",
    "\n",
    "```shell\n",
    "torchrun --nproc_per_node {number of gpus} \\\n",
    "-m FlagEmbedding.reranker.run \\\n",
    "--output_dir /root/autodl-tmp/flagembedding/output_reranker_finetuned_model \\\n",
    "--model_name_or_path /root/autodl-tmp/models/bce-reranker-base_v1 \\ # BAAI/bge-reranker-base\n",
    "--train_data /root/autodl-tmp/samples/dataset_minedHN.jsonl \\\n",
    "--learning_rate 6e-5 \\\n",
    "--fp16 \\\n",
    "--num_train_epochs 5 \\\n",
    "--per_device_train_batch_size 1 \\\n",
    "--gradient_accumulation_steps 4 \\\n",
    "--dataloader_drop_last True \\\n",
    "--train_group_size 16 \\\n",
    "--max_len 512 \\\n",
    "--weight_decay 0.01 \\\n",
    "--logging_steps 10 \n",
    "```  \n",
    "\n",
    "\n",
    "**2. 单块GPU的情况**  \n",
    "\n",
    "```shell\n",
    "python -m FlagEmbedding.reranker.run \\\n",
    "--output_dir /root/autodl-tmp/flagembedding/output_reranker_finetuned_model \\\n",
    "--model_name_or_path /root/autodl-tmp/models/bce-reranker-base_v1 \\\n",
    "--train_data /root/autodl-tmp/samples/dataset_minedHN.jsonl \\\n",
    "--learning_rate 6e-5 \\\n",
    "--fp16 \\\n",
    "--num_train_epochs 5 \\\n",
    "--per_device_train_batch_size 1 \\\n",
    "--gradient_accumulation_steps 4 \\\n",
    "--dataloader_drop_last True \\\n",
    "--train_group_size 16 \\\n",
    "--max_len 512 \\\n",
    "--weight_decay 0.01 \\\n",
    "--logging_steps 10 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里以“单块GPU的情况”为例，创建一个执行shell脚本：run_reranker_fintune.sh，将命令保存进去后执行脚本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 LM-Cocktail 进行模型融合【可选操作】\n",
    "\n",
    "在特定任务上微调基础模型（base bge model）可以提高其在目标任务上的性能，但可能会严重降低模型在目标领域之外的一般能力，例如在c-mteb任务上的性能下降。通过合并微调模型和基础模型，LM-Cocktail技术能够在提高下游任务性能的同时，保持在其他无关任务上的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LM_Cocktail import mix_models, mix_models_with_data\n",
    "model = mix_models(\n",
    "    model_names_or_paths=[\"/root/autodl-tmp/models/bce-reranker-base_v1\", \"/root/autodl-tmp/flagembedding/output_reranker_finetuned_model\"],\n",
    "    model_type=\"reranker\",\n",
    "    weights=[0.5, 0.5],\n",
    "    output_path=\"/root/autodl-tmp/flagembedding/output_reranker_merged_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载微调后的模型进行测试\n",
    "### 微调后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "MODEL_PATH = \"/root/autodl-tmp/flagembedding/output_reranker_finetuned_model\"\n",
    "\n",
    "reranker = FlagReranker(MODEL_PATH, use_fp16=True)\n",
    "\n",
    "samples = [['什么是长城？', '你好'], \n",
    "           ['什么是长城？', '长城，又称万里长城，是中国古代的军事防御工程，是一道位于中国北部的长城。']]\n",
    "\n",
    "scores = reranker.compute_score(samples)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  融合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "MODEL_PATH = \"/root/autodl-tmp/flagembedding/output_reranker_merged_model\"\n",
    "\n",
    "reranker = FlagReranker(MODEL_PATH, use_fp16=True)\n",
    "\n",
    "samples = [['什么是长城？', '你好'], \n",
    "           ['什么是长城？', '长城，又称万里长城，是中国古代的军事防御工程，是一道位于中国北部的长城。']]\n",
    "\n",
    "scores = reranker.compute_score(samples)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reranker模型评估\n",
    "\n",
    "安装 C-MTEB（Chinese Massive Text Embedding Benchmark）:  \n",
    "\n",
    "pip install -U C_MTEB  \n",
    "\n",
    "或   \n",
    "\n",
    "git clone https://github.com/FlagOpen/FlagEmbedding.git  \n",
    "cd FlagEmbedding/C_MTEB  \n",
    "pip install -e .  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对 reranker 进行评估**  \n",
    "\n",
    "```shell\n",
    "python eval_cross_encoder.py --model_name_or_path /root/autodl-tmp/models/bce-reranker-base_v1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
