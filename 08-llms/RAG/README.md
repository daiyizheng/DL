# RGA
RAG提供了一种创新的解决方案，以应对大语言模型（LLM）在处理复杂查询、维持最新的信息以及提高回答的准确性方面遇到的挑战。RAG通过结合传统的生成式语言模型和动态检索机制，能够实时从广泛的外部知识库中检索信息，以此来增强模型的生成输出。这种方法不仅提高了生成内容的相关性和准确度，还扩展了模型的知识范围，使其能够覆盖训练数据之外的信息。

RAG如何通过外部知识增强来克服这些挑战：
- (1) 提升信息的丰富性和准确性
  - 动态知识库接入：RAG通过实时检索最相关的外部文档，引入了最新、最相关的信息作为生成过程的一部分，从而显著提高了回答的准确性和详细程度。
  - 上下文感知生成：结合检索到的文档和原始查询，RAG能够生成更加丰富和具体的内容，尤其是在处理复杂问题或需要详细解释的场景中。
- (2) 扩展知识覆盖范围
  - 覆盖训练数据之外的信息：传统LLM可能难以处理未在训练集中直接出现的信息。RAG通过检索来动态地引入外部知识，从而有效地扩展了模型的知识覆盖范围，包括最新的事件、专业知识或者少⻅的事实。
- (3) 增强模型的适应性和灵活性
  - 模型更新与维护：RAG降低了对模型频繁更新的需求，因为它可以通过查询更新的外部知识库来获取新信息。这样不仅减少了持续训练的成本，也使模型能够更快适应新的信息和变化。
  - 多领域适用性：通过访问专业领域的知识库，RAG可以被应用于多个领域，如医疗、法律、科技等，而无需为每个领域单独训练模型。
- (4) 解决伦理和偏⻅问题
  - 可追溯的信息源：RAG的生成内容可以追溯到具体的外部文档，这为验证生成内容的准确性和公正性提供了可能，有助于识别和减少偏⻅和不准确的信息。



## 相关向量数据库
### weaviate
https://weaviate.io/developers/weaviate/manage-data/create
- [01-intsall](08-llms/RAG/DB/weaviate_/01-intsall.ipynb)