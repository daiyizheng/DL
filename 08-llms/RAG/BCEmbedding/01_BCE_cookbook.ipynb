{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 基于 BCEmbedding\n",
    "## 1.1 调用EmbeddingModel计算句向量表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. BCEmbedding 项目简介\n",
    "- 项目名称：BCEmbedding（双语和跨语言嵌入）\n",
    "- 开发者：网易有道\n",
    "- 组成部分：\n",
    "  - EmbeddingModel（嵌入模型）：专注于生成语义向量，关键应用于语义搜索和问答系统。\n",
    "  - RerankerModel（重排模型）：优化搜索结果的排序和排名任务。\n",
    "- 特点：擅⻓双语和跨语言能力，尤其是在中英文之间，有效桥接语言差距。\n",
    "- 成就：在MTEB的语义表示评估中取得高性能。在LlamaIndex的RAG评估中设立了新的基准。\n",
    "  \n",
    "```shell\n",
    "Github: https://github.com/netease-youdao/BCEmbedding\n",
    "```\n",
    "\n",
    "## 环境配置\n",
    "```\n",
    "conda create -n bce python=3.10\n",
    "conda init bash && source /root/.bashrc\n",
    "conda activate bce\n",
    "conda install ipykernel\n",
    "ipython kernel install --user--name=bce\n",
    "\n",
    "```\n",
    "\n",
    "## 安装依赖包\n",
    "```shell\n",
    "pip install unstructured-inference\n",
    "pip install opencv-python\n",
    "pip install pdfminer.six\n",
    "pip show pdfminer\n",
    "pip install pdf2image\n",
    "pip install unstructured\n",
    "pip install langchain-community\n",
    "pip install langchain\n",
    "pip install langchain-core\n",
    "pip install pikepdf\n",
    "pip install llama-index-embeddings-huggingface\n",
    "pip install llama-index\n",
    "pip install llama-index-llms-huggingface\n",
    "pip install accelerate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from BCEmbedding import EmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['今天天气不错哟', '明天一起去徒步']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "07/25/2024 09:56:29 - [INFO] -BCEmbedding.models.EmbeddingModel->>>    Loading from `/slurm/resources/weights/huggingface/maidalun1020/bce-embedding-base_v1`.\n",
      "07/25/2024 09:56:30 - [INFO] -BCEmbedding.models.EmbeddingModel->>>    Execute device: cuda;\t gpu num: 1;\t use fp16: False;\t embedding pooling type: cls;\t trust remote code: False\n"
     ]
    }
   ],
   "source": [
    "model = EmbeddingModel(model_name_or_path=\"/slurm/resources/weights/huggingface/maidalun1020/bce-embedding-base_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 调用RerankerModel计算句子对的语义相关分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/25/2024 09:56:35 - [INFO] -BCEmbedding.models.RerankerModel->>>    Loading from `/slurm/resources/weights/huggingface/maidalun1020/bce-reranker-base_v1/`.\n",
      "07/25/2024 09:56:35 - [INFO] -BCEmbedding.models.RerankerModel->>>    Execute device: cuda;\t gpu num: 1;\t use fp16: False\n",
      "Calculate scores: 100%|██████████| 1/1 [00:00<00:00, 106.65it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rerank_passages': ['一个女人站在悬崖上。', '一个孩子在她的卧室里读书。'], 'rerank_scores': [0.7433750033378601, 0.38531556725502014], 'rerank_ids': [0, 1]}\n"
     ]
    }
   ],
   "source": [
    "from BCEmbedding import RerankerModel\n",
    "\n",
    "query = \"一个女人站在高崖上单腿站立，俯瞰一条河流。\"\n",
    "\n",
    "passages = [\"一个女人站在悬崖上。\",\n",
    "            \"一个孩子在她的卧室里读书。\"]\n",
    "\n",
    "# 构造语句对\n",
    "sentence_pairs = [[query, passage] for passage in passages]\n",
    "\n",
    "# 初始化 reranker 模型\n",
    "rerank_model = RerankerModel(model_name_or_path=\"/slurm/resources/weights/huggingface/maidalun1020/bce-reranker-base_v1/\")\n",
    "\n",
    "# （1）计算语句对的相似性得分\n",
    "scores = rerank_model.compute_score(sentence_pairs)\n",
    "\n",
    "# (2) 对passages排序\n",
    "rerank_results = rerank_model.rerank(query, passages)\n",
    "\n",
    "print(rerank_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 transformers\n",
    "### 调用EmbeddingModel计算句向量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "passages = [\"一个女人站在悬崖上。\",\n",
    "            \"一个孩子在她的卧室里读书。\"]\n",
    "\n",
    "# 初始化模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/slurm/resources/weights/huggingface/maidalun1020/bce-embedding-base_v1\")\n",
    "model = AutoModel.from_pretrained(\"/slurm/resources/weights/huggingface/maidalun1020/bce-embedding-base_v1\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# 基于tokenizer进行分词\n",
    "encoded_inputs = tokenizer(passages, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 获取embedding\n",
    "outputs = model(**encoded_inputs, return_dict=True)\n",
    "\n",
    "embeddings = outputs.last_hidden_state[:, 0] # cls\n",
    "\n",
    "embeddings = embeddings / embeddings.norm(dim=1, keepdim=True) # 归一化\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用RerankerModel计算句子对的语义相关分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1699, -0.4503], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([0.7631, 0.3893], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 初始化模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/slurm/resources/weights/huggingface/maidalun1020/bce-reranker-base_v1/\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/slurm/resources/weights/huggingface/maidalun1020/bce-reranker-base_v1/\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "query = \"一个女人站在高崖上单腿站立，俯瞰一条河流。\"\n",
    "passages = [\"一个女人站在悬崖上。\",\n",
    "            \"一个孩子在她的卧室里读书。\"]\n",
    "# 构造语句对\n",
    "sentence_pairs = [[query, passage] for passage in passages]\n",
    "\n",
    "# 获取分词后的输入\n",
    "encoded_inputs = tokenizer(sentence_pairs, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# ① 通过模型计算每个语句对的分类得分（logits）,return_dict=True指示模型返回一个包含各种输出的字典，\n",
    "# ② .logits提取出了分类得分，logits是模型的原始输出，对于序列分类任务，这是一个形状为(batch_size, num_labels)的张量，其中每个条目表示对应类别的得分。\n",
    "# ③ .view(-1,): 这个操作改变logits张量的形状。-1意味着该维度的大小会自动计算，使得结果是一个一维张量。\n",
    "scores = model(**encoded_inputs, return_dict=True).logits.view(-1,).float()\n",
    "print(scores)\n",
    "# ④ 使用sigmoid函数将每个得分转换为一个介于0和1之间的值，可以解释为概率。\n",
    "#    对于二分类任务，sigmoid函数非常适合，因为它能够将任何实数映射到0和1之间，从而表示模型对每个类别的置信度。\n",
    "scores = torch.sigmoid(scores)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 sentence_transformers\n",
    "### 调用EmbeddingModel计算句向量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/25/2024 10:10:40 - [INFO] -datasets->>>    PyTorch version 2.2.0 available.\n",
      "07/25/2024 10:10:41 - [INFO] -sentence_transformers.SentenceTransformer->>>    Use pytorch device_name: cuda\n",
      "07/25/2024 10:10:41 - [INFO] -sentence_transformers.SentenceTransformer->>>    Load pretrained SentenceTransformer: /slurm/resources/weights/huggingface/maidalun1020/bce-embedding-base_v1/\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "passages = [\"一个女人站在悬崖上。\",\n",
    "            \"一个孩子在她的卧室里读书。\"]\n",
    "\n",
    "model = SentenceTransformer(\"/slurm/resources/weights/huggingface/maidalun1020/bce-embedding-base_v1/\")\n",
    "\n",
    "embeddings = model.encode(passages, normalize_embeddings=True)\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用RerankerModel计算句子对的语义相关分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/25/2024 10:13:44 - [INFO] -sentence_transformers.cross_encoder.CrossEncoder->>>    Use pytorch device: cuda\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76313466 0.3892789 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"/slurm/resources/weights/huggingface/maidalun1020/bce-reranker-base_v1/\", max_length=512)\n",
    "\n",
    "\n",
    "query = \"一个女人站在高崖上单腿站立，俯瞰一条河流。\"\n",
    "passages = [\"一个女人站在悬崖上。\",\n",
    "            \"一个孩子在她的卧室里读书。\"]\n",
    "# 构造语句对\n",
    "sentence_pairs = [[query, passage] for passage in passages]\n",
    "\n",
    "scores = model.predict(sentence_pairs)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
