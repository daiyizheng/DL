{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from BCEmbedding.tools.langchain import BCERerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "# FAISS是一个高效的相似性搜索库，常用于大规模向量搜索。\n",
    "from langchain_community.vectorstores.faiss import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain.retrievers import ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化embedding模型\n",
    "\n",
    "embedding_model_name = \"/slurm/resources/weights/huggingface/maidalun1020/bce-embedding-base_v1\"\n",
    "embedding_model_kwargs = {\"device\": \"cuda:0\"}\n",
    "embedding_encode_kwargs = {\"batch_size\": 32,\n",
    "                           \"normalize_embeddings\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "07/25/2024 10:27:38 - [INFO] -datasets->>>    PyTorch version 2.2.0 available.\n",
      "/slurm/home/admin/.conda/envs/dl/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "07/25/2024 10:27:38 - [INFO] -sentence_transformers.SentenceTransformer->>>    Load pretrained SentenceTransformer: /slurm/resources/weights/huggingface/maidalun1020/bce-embedding-base_v1\n"
     ]
    }
   ],
   "source": [
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name = embedding_model_name,\n",
    "    model_kwargs = embedding_model_kwargs,\n",
    "    encode_kwargs = embedding_encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/25/2024 10:28:02 - [INFO] -BCEmbedding.models.RerankerModel->>>    Loading from `/slurm/resources/weights/huggingface/maidalun1020/bce-reranker-base_v1/`.\n",
      "07/25/2024 10:28:02 - [INFO] -BCEmbedding.models.RerankerModel->>>    Execute device: cuda:0;\t gpu num: 1;\t use fp16: False\n"
     ]
    }
   ],
   "source": [
    "# 初始化rereanker模型\n",
    "\n",
    "reranker_args = {\n",
    "    \"model\": \"/slurm/resources/weights/huggingface/maidalun1020/bce-reranker-base_v1/\",\n",
    "    \"top_n\": 5,\n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "reranker = BCERerank(**reranker_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/25/2024 10:33:23 - [INFO] -pikepdf._core->>>    pikepdf C++ to Python logger bridge initialized\n"
     ]
    }
   ],
   "source": [
    "# 文档数据预处理\n",
    "\n",
    "documents = UnstructuredPDFLoader(\"./RAG-编年史.pdf\").load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,\n",
    "                                               chunk_overlap=200)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': './RAG-编年史.pdf'}, page_content='唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n1. 论⽂名称：the chronicles of rag: the retriever, the chunk and the generator\\n\\nRAG编年史：检索器，⽂本块和⽣成器\\n\\nAbstract\\n\\n背景：\\n\\n唐国梁Tommy\\n\\nRAG是⼀种使⼤型语⾔模型（LLMs）访问外部数据的流⾏范式。\\n\\n唐国梁Tommy\\n\\nRAG的实施⾯临诸多挑战，包括检索模型的有效整合、表示学习、数据多样性、计算效率优化等。\\n\\n唐国梁Tommy\\n\\n⽬的：\\n\\n提出对巴⻄葡萄⽛语实施、优化和评估RAG的良好实践。\\n\\n通过简单的流⽔线进⾏推理和实验，回答有关哈利·波特书籍的问题。\\n\\n⽅法：\\n\\n使⽤OpenAI的gpt-4、gpt-4-1106-preview、gpt-3.5-turbo-1106和Google的Gemini Pro⽣成答案。\\n\\n唐国梁Tommy\\n\\n重点提升检索器的质量。\\n\\n唐国梁Tommy\\n\\n结果：\\n\\n唐国梁Tommy\\n\\n⽅法使得MRR@10相⽐基线提⾼了35.4%。\\n\\n经过优化，性能进⼀步提升了2.4%。\\n\\n结论：\\n\\nRAG架构经过建议的增强后，相对得分从57.88%提⾼到了98.61%的最⼤值。\\n\\n唐国梁Tommy\\n\\n1 Introduction\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n背景：\\n\\nLLMs在AI应⽤中取得显著成绩，尤其在翻译、总结等任务中。\\n\\n需要基于最新信息和外部数据提供答案的问题上存在挑战。\\n\\n挑战：\\n\\n实现RAG技术⾯临新挑战，包括发展可靠检索器和确保检索⽂本相关性。\\n\\n唐国梁Tommy\\n\\nRAG领域发展：\\n\\n唐国梁Tommy\\n\\nRAG研究快速扩张，新论⽂介绍了不同的实现⽅式和技术改进。\\n\\n这些发展给AI实践者评估性能和适⽤性带来挑战。\\n\\n研究内容：\\n\\n针对巴⻄葡萄⽛语的RAG实施的全⾯实验。\\n\\n评估不同检索技术，探讨分块策略优化检索信息的整合。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n分析⽂档位置对⽣成内容质量的影响。\\n\\n⽐较不同LLMs在整合检索信息产⽣回应的能⼒。\\n\\n主要贡献：\\n\\n1. 数据集准备⽅法，量化RAG系统不同步骤的质量。\\n\\n2. 最⼤相对分数度量，量化⽅法与理想RAG系统间的差距。\\n\\n3. 开发RAG系统时的最佳实践和优化讨论。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n2 数据预处理\\n\\n1. 数据集选择：选⽤的数据集是巴⻄葡萄⽛语版本的第⼀本《哈利·波特》书籍。这个选择的原因是该书籍⼴为\\n\\n⼈知，且Gemini Pro和OpenAI模型都能就此主题回答⼀般性问题。\\n\\n2. 数据处理：使⽤标准的ChatGPT分词器c110k_base，发现总共⼤约有140,000个词标。这允许创建包含整本\\n\\n书的提示语。\\n\\n3. 数据集构建：随后，开发了⼀个包含问题和相应答案的数据集，问题和答案都是由gpt-4模型⽣成，并基于⼀\\n\\n唐国梁Tommy\\n\\n个参考⽂本块。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n3 如何评估\\n\\n1. 问题：\\n\\n传统评价指标如BLEU和ROUGE可能⽆法准确反映⽂本之间的上下⽂相似性。\\n\\n2. ⽅法：\\n\\n使⽤gpt-4提供基于特定提示的评分。\\n\\n唐国梁Tommy\\n\\n开发了⼀个五级评分系统来⽐较⽂本。\\n\\n唐国梁Tommy\\n\\n3. 评分标准：\\n\\n1分：答案与参考⽆关。\\n\\n3分：答案略有相关性，但不⼀致。')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "1. 论⽂名称：the chronicles of rag: the retriever, the chunk and the generator\n",
      "\n",
      "RAG编年史：检索器，⽂本块和⽣成器\n",
      "\n",
      "Abstract\n",
      "\n",
      "背景：\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "RAG是⼀种使⼤型语⾔模型（LLMs）访问外部数据的流⾏范式。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "RAG的实施⾯临诸多挑战，包括检索模型的有效整合、表示学习、数据多样性、计算效率优化等。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "⽬的：\n",
      "\n",
      "提出对巴⻄葡萄⽛语实施、优化和评估RAG的良好实践。\n",
      "\n",
      "通过简单的流⽔线进⾏推理和实验，回答有关哈利·波特书籍的问题。\n",
      "\n",
      "⽅法：\n",
      "\n",
      "使⽤OpenAI的gpt-4、gpt-4-1106-preview、gpt-3.5-turbo-1106和Google的Gemini Pro⽣成答案。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "重点提升检索器的质量。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "结果：\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "⽅法使得MRR@10相⽐基线提⾼了35.4%。\n",
      "\n",
      "经过优化，性能进⼀步提升了2.4%。\n",
      "\n",
      "结论：\n",
      "\n",
      "RAG架构经过建议的增强后，相对得分从57.88%提⾼到了98.61%的最⼤值。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "1 Introduction\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "背景：\n",
      "\n",
      "LLMs在AI应⽤中取得显著成绩，尤其在翻译、总结等任务中。\n",
      "\n",
      "需要基于最新信息和外部数据提供答案的问题上存在挑战。\n",
      "\n",
      "挑战：\n",
      "\n",
      "实现RAG技术⾯临新挑战，包括发展可靠检索器和确保检索⽂本相关性。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "RAG领域发展：\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "RAG研究快速扩张，新论⽂介绍了不同的实现⽅式和技术改进。\n",
      "\n",
      "这些发展给AI实践者评估性能和适⽤性带来挑战。\n",
      "\n",
      "研究内容：\n",
      "\n",
      "针对巴⻄葡萄⽛语的RAG实施的全⾯实验。\n",
      "\n",
      "评估不同检索技术，探讨分块策略优化检索信息的整合。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "分析⽂档位置对⽣成内容质量的影响。\n",
      "\n",
      "⽐较不同LLMs在整合检索信息产⽣回应的能⼒。\n",
      "\n",
      "主要贡献：\n",
      "\n",
      "1. 数据集准备⽅法，量化RAG系统不同步骤的质量。\n",
      "\n",
      "2. 最⼤相对分数度量，量化⽅法与理想RAG系统间的差距。\n",
      "\n",
      "3. 开发RAG系统时的最佳实践和优化讨论。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "2 数据预处理\n",
      "\n",
      "1. 数据集选择：选⽤的数据集是巴⻄葡萄⽛语版本的第⼀本《哈利·波特》书籍。这个选择的原因是该书籍⼴为\n",
      "\n",
      "⼈知，且Gemini Pro和OpenAI模型都能就此主题回答⼀般性问题。\n",
      "\n",
      "2. 数据处理：使⽤标准的ChatGPT分词器c110k_base，发现总共⼤约有140,000个词标。这允许创建包含整本\n",
      "\n",
      "书的提示语。\n",
      "\n",
      "3. 数据集构建：随后，开发了⼀个包含问题和相应答案的数据集，问题和答案都是由gpt-4模型⽣成，并基于⼀\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "个参考⽂本块。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "3 如何评估\n",
      "\n",
      "1. 问题：\n",
      "\n",
      "传统评价指标如BLEU和ROUGE可能⽆法准确反映⽂本之间的上下⽂相似性。\n",
      "\n",
      "2. ⽅法：\n",
      "\n",
      "使⽤gpt-4提供基于特定提示的评分。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "开发了⼀个五级评分系统来⽐较⽂本。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "3. 评分标准：\n",
      "\n",
      "1分：答案与参考⽆关。\n",
      "\n",
      "3分：答案略有相关性，但不⼀致。' metadata={'source': './RAG-编年史.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/25/2024 10:36:13 - [INFO] -faiss.loader->>>    Loading faiss with AVX2 support.\n",
      "07/25/2024 10:36:13 - [INFO] -faiss.loader->>>    Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "# FAISS.from_documents(...) 从给定的文档集合texts中创建一个FAISS索引\n",
    "\n",
    "# distrance_strategy : 指定了距离计算策略为最大内积（MAX_INNER_PRODUCT）。\n",
    "# 在相似性搜索中，内积常用于衡量向量之间的相似度，最大内积策略意味着会优先考虑内积值最大的项，即最相似的文档。\n",
    "\n",
    "# as_retriever() : 将之前创建的FAISS索引转化为一个检索器，用于执行相似性搜索。\n",
    "# score_threshold=0.3表示只有当相似性得分超过0.3时，结果才会被认为是相关的，这是一个过滤结果的阈值。\n",
    "# \"k\": 10指定了返回结果的数量，即对于每个查询，返回得分最高的10个文档。\n",
    "\n",
    "retriever = FAISS.from_documents(texts, \n",
    "                                 embed_model, \n",
    "                                 distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT\n",
    "                                ).as_retriever(search_type=\"similarity\", \n",
    "                                               search_kwargs={\"score_threshold\": 0.3, \"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先使用retriever来进行初始的文档检索，然后可能使用base_compressor（即reranker）来进一步处理这些检索结果，\n",
    "# 比如通过重新排序来提高检索结果的相关性。\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor = reranker,\n",
    "    base_retriever = retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "response = compression_retriever.get_relevant_documents(\"RAG是什么?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './RAG-编年史.pdf', 'relevance_score': 0.5261356234550476}, page_content='唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n1. 论⽂名称：the chronicles of rag: the retriever, the chunk and the generator\\n\\nRAG编年史：检索器，⽂本块和⽣成器\\n\\nAbstract\\n\\n背景：\\n\\n唐国梁Tommy\\n\\nRAG是⼀种使⼤型语⾔模型（LLMs）访问外部数据的流⾏范式。\\n\\n唐国梁Tommy\\n\\nRAG的实施⾯临诸多挑战，包括检索模型的有效整合、表示学习、数据多样性、计算效率优化等。\\n\\n唐国梁Tommy\\n\\n⽬的：\\n\\n提出对巴⻄葡萄⽛语实施、优化和评估RAG的良好实践。\\n\\n通过简单的流⽔线进⾏推理和实验，回答有关哈利·波特书籍的问题。\\n\\n⽅法：\\n\\n使⽤OpenAI的gpt-4、gpt-4-1106-preview、gpt-3.5-turbo-1106和Google的Gemini Pro⽣成答案。\\n\\n唐国梁Tommy\\n\\n重点提升检索器的质量。\\n\\n唐国梁Tommy\\n\\n结果：\\n\\n唐国梁Tommy\\n\\n⽅法使得MRR@10相⽐基线提⾼了35.4%。\\n\\n经过优化，性能进⼀步提升了2.4%。\\n\\n结论：\\n\\nRAG架构经过建议的增强后，相对得分从57.88%提⾼到了98.61%的最⼤值。\\n\\n唐国梁Tommy\\n\\n1 Introduction\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n背景：\\n\\nLLMs在AI应⽤中取得显著成绩，尤其在翻译、总结等任务中。\\n\\n需要基于最新信息和外部数据提供答案的问题上存在挑战。\\n\\n挑战：\\n\\n实现RAG技术⾯临新挑战，包括发展可靠检索器和确保检索⽂本相关性。\\n\\n唐国梁Tommy\\n\\nRAG领域发展：\\n\\n唐国梁Tommy\\n\\nRAG研究快速扩张，新论⽂介绍了不同的实现⽅式和技术改进。\\n\\n这些发展给AI实践者评估性能和适⽤性带来挑战。\\n\\n研究内容：\\n\\n针对巴⻄葡萄⽛语的RAG实施的全⾯实验。\\n\\n评估不同检索技术，探讨分块策略优化检索信息的整合。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n分析⽂档位置对⽣成内容质量的影响。\\n\\n⽐较不同LLMs在整合检索信息产⽣回应的能⼒。\\n\\n主要贡献：\\n\\n1. 数据集准备⽅法，量化RAG系统不同步骤的质量。\\n\\n2. 最⼤相对分数度量，量化⽅法与理想RAG系统间的差距。\\n\\n3. 开发RAG系统时的最佳实践和优化讨论。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n2 数据预处理\\n\\n1. 数据集选择：选⽤的数据集是巴⻄葡萄⽛语版本的第⼀本《哈利·波特》书籍。这个选择的原因是该书籍⼴为\\n\\n⼈知，且Gemini Pro和OpenAI模型都能就此主题回答⼀般性问题。\\n\\n2. 数据处理：使⽤标准的ChatGPT分词器c110k_base，发现总共⼤约有140,000个词标。这允许创建包含整本\\n\\n书的提示语。\\n\\n3. 数据集构建：随后，开发了⼀个包含问题和相应答案的数据集，问题和答案都是由gpt-4模型⽣成，并基于⼀\\n\\n唐国梁Tommy\\n\\n个参考⽂本块。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n3 如何评估\\n\\n1. 问题：\\n\\n传统评价指标如BLEU和ROUGE可能⽆法准确反映⽂本之间的上下⽂相似性。\\n\\n2. ⽅法：\\n\\n使⽤gpt-4提供基于特定提示的评分。\\n\\n唐国梁Tommy\\n\\n开发了⼀个五级评分系统来⽐较⽂本。\\n\\n唐国梁Tommy\\n\\n3. 评分标准：\\n\\n1分：答案与参考⽆关。\\n\\n3分：答案略有相关性，但不⼀致。'),\n",
       " Document(metadata={'source': './RAG-编年史.pdf', 'relevance_score': 0.5250557065010071}, page_content='唐国梁Tommy\\n\\n2. 架构和训练：\\n\\n唐国梁Tommy\\n\\ngpt-4的具体架构未公开，但据信没有在128k词标输⼊上下⽂中进⾏预训练。\\n\\n可能通过后训练技术扩展输⼊词标数量。\\n\\n重要的是，使⽤这样的技术可能在达到扩展极限时导致性能下降。\\n\\n3. 实验：\\n\\n为评估gpt-4-1106-preview在全上下⽂容量下的性能，进⾏了类似于数据集中的\"中间丢失\"分析。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n分析了模型输出，同时改变答案在提示中的位置。\\n\\n实验通过改变包含问题答案的块的深度（以总词标数量的10%为增量），在y轴上展示了11种答案深度变化。\\n\\n4. 结果：\\n\\n提⾼输⼊⻓度时，分数有显著下降。\\n\\n位于（40%，80%）区间的答案表现最差，如\"中间丢失\"⽂章中所记录。\\n\\n1. 图表：\\n\\n唐国梁Tommy\\n\\n图2展示了实验分数，颜⾊越绿表示分数越好。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n图3显示了答案位置与性能下降之间的关系。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n图2展示了实验分数，颜⾊越绿表示分数越好\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n图3显示了答案位置与性能下降之间的关系\\n\\n4.3 RAG Naive\\n\\n1. ⽅法：\\n\\n唐国梁Tommy\\n\\n使⽤llama-index进⾏直接的RAG实验，采⽤所有默认的超参数。\\n\\n唐国梁Tommy\\n\\n使⽤余弦相似性和ADA-002嵌⼊来检索块。\\n\\n图4描述了问题处理的基本流程。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n5 ⾼级实验\\n\\n1. 背景：\\n\\n第4节的研究和实验显示了不满意的性能，⾄少⽐峰值性能降低了20%。\\n\\n本节探索了RAG的各种检索⽅法，认识到检索器的质量是提⾼这种问题性能的关键因素。\\n\\n2. 实验设计：\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n对稀疏和密集搜索进⾏评估，使⽤混合⽅法，甚⾄采⽤了多阶段架构使⽤重排序器。\\n\\n3. 系统选择：\\n\\n为了代码调试的灵活性和每个阶段更容易的定制化，没有使⽤RAG框架（如LangChain或Llama- Index）。\\n\\n5.1 检索器 Retriever\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n5.1 检索器 Retriever\\n\\n1. 检索器评估：\\n\\n评估策略围绕检索器在检索相关信息上的表现，使⽤召回率作为评价指标。\\n\\n引⼊了倒数排名（RR）到分析中，这个指标考虑了相关块出现的具体排名位置。\\n\\n评估使⽤召回率和倒数排名在特定截⽌点进⾏，作为给定检索⽅法效果的综合度量。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n2. 检索⽅法：\\n\\n唐国梁Tommy\\n\\n稀疏检索器强调BM25技术，⼀个基于统计权重的技术。\\n\\n双编码器设计的双向检索器，可以独⽴编码查询和⽂档，创建单独的向量表示。\\n\\n混合搜索技术试图结合稀疏和密集搜索技术的优势。\\n\\n3. 多阶段搜索架构：\\n\\n基于检索和重排管道，第⼀阶段使⽤好的检索器来选择初始列表的⽂档，然后在第⼆阶段进⾏⾼计算复杂度的\\n\\n唐国梁Tommy\\n\\n重排。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n5.1.1 BM25\\n\\n1.BM25的优势：'),\n",
       " Document(metadata={'source': './RAG-编年史.pdf', 'relevance_score': 0.49286386370658875}, page_content=\"提供了最佳结果的混合组合是使⽤BM25和⾃定义ADA-002。\\n\\n5.1.5 Reranker 重排\\n\\n1. 重排器的基本概念：\\n\\n唐国梁Tommy\\n\\n多阶段排名的基础是将⽂档排名分为⼀系列阶段，每个后续阶段重新评估并排名前⼀阶段传递来的候选\\n\\n唐国梁Tommy\\n\\n集。\\n\\n唐国梁Tommy\\n\\n2. 多阶段排名：\\n\\n图9展示了⼀个多阶段管道，其中Pyserini BM25负责第⼀阶段，然后候选块由重排器重新评估。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n重排后的列表称为检索到的块，由\\n\\n个块组成最终结果。\\n\\n3. 重排器的使⽤：\\n\\n通常使⽤基于Transformer的模型作为重排器，利⽤它们捕捉⽂档和查询中复杂关系和上下⽂信息的能 ⼒来提⾼信息检索系统的效果。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n最初在多阶段排名框架内使⽤Transformer的研究提出了monoBERT，将排名过程转换为相关性分类问 题。\\n\\n4. monoBERT与monoT5：\\n\\nmonoBERT通过计算\\n\\n来对⽂本进⾏排序，其中\\n\\n是查询， 表示⽂档。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n另⼀⽅⾯，monoT5是⼀种序列到序列的重排器，使⽤T5模型⽣成查询和⽂档之间的分数，这要求对⽂ 本到⽂本任务进⾏⼀些调整。\\n\\n5. 实验中的应⽤：\\n\\n在实验中，⾸先使⽤Pyserini BM25作为第⼀阶段检索，检索50个⽂档进⾏下⼀阶段的重排。\\n\\n第⼆阶段利⽤了unicamp-dl/mt5-base-en-pt-msmarco-v2模型，这是⼀个基于序列到序列的重排器， 它在英语和葡萄⽛语的查询和⽂档对上进⾏了训练。\\n\\n6. 重排器的推理过程：\\n\\n唐国梁Tommy\\n\\n图11展示了monoT5的推理过程，其中输⼊格式是 'Query: {query} Document: {document}\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\nRelevant:' ，在训练时使⽤标签yes如果⽂档与查询相关，否则为no。\\n\\n在推理时，通过计算是（yes）和否（no）标记的softmax值来获取分数。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n5.2 检索结果\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n1. 结果概述：\\n\\n展示了各种检索器的结果，如表6所示。\\n\\n2. 检索器⽐较（表6）：\\n\\n对⽐了ADA-002、⾃定义ADA-002、混合BM25-ADA-002、BM25以及BM25加重排器的性能。\\n\\n使⽤了两个指标：平均倒数排名（MRR）@10和召回率（R）@k。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n3. 性能表现：\\n\\nBM25加重排器在MRR@10和R@k上取得了最佳结果。\\n\\n其他检索器配置在不同召回率阈值下的表现也有所提升。\\n\\n这表明，通过结合BM25检索器和后续重排过程，可以显著提⾼检索任务的性能。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n6 结论\\n\\n1. RAG系统的挑战：\\n\\nRAG系统的实施⾯临着有效整合检索模型、⾼效的表示学习、数据多样性、计算效率优化、评估和⽂本 ⽣成质量等挑战。\\n\\n2. 最佳实践和简化流程：\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n⽂章提出了在巴⻄葡萄⽛语数据集上实施、优化和评估RAG的最佳实践，重点是简化推理和实验的流 程。\\n\\n唐国梁Tommy\\n\\n3. 性能改进：\"),\n",
       " Document(metadata={'source': './RAG-编年史.pdf', 'relevance_score': 0.4814987778663635}, page_content='双编码器设计的双向检索器，可以独⽴编码查询和⽂档，创建单独的向量表示。\\n\\n混合搜索技术试图结合稀疏和密集搜索技术的优势。\\n\\n3. 多阶段搜索架构：\\n\\n基于检索和重排管道，第⼀阶段使⽤好的检索器来选择初始列表的⽂档，然后在第⼆阶段进⾏⾼计算复杂度的\\n\\n唐国梁Tommy\\n\\n重排。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n5.1.1 BM25\\n\\n1.BM25的优势：\\n\\nBM25因其⽤户友好性质在RAG评估中常被采⽤。\\n\\n⼀个相关的研究表明，BM25能够建⽴⼀个强⼤的基线，并因数据与SQuAD数据集的相似性⽽提⾼效果。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n2.BM25排名函数：\\n\\n唐国梁Tommy\\n\\n和 是影响词项饱和度和⽂档⻓度规范化的参数。\\n\\nBM25公式整合了这些参数来评分⽂档对于⼀个查询的相关性，提供了在不同检索场景下提⾼有效性的灵活 性。\\n\\n1. 实验结果（表4）：\\n\\n展示了使⽤\\n\\n和\\n\\n时，不同BM25实现的⽐较。\\n\\n对⽐了rank-bm25和Pyserini BM25两种实现，以及Pyserini相较于rank-bm25的性能增益。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n2. 实施影响：\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n选择的BM25实现会影响效果。\\n\\nPyserini的BM25实现包括预处理步骤，如词⼲提取和特定语⾔的停⽤词去除。\\n\\n为了⽐较，包括了使⽤rank-bm25的结果，这是⼀种没有预处理的基础实现，并且在Python中⼴泛使 ⽤，集成到像LangChain和Llama-index这样的库中。\\n\\n3. Pyserini BM25的应⽤：\\n\\n在所有实验中都使⽤了Pyserini BM25实现，考虑\\n\\n和\\n\\n。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n5.1.2 ADA-002\\n\\n唐国梁Tommy\\n\\n1. ADA-002架构：\\n\\nOpenAI没有公开ADA-002架构的详细信息。\\n\\n尽管如此，该模型在检索过程中被⽤作所展示的双编码器设计。\\n\\n2. 双编码器设计：\\n\\n为所有可⽤的块构建向量表示。\\n\\n每个输⼊查询在搜索时计算其嵌⼊。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n随后，使⽤余弦相似性评估查询和块之间的相似度。\\n\\n唐国梁Tommy\\n\\n3. 图5说明：\\n\\n展示了双编码器架构，其中包括输⼊1的查询词标和输⼊2的块词标。\\n\\n两个输⼊在多层架构中各⾃编码，然后通过余弦相似度来评估它们之间的相似性。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n4. 由于没有关于ADA-002的更多细节，⽂本中提到将这种⽅法仅称为密集检索器。\\n\\n5.1.3 Custom ADA-002\\n\\n唐国梁Tommy\\n\\n1. ⾃定义ADA-002：\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n采⽤了⾃定义ADA-002⽅法，在第5.1.2节中介绍的密集检索器配置中。\\n\\n嵌⼊⾃定义在提⾼整体表征中扮演了关键⻆⾊。\\n\\n2. 嵌⼊⾃定义技术：\\n\\n不仅限于OpenAI的嵌⼊，适⽤于其他同类嵌⼊。\\n\\n有多种⽅法可以优化矩阵，其中之⼀是在未来⼯作中探索的多负例排名损失（Multiple Negative Ranking Loss）。\\n\\n3. 微调阶段：'),\n",
       " Document(metadata={'source': './RAG-编年史.pdf', 'relevance_score': 0.4795352518558502}, page_content='唐国梁Tommy\\n\\n6 结论\\n\\n1. RAG系统的挑战：\\n\\nRAG系统的实施⾯临着有效整合检索模型、⾼效的表示学习、数据多样性、计算效率优化、评估和⽂本 ⽣成质量等挑战。\\n\\n2. 最佳实践和简化流程：\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n⽂章提出了在巴⻄葡萄⽛语数据集上实施、优化和评估RAG的最佳实践，重点是简化推理和实验的流 程。\\n\\n唐国梁Tommy\\n\\n3. 性能改进：\\n\\n讨论了检索器质量和性能改进之间的关系，提到采⽤的⽅法使MRR@10相⽐基线提⾼了35.4%。\\n\\n4. 输⼊⼤⼩对性能的影响：\\n\\n通过输⼊⼤⼩的优化，可以进⼀步提升信息检索策略的性能，观察到性能提⾼了2.4%。\\n\\n5. RAG架构的完整评估：\\n\\n最后，展示了完整的RAG架构，并提出了优化建议。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n最终，该⽅法的准确率达到了98.61%，相⽐基线显示了40.73%的降级分数改进。\\n\\n唐国梁Tommy\\n\\n6.1 检索分数与性能\\n\\n1. 性能变化：\\n\\n检索器的性能变化范围在MRR@10指标上为0.565到0.919，如表6所详细描述。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n2. 性能与检索器质量的关系：\\n\\nRAG的性能直接受到检索器质量的影响，这⼀点⾮常重要。\\n\\n3. 图12解释：\\n\\n展示了不同检索⽅法的有效性与RAG性能之间的关系。\\n\\n横轴是MRR@10指标，纵轴是降级分数（0代表理想情况）。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n图12说明了不同检索⽅法在保持较低降级分数的同时，如何在MRR@10上实现不同的性能⽔平，其中包括BM25、 Pyserini BM25、ADA-002、⾃定义ADA-002、混合⽅法和重排⽅法。这些数据可⽤于评估和选择适合特定RAG应 ⽤的最佳检索器。\\n\\n6.2 输⼊⼤⼩与性能\\n\\n1. 性能观察：\\n\\n唐国梁Tommy\\n\\n使⽤检索-重排策略检索3个块时，获得了最佳性能，如表7所示。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n重排器的使⽤（如图9所示）在测试中改善了信息检索的结果。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n在相同配置下，Gemini Pro的性能与gpt-4相似，如表8所示。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n2. 输⼊⼤⼩的影响：\\n\\n尽管使⽤9000个词标的输⼊（表6所示）实现了9块的完美召回率，但这并未导致最佳性能。\\n\\n唐国梁Tommy\\n\\n如第4.2节所讨论的，RAG的最终结果与输⼊⼤⼩及答案所在的位置有直接关系。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n3. 成本考虑：\\n\\n从成本⻆度考虑，避免过载LLM是⾄关重要的，因为成本也基于输⼊⽂本的数量。\\n\\n4. 研究结果的通⽤性：\\n\\n本研究中获得的结果不能视为对其他数据集的泛化。\\n\\n探索性数据分析（EDA）的使⽤和良好检索器实践总是实现良好结果的可靠路径。\\n\\n表7和表8提供了检索器性能的具体数字，表明检索块数量和重排器使⽤对于提⾼RAG系统性能的重要性。\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy\\n\\n唐国梁Tommy')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "1. 论⽂名称：the chronicles of rag: the retriever, the chunk and the generator\n",
      "\n",
      "RAG编年史：检索器，⽂本块和⽣成器\n",
      "\n",
      "Abstract\n",
      "\n",
      "背景：\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "RAG是⼀种使⼤型语⾔模型（LLMs）访问外部数据的流⾏范式。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "RAG的实施⾯临诸多挑战，包括检索模型的有效整合、表示学习、数据多样性、计算效率优化等。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "⽬的：\n",
      "\n",
      "提出对巴⻄葡萄⽛语实施、优化和评估RAG的良好实践。\n",
      "\n",
      "通过简单的流⽔线进⾏推理和实验，回答有关哈利·波特书籍的问题。\n",
      "\n",
      "⽅法：\n",
      "\n",
      "使⽤OpenAI的gpt-4、gpt-4-1106-preview、gpt-3.5-turbo-1106和Google的Gemini Pro⽣成答案。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "重点提升检索器的质量。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "结果：\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "⽅法使得MRR@10相⽐基线提⾼了35.4%。\n",
      "\n",
      "经过优化，性能进⼀步提升了2.4%。\n",
      "\n",
      "结论：\n",
      "\n",
      "RAG架构经过建议的增强后，相对得分从57.88%提⾼到了98.61%的最⼤值。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "1 Introduction\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "背景：\n",
      "\n",
      "LLMs在AI应⽤中取得显著成绩，尤其在翻译、总结等任务中。\n",
      "\n",
      "需要基于最新信息和外部数据提供答案的问题上存在挑战。\n",
      "\n",
      "挑战：\n",
      "\n",
      "实现RAG技术⾯临新挑战，包括发展可靠检索器和确保检索⽂本相关性。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "RAG领域发展：\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "RAG研究快速扩张，新论⽂介绍了不同的实现⽅式和技术改进。\n",
      "\n",
      "这些发展给AI实践者评估性能和适⽤性带来挑战。\n",
      "\n",
      "研究内容：\n",
      "\n",
      "针对巴⻄葡萄⽛语的RAG实施的全⾯实验。\n",
      "\n",
      "评估不同检索技术，探讨分块策略优化检索信息的整合。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "分析⽂档位置对⽣成内容质量的影响。\n",
      "\n",
      "⽐较不同LLMs在整合检索信息产⽣回应的能⼒。\n",
      "\n",
      "主要贡献：\n",
      "\n",
      "1. 数据集准备⽅法，量化RAG系统不同步骤的质量。\n",
      "\n",
      "2. 最⼤相对分数度量，量化⽅法与理想RAG系统间的差距。\n",
      "\n",
      "3. 开发RAG系统时的最佳实践和优化讨论。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "2 数据预处理\n",
      "\n",
      "1. 数据集选择：选⽤的数据集是巴⻄葡萄⽛语版本的第⼀本《哈利·波特》书籍。这个选择的原因是该书籍⼴为\n",
      "\n",
      "⼈知，且Gemini Pro和OpenAI模型都能就此主题回答⼀般性问题。\n",
      "\n",
      "2. 数据处理：使⽤标准的ChatGPT分词器c110k_base，发现总共⼤约有140,000个词标。这允许创建包含整本\n",
      "\n",
      "书的提示语。\n",
      "\n",
      "3. 数据集构建：随后，开发了⼀个包含问题和相应答案的数据集，问题和答案都是由gpt-4模型⽣成，并基于⼀\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "个参考⽂本块。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "3 如何评估\n",
      "\n",
      "1. 问题：\n",
      "\n",
      "传统评价指标如BLEU和ROUGE可能⽆法准确反映⽂本之间的上下⽂相似性。\n",
      "\n",
      "2. ⽅法：\n",
      "\n",
      "使⽤gpt-4提供基于特定提示的评分。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "开发了⼀个五级评分系统来⽐较⽂本。\n",
      "\n",
      "唐国梁Tommy\n",
      "\n",
      "3. 评分标准：\n",
      "\n",
      "1分：答案与参考⽆关。\n",
      "\n",
      "3分：答案略有相关性，但不⼀致。\n"
     ]
    }
   ],
   "source": [
    "print(response[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
