{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 使用 FlagEmbedding\n",
    "默认情况下，`FlagModel` 在编码时将使用所有可用的 GPU。请设置 `os.environ[\"CUDA_VISIBLE_DEVICES\"]` 以选择特定的 GPU。\n",
    "\n",
    "还可以设置 `os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"` 以使所有 GPU 不可用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 情形一：一般情况下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/slurm/home/yrd/shaolab/daiyizheng/.conda/envs/langechain/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_1 = [\"这个周末我计划去海边度假，享受阳光和海浪\", \"最新研究表明，定期运动有助于提高工作效率和创造力\"]\n",
    "sentences_2 = [\"我期待的假期是在沙滩上，听着海浪声放松\", \"科技公司最近发布了一款新的智能手机，引起了广泛关注\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlagModel(\"/slurm/home/yrd/shaolab/daiyizheng/resources/hf_weights/BAAI/bge-large-zh-v1.5\", use_fp16=True)\n",
    "\n",
    "# model = FlagModel(\"BAAI/bge-large-zh-v1.5\", use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1 = model.encode(sentences_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2 = model.encode(sentences_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6987 0.271 ]\n",
      " [0.3416 0.37  ]]\n"
     ]
    }
   ],
   "source": [
    "# @运算符计算两组嵌入之间的点积\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一行表示sentences_1中第一个句子与sentences_2中两个句子的相似度分别为0.6987和0.2712。\n",
    "\n",
    "第二行表示第二个句子与sentences_2中两个句子的相似度分别为0.3416和0.37。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 情形二：query比较短，passage比较长\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.691  0.2598]\n",
      " [0.3079 0.6953]]\n"
     ]
    }
   ],
   "source": [
    "queries = [\"最新的AI研究成果\", \"健康饮食的重要性\"]\n",
    "passages = [\"AI技术正在不断进步，最近的研究揭示了其在医疗领域的潜在应用。\", \"合理的饮食习惯对维持良好的身体健康至关重要，包括足够的蔬菜和水果。\"]\n",
    "\n",
    "# encode_queries()方法为每个查询自动添加指令，从而优化查询的嵌入表示\n",
    "q_embeddings = model.encode_queries(queries)\n",
    "\n",
    "# 文档的嵌入表示则可以通过encode()或encode_corpus()方法获得，因为在这种场景下，文档不需要添加指令。\n",
    "p_embeddings = model.encode(passages)\n",
    "\n",
    "# 相似性得分\n",
    "scores = q_embeddings @ p_embeddings.T\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 使用 Sentence-Transformers\n",
    "pip install -U sentence-transformers\n",
    "\n",
    "## 2.1 情形一：一般情况下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69884855 0.2711424 ]\n",
      " [0.34143457 0.37027735]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentences_1 = [\"这个周末我计划去海边度假，享受阳光和海浪\", \"最新研究表明，定期运动有助于提高工作效率和创造力\"]\n",
    "sentences_2 = [\"我期待的假期是在沙滩上，听着海浪声放松\", \"科技公司最近发布了一款新的智能手机，引起了广泛关注\"]\n",
    "\n",
    "model = SentenceTransformer('/slurm/home/yrd/shaolab/daiyizheng/resources/hf_weights/BAAI/bge-large-zh-v1.5')\n",
    "\n",
    "embeddings_1 = model.encode(sentences_1, normalize_embeddings=True)\n",
    "embeddings_2 = model.encode(sentences_2, normalize_embeddings=True)\n",
    "\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 情形二：query比较短，passage比较长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.604624   0.15020016]\n",
      " [0.25311324 0.63686144]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "queries = [\"最新的AI研究成果\", \"健康饮食的重要性\"]\n",
    "passages = [\"AI技术正在不断进步，最近的研究揭示了其在医疗领域的潜在应用。\", \"合理的饮食习惯对维持良好的身体健康至关重要，包括足够的蔬菜和水果。\"]\n",
    "\n",
    "instruction = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "\n",
    "model = SentenceTransformer('/slurm/home/yrd/shaolab/daiyizheng/resources/hf_weights/BAAI/bge-large-zh-v1.5')\n",
    "\n",
    "# normalize_embeddings=True参数，确保生成的嵌入向量是归一化的\n",
    "q_embeddings = model.encode([instruction+q for q in queries], normalize_embeddings=True)\n",
    "\n",
    "p_embeddings = model.encode(passages, normalize_embeddings=True)\n",
    "\n",
    "scores = q_embeddings @ p_embeddings.T\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 使用 Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "import torch\n",
    "# 参考 API\n",
    "# https://api.python.langchain.com/en/v0.0.345/embeddings/langchain.embeddings.huggingface.HuggingFaceBgeEmbeddings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"/slurm/home/yrd/shaolab/daiyizheng/resources/hf_weights/BAAI/bge-large-zh-v1.5\"\n",
    "\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "hf = HuggingFaceBgeEmbeddings(model_name = model_name,\n",
    "                              model_kwargs = model_kwargs,\n",
    "                              encode_kwargs = encode_kwargs,\n",
    "                              query_instruction = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"最新的AI研究成果\", \"健康饮食的重要性\"]\n",
    "passages = [\"AI技术正在不断进步，最近的研究揭示了其在医疗领域的潜在应用。\", \"合理的饮食习惯对维持良好的身体健康至关重要，包括足够的蔬菜和水果。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "q_embeddings = [torch.tensor(hf.embed_query(query)) for query in queries]\n",
    "print(q_embeddings[0].shape)\n",
    "q_embeddings = torch.stack(q_embeddings)\n",
    "print(q_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_embeddings = torch.tensor(hf.embed_documents(passages))\n",
    "p_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6046, 0.1502],\n",
      "        [0.2531, 0.6369]])\n"
     ]
    }
   ],
   "source": [
    "scores = q_embeddings @ p_embeddings.T\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 使用 HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"/slurm/home/yrd/shaolab/daiyizheng/resources/hf_weights/BAAI/bge-large-zh-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备模拟数据\n",
    "\n",
    "documents = [\n",
    "    \"深度学习技术在计算机视觉领域中非常重要。\",\n",
    "    \"使用深度学习模型可以理解文档的深层语义。\",\n",
    "    \"密集检索器的优势通过学习文档和查询的表示来提高检索的准确率。\"\n",
    "]\n",
    "\n",
    "query = \"密集检索的优势\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取句向量表示\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    # 从模型输出中提取句子嵌入。这里，我们取输出的第一个元素（通常是最后一层的隐藏状态），\n",
    "    # 并且使用CLS令牌的嵌入作为句子的嵌入表示。CLS令牌位于每个序列的开头，经常被用作句子级任务的表示。\n",
    "    # print(output.keys())\n",
    "    # print(output[0].shape)\n",
    "    # print(output[0][:,0].shape)\n",
    "    embeddings = output[0][:,0]\n",
    "    \n",
    "    # 对句子嵌入进行L2标准化\n",
    "    normalized_embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "    return normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = get_embedding(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = torch.stack([get_embedding(doc) for doc in documents]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1024])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32651913 0.3553676  0.72206295]]\n"
     ]
    }
   ],
   "source": [
    "# 计算相似度\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "simialrities = cosine_similarity(query_embedding.numpy(), doc_embeddings.numpy())\n",
    "\n",
    "print(simialrities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
