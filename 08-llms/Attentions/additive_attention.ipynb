{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加性注意力例子\n",
    "加性注意力分数计算：\n",
    "$$a(\\mathbf{q}, \\mathbf{k})=\\mathbf{w}_v^{\\top} \\tanh \\left(\\mathbf{W}_q \\mathbf{q}+\\mathbf{W}_k \\mathbf{k}\\right) \\in \\mathbb{R}$$\n",
    "\n",
    "其中可学习的参数                                       \n",
    "$\\mathbf{W}_q \\in \\mathbb{R}^{h \\times q}, \\mathbf{W}_k \\in \\mathbb{R}^{h \\times k}, \\text { and } \\mathbf{w}_v \\in \\mathbb{R}^h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DYZ/dyz1/anaconda3/envs/cv_project/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import Tuple\n",
    "\n",
    "from lib.d2l_torch import masked_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加性注意力例子\n",
    "- batch size 为 2，对于每一个 batch，有：\n",
    "  - 两个 `query`，每个的长度为 20;\n",
    "- 有 10 个 `key-value pair`;\n",
    "  - 其中 `key` 的长度为2;\n",
    "  - 其中 `value` 的长度为 4;\n",
    "\n",
    "假设 h 的大小为 16，也就是都转换为长度为16的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 20]) torch.Size([2, 10, 2]) torch.Size([2, 10, 4])\n"
     ]
    }
   ],
   "source": [
    "queries, keys = torch.normal(0, 1, (2, 2, 20)), torch.ones((2, 10, 2))\n",
    "# The two value matrices in the values minibatch are identical\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\n",
    "# 打印大小, 第一位都是 batch size\n",
    "print(queries.shape, keys.shape, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 16]) torch.Size([2, 10, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DYZ/dyz1/anaconda3/envs/cv_project/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# 分别计算 Wq, Wk, 转换为长度为 h 的向量\n",
    "num_hiddens = 16\n",
    "W_k = nn.LazyLinear(num_hiddens, bias=False)\n",
    "W_q = nn.LazyLinear(num_hiddens, bias=False)\n",
    "\n",
    "_keys, _queries, = W_k(keys), W_q(queries)\n",
    "print(_queries.shape, _keys.shape) # 打印 query 和 key 的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "# 计算 Wq + Wk_i, 一个 q 要和所有 k 现加\n",
    "# shape of queries: (batch_size, no. of queries, num_hiddens) --> (batch_size, no. of queries, 1, num_hiddens)\n",
    "# shape of keys: (batch_size, no. of key-value pairs, num_hiddens).  --> (batch_size, 1, no. of key-value pairs, num_hiddens). \n",
    "wq_wk = _queries.unsqueeze(2) +  _keys.unsqueeze(1)\n",
    "print(wq_wk.shape)  # 一共有两个 query, 每个 query 和 10 个 key 得到一个长度为 16 的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "# 计算 tanh(w), 这里大小不变\n",
    "features = torch.tanh(wq_wk)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Squeeze torch.Size([2, 2, 10, 1])\n",
      "After Squeeze torch.Size([2, 2, 10])\n",
      "torch.Size([10])\n",
      "tensor([-0.2575, -0.2575, -0.2575, -0.2575, -0.2575, -0.2575, -0.2575, -0.2575,\n",
      "        -0.2575, -0.2575], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 计算 w_v * tanh(wq + wk) 的值, 一个 query 和 key 得到一个值\n",
    "w_v = nn.LazyLinear(1, bias=False)\n",
    "scores = w_v(features)\n",
    "print('Before Squeeze', scores.shape)\n",
    "scores.squeeze_(-1)\n",
    "print('After Squeeze', scores.shape)\n",
    "print(scores[0][0].shape) # 一个 query 和所有 key 的值, 形状\n",
    "print(scores[0][0]) # 一个 query 和所有 key 的值, 数值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 10])\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 对数值进行归一化\n",
    "attention_weight = F.softmax(scores, dim=2)\n",
    "print(attention_weight.shape)\n",
    "print(attention_weight[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 10])\n",
      "tensor([0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 利用 attention mask, 有一些是不会被包含在内的\n",
    "valid_lens = torch.tensor([2, 6]) # 第一个查看前 2 个, 第二个查看前 6 个\n",
    "attention_weight = masked_softmax(scores, valid_lens=valid_lens)\n",
    "\n",
    "print(attention_weight.shape)\n",
    "print(attention_weight[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义「加性注意力」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Additive attention.\"\"\"\n",
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.LazyLinear(num_hiddens, bias=False) # k --> h\n",
    "        self.W_q = nn.LazyLinear(num_hiddens, bias=False) # q --> h\n",
    "        self.w_v = nn.LazyLinear(1, bias=False) # h --> 1\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # 注意这里维度的变化, 会有四个维度\n",
    "        # valid_lens, 考虑多少个 key-value pair\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # After dimension expansion, \n",
    "        # shape of queries: (batch_size, no. of queries, 1, num_hiddens)\n",
    "        # shape of keys: (batch_size, 1, no. of key-value pairs, num_hiddens). \n",
    "        # Sum them up with broadcasting\n",
    "        # 最终结果的维度是, (batch_size, no. of queries, no. of key-value pairs, num_hiddens)\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # There is only one output of self.w_v, so we remove the last\n",
    "        # one-dimensional entry from the shape. \n",
    "        # Shape of scores: (batch_size, no. of queries, no. of key-value pairs)\n",
    "        # 对每一个 query, 都有 key-value pair 的大小\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # Shape of values: (batch_size, no. of key-value pairs, value dimension)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DYZ/dyz1/anaconda3/envs/cv_project/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
       "\n",
       "        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有 1 个 query, query 的长度是 20\n",
    "# 有 10 个 key, key 的长度是 2\n",
    "# 有 10 个 value, value 的长度是 4\n",
    "queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))\n",
    "# The two value matrices in the values minibatch are identical\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\n",
    "valid_lens = torch.tensor([2, 6]) # 第一个查看前 2 个, 第二个查看前 6 个\n",
    "\n",
    "attention = AdditiveAttention(num_hiddens=8, dropout=0.1)\n",
    "attention.eval()\n",
    "attention(queries, keys, values, valid_lens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表示形式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"\n",
    "     Applies a additive attention (bahdanau) mechanism on the output features from the decoder.\n",
    "     Additive attention proposed in \"Neural Machine Translation by Jointly Learning to Align and Translate\" paper.\n",
    "\n",
    "     Args:\n",
    "         hidden_dim (int): dimesion of hidden state vector\n",
    "\n",
    "     Inputs: query, value\n",
    "         - **query** (batch_size, q_len, hidden_dim): tensor containing the output features from the decoder.\n",
    "         - **value** (batch_size, v_len, hidden_dim): tensor containing features of the encoded input sequence.\n",
    "\n",
    "     Returns: context, attn\n",
    "         - **context**: tensor containing the context vector from attention mechanism.\n",
    "         - **attn**: tensor containing the alignment from the encoder outputs.\n",
    "\n",
    "     Reference:\n",
    "         - **Neural Machine Translation by Jointly Learning to Align and Translate**: https://arxiv.org/abs/1409.0473\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int) -> None:\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.query_proj = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.key_proj = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.bias = nn.Parameter(torch.rand(hidden_dim).uniform_(-0.1, 0.1))\n",
    "        self.score_proj = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        score = self.score_proj(torch.tanh(self.key_proj(key) + self.query_proj(query) + self.bias)).squeeze(-1)\n",
    "        attn = F.softmax(score, dim=-1)\n",
    "        context = torch.bmm(attn.unsqueeze(1), value)\n",
    "        return context, attn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('cv_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4a9c97a8b021f57fd72049f636b97cda4a73e3b574c4423a7c228fa056b5e4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
