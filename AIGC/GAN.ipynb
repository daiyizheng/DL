{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DYZ/dyz1/anaconda3/envs/cv_project/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\"./datasets/\", \n",
    "                            download=True, \n",
    "                            train=True, \n",
    "                            transform=transforms.Compose([\n",
    "                               transforms.ToTensor(), transforms.Normalize([0.5], [0.5])\n",
    "                            ]))\n",
    "\n",
    "test_data = datasets.MNIST('./datasets/', \n",
    "                           train=False, \n",
    "                           download=True, \n",
    "                           transform=transforms.Compose([\n",
    "                              transforms.ToTensor(), transforms.Normalize([0.5], [0.5])\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x,y = iter(train_loader).next()\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ##### 定义判别器 Discriminator ######\n",
    "## 将图片28x28展开成784，然后通过多层感知器，中间经过斜率设置为0.2的LeakyReLU激活函数，\n",
    "## 最后接sigmoid激活函数得到一个0到1之间的概率进行二分类    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(784, 512),  ## 输入特征数为784，输出为512\n",
    "            nn.LeakyReLU(0.2, inplace=True), ## 进行非线性映射\n",
    "            nn.Linear(512, 256), ## 输入特征数为512，输出为256\n",
    "            nn.LeakyReLU(0.2, inplace=True), ## 进行非线性映射\n",
    "            nn.Linear(256, 1),  ## 输入特征数为256，输出为1\n",
    "            nn.Sigmoid(), ## sigmoid是一个激活函数，二分类问题中可将实数映射到[0, 1],作为概率值, 多分类用softmax函数\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "                x:torch.Tensor):\n",
    "        \"\"\"_summary_\n",
    "        Args:\n",
    "            x (torch.Tensor): \n",
    "        Returns:\n",
    "            _type_: \n",
    "        \"\"\"\n",
    "        x = x.flatten(1)\n",
    "        return self.discriminator(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layer = [nn.Linear(in_feat, out_feat)]          ## 线性变换将输入映射到out维\n",
    "            if normalize:\n",
    "                layer.append(nn.BatchNorm1d(out_feat, 0.8)) ## 正则化\n",
    "            layer.append(nn.LeakyReLU(0.2, inplace=True)) ## 非线性激活函数\n",
    "            return layer\n",
    "\n",
    "        self.generator = nn.Sequential(\n",
    "            *block(100, 128,normalize=False), ## 线性变化将输入映射 100 to 128, 正则化, LeakyReLU\n",
    "            *block(128, 256),   ## 线性变化将输入映射 128 to 256, 正则化, LeakyReLU\n",
    "            *block(256, 512),   ## 线性变化将输入映射 256 to 512, 正则化, LeakyReLU\n",
    "            *block(512, 1024),  ## 线性变化将输入映射 512 to 1024, 正则化, LeakyReLU\n",
    "            nn.Linear(1024, 784), ## 线性变化将输入映射 1024 to 784\n",
    "            nn.Tanh() # ## 将(784)的数据每一个都映射到[-1, 1]之间\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        imgs = self.generator(z)                                     ## 噪声数据通过生成器模型\n",
    "        imgs = imgs.view(imgs.size(0), 1, 28, 28)                ## reshape成(64, 1, 28, 28)\n",
    "        return imgs                                              ## 输出为64张大小为(1, 28, 28)的图像  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 参数\n",
    "epcohs = 10\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "## 首先需要定义loss的度量方式  （二分类的交叉熵）\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "## 创建生成器，判别器对象\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "## 其次定义 优化函数,优化函数的学习率为0.0003\n",
    "## betas:用于计算梯度以及梯度平方的运行平均值的系数\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.003, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.003, betas=(0.5, 0.999))\n",
    "\n",
    "## 都在cuda模式中运行\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 99/60000] [D loss: 1.057642] [G loss: 2.896710] [D real: 0.634835] [D fake: 0.448564]\n",
      "[Epoch 0/10] [Batch 199/60000] [D loss: 0.699268] [G loss: 2.513327] [D real: 0.727830] [D fake: 0.265682]\n",
      "[Epoch 0/10] [Batch 299/60000] [D loss: 1.090155] [G loss: 1.115966] [D real: 0.498161] [D fake: 0.298167]\n",
      "[Epoch 0/10] [Batch 399/60000] [D loss: 1.131881] [G loss: 0.999511] [D real: 0.695840] [D fake: 0.525407]\n",
      "[Epoch 0/10] [Batch 499/60000] [D loss: 2.041314] [G loss: 0.269469] [D real: 0.156802] [D fake: 0.075694]\n",
      "[Epoch 0/10] [Batch 599/60000] [D loss: 0.927922] [G loss: 1.115815] [D real: 0.575406] [D fake: 0.293345]\n",
      "[Epoch 0/10] [Batch 699/60000] [D loss: 0.957753] [G loss: 2.605673] [D real: 0.670651] [D fake: 0.404052]\n",
      "[Epoch 0/10] [Batch 799/60000] [D loss: 0.925860] [G loss: 1.181737] [D real: 0.561867] [D fake: 0.270989]\n",
      "[Epoch 0/10] [Batch 899/60000] [D loss: 1.073038] [G loss: 1.098074] [D real: 0.547136] [D fake: 0.365166]\n",
      "d_epoch_loss: 1.301612191680652\n",
      "g_epoch_loss: 1.7626964569878096\n",
      "[Epoch 1/10] [Batch 99/60000] [D loss: 0.794078] [G loss: 2.283109] [D real: 0.675704] [D fake: 0.293950]\n",
      "[Epoch 1/10] [Batch 199/60000] [D loss: 0.669984] [G loss: 2.527311] [D real: 0.650447] [D fake: 0.190866]\n",
      "[Epoch 1/10] [Batch 299/60000] [D loss: 2.331282] [G loss: 1.184279] [D real: 0.928193] [D fake: 0.886093]\n",
      "[Epoch 1/10] [Batch 399/60000] [D loss: 1.040374] [G loss: 0.926493] [D real: 0.536940] [D fake: 0.310555]\n",
      "[Epoch 1/10] [Batch 499/60000] [D loss: 1.636374] [G loss: 0.049880] [D real: 0.267748] [D fake: 0.133943]\n",
      "[Epoch 1/10] [Batch 599/60000] [D loss: 1.000052] [G loss: 1.388501] [D real: 0.578357] [D fake: 0.338637]\n",
      "[Epoch 1/10] [Batch 699/60000] [D loss: 1.120750] [G loss: 1.580834] [D real: 0.734176] [D fake: 0.516785]\n",
      "[Epoch 1/10] [Batch 799/60000] [D loss: 1.352684] [G loss: 1.071802] [D real: 0.396137] [D fake: 0.263753]\n",
      "[Epoch 1/10] [Batch 899/60000] [D loss: 1.332145] [G loss: 0.691270] [D real: 0.478176] [D fake: 0.368867]\n",
      "d_epoch_loss: 1.2552656918319303\n",
      "g_epoch_loss: 1.42086172257977\n",
      "[Epoch 2/10] [Batch 99/60000] [D loss: 1.241895] [G loss: 1.033575] [D real: 0.451034] [D fake: 0.257112]\n",
      "[Epoch 2/10] [Batch 199/60000] [D loss: 0.925261] [G loss: 1.233659] [D real: 0.673539] [D fake: 0.367439]\n",
      "[Epoch 2/10] [Batch 299/60000] [D loss: 1.296012] [G loss: 1.209206] [D real: 0.757714] [D fake: 0.607960]\n",
      "[Epoch 2/10] [Batch 399/60000] [D loss: 1.168537] [G loss: 0.891103] [D real: 0.543370] [D fake: 0.342247]\n",
      "[Epoch 2/10] [Batch 499/60000] [D loss: 1.325790] [G loss: 1.360733] [D real: 0.391842] [D fake: 0.232773]\n",
      "[Epoch 2/10] [Batch 599/60000] [D loss: 1.111811] [G loss: 1.917865] [D real: 0.773444] [D fake: 0.511392]\n",
      "[Epoch 2/10] [Batch 699/60000] [D loss: 1.073817] [G loss: 1.170134] [D real: 0.603981] [D fake: 0.386793]\n",
      "[Epoch 2/10] [Batch 799/60000] [D loss: 1.192969] [G loss: 1.821216] [D real: 0.715313] [D fake: 0.515662]\n",
      "[Epoch 2/10] [Batch 899/60000] [D loss: 1.353186] [G loss: 1.030660] [D real: 0.408123] [D fake: 0.262190]\n",
      "d_epoch_loss: 1.224287030729912\n",
      "g_epoch_loss: 1.2649204433440908\n",
      "[Epoch 3/10] [Batch 99/60000] [D loss: 1.283465] [G loss: 1.594425] [D real: 0.693100] [D fake: 0.526244]\n",
      "[Epoch 3/10] [Batch 199/60000] [D loss: 1.248880] [G loss: 1.243452] [D real: 0.683202] [D fake: 0.527680]\n",
      "[Epoch 3/10] [Batch 299/60000] [D loss: 1.310168] [G loss: 1.200765] [D real: 0.672531] [D fake: 0.541192]\n",
      "[Epoch 3/10] [Batch 399/60000] [D loss: 1.176651] [G loss: 0.705939] [D real: 0.524409] [D fake: 0.320893]\n",
      "[Epoch 3/10] [Batch 499/60000] [D loss: 1.266568] [G loss: 0.730774] [D real: 0.465203] [D fake: 0.289498]\n",
      "[Epoch 3/10] [Batch 599/60000] [D loss: 1.296563] [G loss: 0.978490] [D real: 0.500811] [D fake: 0.403939]\n",
      "[Epoch 3/10] [Batch 699/60000] [D loss: 1.162270] [G loss: 0.869673] [D real: 0.494430] [D fake: 0.287457]\n",
      "[Epoch 3/10] [Batch 799/60000] [D loss: 1.071374] [G loss: 1.372584] [D real: 0.637101] [D fake: 0.395805]\n",
      "[Epoch 3/10] [Batch 899/60000] [D loss: 1.144840] [G loss: 1.365219] [D real: 0.626378] [D fake: 0.417367]\n",
      "d_epoch_loss: 1.27021589640107\n",
      "g_epoch_loss: 1.1664241779841849\n",
      "[Epoch 4/10] [Batch 99/60000] [D loss: 1.299938] [G loss: 1.203399] [D real: 0.562721] [D fake: 0.440786]\n",
      "[Epoch 4/10] [Batch 199/60000] [D loss: 1.109353] [G loss: 1.140164] [D real: 0.556484] [D fake: 0.347406]\n",
      "[Epoch 4/10] [Batch 299/60000] [D loss: 1.299252] [G loss: 1.949475] [D real: 0.769476] [D fake: 0.595727]\n",
      "[Epoch 4/10] [Batch 399/60000] [D loss: 1.510109] [G loss: 2.692245] [D real: 0.855744] [D fake: 0.687779]\n",
      "[Epoch 4/10] [Batch 499/60000] [D loss: 1.228672] [G loss: 2.646301] [D real: 0.786471] [D fake: 0.561652]\n",
      "[Epoch 4/10] [Batch 599/60000] [D loss: 1.349209] [G loss: 0.695002] [D real: 0.432434] [D fake: 0.304814]\n",
      "[Epoch 4/10] [Batch 699/60000] [D loss: 1.497022] [G loss: 0.292088] [D real: 0.359906] [D fake: 0.209016]\n",
      "[Epoch 4/10] [Batch 799/60000] [D loss: 1.835479] [G loss: 0.792361] [D real: 0.222957] [D fake: 0.128955]\n",
      "[Epoch 4/10] [Batch 899/60000] [D loss: 1.152136] [G loss: 0.916663] [D real: 0.517682] [D fake: 0.337842]\n",
      "d_epoch_loss: 1.2808273127084093\n",
      "g_epoch_loss: 1.1385858353060574\n",
      "[Epoch 5/10] [Batch 99/60000] [D loss: 1.147242] [G loss: 1.168050] [D real: 0.573043] [D fake: 0.387921]\n",
      "[Epoch 5/10] [Batch 199/60000] [D loss: 1.149640] [G loss: 0.783525] [D real: 0.616953] [D fake: 0.440577]\n",
      "[Epoch 5/10] [Batch 299/60000] [D loss: 1.318148] [G loss: 0.928262] [D real: 0.459311] [D fake: 0.338843]\n",
      "[Epoch 5/10] [Batch 399/60000] [D loss: 1.326242] [G loss: 0.907844] [D real: 0.563036] [D fake: 0.458741]\n",
      "[Epoch 5/10] [Batch 499/60000] [D loss: 1.226432] [G loss: 1.049048] [D real: 0.602527] [D fake: 0.473031]\n",
      "[Epoch 5/10] [Batch 599/60000] [D loss: 1.308430] [G loss: 0.886389] [D real: 0.603260] [D fake: 0.496612]\n",
      "[Epoch 5/10] [Batch 699/60000] [D loss: 1.185418] [G loss: 1.044675] [D real: 0.546877] [D fake: 0.398375]\n",
      "[Epoch 5/10] [Batch 799/60000] [D loss: 1.220606] [G loss: 0.891183] [D real: 0.593415] [D fake: 0.459855]\n",
      "[Epoch 5/10] [Batch 899/60000] [D loss: 1.288687] [G loss: 0.900367] [D real: 0.626879] [D fake: 0.533706]\n",
      "d_epoch_loss: 1.3106118860021074\n",
      "g_epoch_loss: 1.0606354829281377\n",
      "[Epoch 6/10] [Batch 99/60000] [D loss: 1.314252] [G loss: 1.441012] [D real: 0.721214] [D fake: 0.586153]\n",
      "[Epoch 6/10] [Batch 199/60000] [D loss: 1.326526] [G loss: 1.209125] [D real: 0.652004] [D fake: 0.555246]\n",
      "[Epoch 6/10] [Batch 299/60000] [D loss: 1.227712] [G loss: 1.224423] [D real: 0.584117] [D fake: 0.432783]\n",
      "[Epoch 6/10] [Batch 399/60000] [D loss: 1.438500] [G loss: 1.270888] [D real: 0.718590] [D fake: 0.632425]\n",
      "[Epoch 6/10] [Batch 499/60000] [D loss: 1.285792] [G loss: 1.296294] [D real: 0.678702] [D fake: 0.546760]\n",
      "[Epoch 6/10] [Batch 599/60000] [D loss: 1.254410] [G loss: 0.689524] [D real: 0.530253] [D fake: 0.372836]\n",
      "[Epoch 6/10] [Batch 699/60000] [D loss: 1.242446] [G loss: 0.828092] [D real: 0.557606] [D fake: 0.421613]\n",
      "[Epoch 6/10] [Batch 799/60000] [D loss: 1.392047] [G loss: 1.839754] [D real: 0.673871] [D fake: 0.587787]\n",
      "[Epoch 6/10] [Batch 899/60000] [D loss: 1.336739] [G loss: 1.390419] [D real: 0.672059] [D fake: 0.572128]\n",
      "d_epoch_loss: 1.3280951903064622\n",
      "g_epoch_loss: 1.0174082804367994\n",
      "[Epoch 7/10] [Batch 99/60000] [D loss: 1.198755] [G loss: 0.986620] [D real: 0.593029] [D fake: 0.461524]\n",
      "[Epoch 7/10] [Batch 199/60000] [D loss: 1.217744] [G loss: 1.048826] [D real: 0.621722] [D fake: 0.483658]\n",
      "[Epoch 7/10] [Batch 299/60000] [D loss: 1.257383] [G loss: 0.728631] [D real: 0.524980] [D fake: 0.430876]\n",
      "[Epoch 7/10] [Batch 399/60000] [D loss: 1.362597] [G loss: 1.841502] [D real: 0.688969] [D fake: 0.576916]\n",
      "[Epoch 7/10] [Batch 499/60000] [D loss: 1.269433] [G loss: 0.747678] [D real: 0.463283] [D fake: 0.343016]\n",
      "[Epoch 7/10] [Batch 599/60000] [D loss: 1.436398] [G loss: 0.994362] [D real: 0.513647] [D fake: 0.482865]\n",
      "[Epoch 7/10] [Batch 699/60000] [D loss: 1.362133] [G loss: 0.531383] [D real: 0.495587] [D fake: 0.456368]\n",
      "[Epoch 7/10] [Batch 799/60000] [D loss: 1.395563] [G loss: 0.676785] [D real: 0.414218] [D fake: 0.337866]\n",
      "[Epoch 7/10] [Batch 899/60000] [D loss: 1.984331] [G loss: 0.464375] [D real: 0.171521] [D fake: 0.114117]\n",
      "d_epoch_loss: 1.3510561521881934\n",
      "g_epoch_loss: 0.9909155500182973\n",
      "[Epoch 8/10] [Batch 99/60000] [D loss: 1.316770] [G loss: 0.870440] [D real: 0.397959] [D fake: 0.282194]\n",
      "[Epoch 8/10] [Batch 199/60000] [D loss: 1.276566] [G loss: 1.505192] [D real: 0.649443] [D fake: 0.523732]\n",
      "[Epoch 8/10] [Batch 299/60000] [D loss: 1.232966] [G loss: 1.004890] [D real: 0.666519] [D fake: 0.522457]\n",
      "[Epoch 8/10] [Batch 399/60000] [D loss: 1.157153] [G loss: 0.943690] [D real: 0.553168] [D fake: 0.393880]\n",
      "[Epoch 8/10] [Batch 499/60000] [D loss: 1.240714] [G loss: 0.964281] [D real: 0.597546] [D fake: 0.487710]\n",
      "[Epoch 8/10] [Batch 599/60000] [D loss: 1.271696] [G loss: 1.487930] [D real: 0.705844] [D fake: 0.572835]\n",
      "[Epoch 8/10] [Batch 699/60000] [D loss: 1.342510] [G loss: 0.588274] [D real: 0.459472] [D fake: 0.362871]\n",
      "[Epoch 8/10] [Batch 799/60000] [D loss: 1.965793] [G loss: 1.618929] [D real: 0.851626] [D fake: 0.805068]\n",
      "[Epoch 8/10] [Batch 899/60000] [D loss: 1.337730] [G loss: 1.632258] [D real: 0.702164] [D fake: 0.590302]\n",
      "d_epoch_loss: 1.3547119535108618\n",
      "g_epoch_loss: 0.973646426061069\n",
      "[Epoch 9/10] [Batch 99/60000] [D loss: 1.355154] [G loss: 0.673036] [D real: 0.394877] [D fake: 0.278016]\n",
      "[Epoch 9/10] [Batch 199/60000] [D loss: 1.457157] [G loss: 0.999063] [D real: 0.765289] [D fake: 0.665954]\n",
      "[Epoch 9/10] [Batch 299/60000] [D loss: 1.387333] [G loss: 0.495900] [D real: 0.441585] [D fake: 0.364889]\n",
      "[Epoch 9/10] [Batch 399/60000] [D loss: 1.326465] [G loss: 1.432000] [D real: 0.694482] [D fake: 0.572021]\n",
      "[Epoch 9/10] [Batch 499/60000] [D loss: 1.383523] [G loss: 0.598196] [D real: 0.456718] [D fake: 0.404336]\n",
      "[Epoch 9/10] [Batch 599/60000] [D loss: 1.500843] [G loss: 0.458707] [D real: 0.348167] [D fake: 0.289047]\n",
      "[Epoch 9/10] [Batch 699/60000] [D loss: 1.464530] [G loss: 1.273918] [D real: 0.691565] [D fake: 0.636624]\n",
      "[Epoch 9/10] [Batch 799/60000] [D loss: 1.313260] [G loss: 0.883523] [D real: 0.547349] [D fake: 0.458011]\n",
      "[Epoch 9/10] [Batch 899/60000] [D loss: 1.246434] [G loss: 1.133630] [D real: 0.556493] [D fake: 0.460875]\n",
      "d_epoch_loss: 1.3648837190955432\n",
      "g_epoch_loss: 0.962207521234494\n"
     ]
    }
   ],
   "source": [
    "## 训练\n",
    "for epoch in range(epcohs):\n",
    "    \n",
    "    d_epoch_loss = 0\n",
    "    g_epoch_loss = 0\n",
    "    count = len(train_loader)  #返回批次数\n",
    "\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        bz = x.shape[0]\n",
    "        x = x.to(device)\n",
    "        ## ---------------------\n",
    "        ##  Train Discriminator\n",
    "        ## 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "        ## ---------------------\n",
    "        ## 计算真实图片的损失\n",
    "        real_out = discriminator(x)\n",
    "        d_real_loss = criterion(real_out, torch.ones_like(real_out))\n",
    "        \n",
    "        ## 计算假的图片的损失\n",
    "        ## detach(): 从当前计算图中分离下来避免梯度传到G，因为G不用更新\n",
    "        random_noise = torch.randn(bz,100,device=device)\n",
    "        gen_img = generator(random_noise)\n",
    "        fake_output = discriminator(gen_img.detach()) \n",
    "        d_fake_loss = criterion(fake_output,torch.zeros_like(fake_output))\n",
    "        \n",
    "        d_loss = d_real_loss + d_fake_loss ## 损失包括判真损失和判假损失\n",
    "        optimizer_D.zero_grad()  ## 在反向传播之前，先将梯度归0\n",
    "        d_loss.backward()  ## 将误差反向传播\n",
    "        optimizer_D.step() ## 更新参数\n",
    "        \n",
    "        d_epoch_loss += d_loss.item()\n",
    "        \n",
    "        ## -----------------\n",
    "        ##  Train Generator\n",
    "        ## 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "        ## 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "        ## 反向传播更新的参数是生成网络里面的参数，\n",
    "        ## 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的, 这样就达到了对抗的目的\n",
    "        ## -----------------\n",
    "\n",
    "        random_noise = torch.randn(bz,100,device=device)\n",
    "        fake_img = generator(random_noise)                                             ## 随机噪声输入到生成器中，得到一副假的图片\n",
    "        output = discriminator(fake_img)                                    ## 经过判别器得到的结果\n",
    "        ## 损失函数和优化\n",
    "        g_loss = criterion(output, torch.ones_like(output))                             ## 得到的假的图片与真实的图片的label的loss\n",
    "        optimizer_G.zero_grad()                                             ## 梯度归0\n",
    "        g_loss.backward()                                                   ## 进行反向传播\n",
    "        optimizer_G.step()                                                  ## step()一般用在反向传播后面,用于更新生成网络的参数\n",
    "\n",
    "        g_epoch_loss += g_loss.item()\n",
    "        \n",
    "        ## 打印训练过程中的日志\n",
    "        ## item():取出单元素张量的元素值并返回该值，保持原元素类型不变\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [D real: %f] [D fake: %f]\"\n",
    "                % (epoch, 10, i, len(train_data), d_loss.item(), g_loss.item(), real_out.data.mean(), fake_output.data.mean())\n",
    "            )\n",
    "        # ## 保存训练过程中的图像\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            batches_done = \"_\"+str(epoch)+\"_\"+ str(i)+\"_\"\n",
    "            save_image(fake_img.data[:25], \"./results/gan/images/%s.png\" % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "    print(\"d_epoch_loss:\", d_epoch_loss/count)\n",
    "    print(\"g_epoch_loss:\", g_epoch_loss/count)\n",
    "        \n",
    "## 保存模型\n",
    "torch.save(generator.state_dict(), './results/gan/generator.pth')\n",
    "torch.save(discriminator.state_dict(), './results/gan/discriminator.pth')       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------\n",
    "##  Training\n",
    "## ----------\n",
    "## 进行多个epoch的训练\n",
    "for epoch in range(10):                               ## epoch:50\n",
    "    for i, (imgs, _) in enumerate(train_loader):                  ## imgs:(64, 1, 28, 28)     _:label(64)\n",
    "        \n",
    "        ## =============================训练判别器==================\n",
    "        ## view(): 相当于numpy中的reshape，重新定义矩阵的形状, 相当于reshape(128，784)  原来是(128, 1, 28, 28)\n",
    "        # imgs = imgs.view(imgs.size(0), -1)                          ## 将图片展开为28*28=784  imgs:(64, 784)\n",
    "        real_img = Variable(imgs).cuda()                            ## 将tensor变成Variable放入计算图中，tensor变成variable之后才能进行反向传播求梯度\n",
    "        real_label = Variable(torch.ones(imgs.size(0), 1)).cuda()      ## 定义真实的图片label为1\n",
    "        fake_label = Variable(torch.zeros(imgs.size(0), 1)).cuda()     ## 定义假的图片的label为0\n",
    "\n",
    "\n",
    "        ## ---------------------\n",
    "        ##  Train Discriminator\n",
    "        ## 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "        ## ---------------------\n",
    "        ## 计算真实图片的损失\n",
    "        real_out = discriminator(real_img)                          ## 将真实图片放入判别器中\n",
    "        loss_real_D = criterion(real_out, real_label)               ## 得到真实图片的loss\n",
    "        real_scores = real_out                                      ## 得到真实图片的判别值，输出的值越接近1越好\n",
    "        ## 计算假的图片的损失\n",
    "        ## detach(): 从当前计算图中分离下来避免梯度传到G，因为G不用更新\n",
    "        z = Variable(torch.randn(imgs.size(0), 100)).cuda()      ## 随机生成一些噪声, 大小为(128, 100)\n",
    "       \n",
    "        fake_img = generator(z).detach()                                    ## 随机噪声放入生成网络中，生成一张假的图片。 \n",
    "        fake_out = discriminator(fake_img)                                  ## 判别器判断假的图片\n",
    "        loss_fake_D = criterion(fake_out, fake_label)                       ## 得到假的图片的loss\n",
    "        fake_scores = fake_out                                              ## 得到假图片的判别值，对于判别器来说，假图片的损失越接近0越好\n",
    "        ## 损失函数和优化\n",
    "        loss_D = loss_real_D + loss_fake_D                  ## 损失包括判真损失和判假损失\n",
    "        optimizer_D.zero_grad()                             ## 在反向传播之前，先将梯度归0\n",
    "        loss_D.backward()                                   ## 将误差反向传播\n",
    "        optimizer_D.step()                                  ## 更新参数\n",
    "\n",
    "\n",
    "        ## -----------------\n",
    "        ##  Train Generator\n",
    "        ## 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "        ## 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "        ## 反向传播更新的参数是生成网络里面的参数，\n",
    "        ## 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的, 这样就达到了对抗的目的\n",
    "        ## -----------------\n",
    "        z = Variable(torch.randn(imgs.size(0), 100)).cuda()      ## 得到随机噪声\n",
    "        fake_img = generator(z)                                             ## 随机噪声输入到生成器中，得到一副假的图片\n",
    "        output = discriminator(fake_img)                                    ## 经过判别器得到的结果\n",
    "        ## 损失函数和优化\n",
    "        loss_G = criterion(output, real_label)                              ## 得到的假的图片与真实的图片的label的loss\n",
    "        optimizer_G.zero_grad()                                             ## 梯度归0\n",
    "        loss_G.backward()                                                   ## 进行反向传播\n",
    "        optimizer_G.step()                                                  ## step()一般用在反向传播后面,用于更新生成网络的参数\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## 打印训练过程中的日志\n",
    "        ## item():取出单元素张量的元素值并返回该值，保持原元素类型不变\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [D real: %f] [D fake: %f]\"\n",
    "                % (epoch, 10, i, len(train_loader), loss_D.item(), loss_G.item(), real_scores.data.mean(), fake_scores.data.mean())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('cv_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4a9c97a8b021f57fd72049f636b97cda4a73e3b574c4423a7c228fa056b5e4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
