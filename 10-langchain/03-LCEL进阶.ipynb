{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL进阶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "set_debug(False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绑定常量参数\n",
    "有时，我们希望调用`Runnable`序列中的`Runnable`，其常量参数不属于序列中前面`Runnable`的输出，也不属于用户输入。我们可以使用[Runnable.bind()](https://api.python.langchain.com/en/latest/schema.runnable/langchain.schema.runnable.base.Runnable.html#langchain.schema.runnable.base.Runnable.bind)来传递这些参数。\n",
    "\n",
    "\n",
    "首先构建一个简单的`prompt + model`链条，以交互的方式引导用户提供一个等式，然后根据该等式进行求解。代码中使用了 `ChatPromptTemplate` 来定义交互模板，`ChatOpenAI` 模型进行对话，然后使用 `StrOutputParser` 解析输出结果（把响应作为字符串返回）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"x raised to the third plus seven equals 12\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<equation_statement>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"x raised to the third plus seven equals 12\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<equation_statement> > 3:chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"x raised to the third plus seven equals 12\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<equation_statement> > 3:chain:RunnablePassthrough] [19ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"x raised to the third plus seven equals 12\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<equation_statement>] [38ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"equation_statement\": \"x raised to the third plus seven equals 12\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"equation_statement\": \"x raised to the third plus seven equals 12\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] [20ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Write out the following equation using algebraic symbols then solve it. Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\\nHuman: x raised to the third plus seven equals 12\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 5:llm:ChatOpenAI] [2.03s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"EQUATION: \\\\(x^3 + 7 = 12\\\\)\\n\\nSOLUTION: \\nSubtracting 7 from both sides, we get:\\n\\\\(x^3 = 5\\\\)\\n\\nTaking the cube root of both sides, we find:\\n\\\\(x = \\\\sqrt[3]{5}\\\\)\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"EQUATION: \\\\(x^3 + 7 = 12\\\\)\\n\\nSOLUTION: \\nSubtracting 7 from both sides, we get:\\n\\\\(x^3 = 5\\\\)\\n\\nTaking the cube root of both sides, we find:\\n\\\\(x = \\\\sqrt[3]{5}\\\\)\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 63,\n",
      "      \"prompt_tokens\": 47,\n",
      "      \"total_tokens\": 110\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_3b956da36b\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 6:parser:StrOutputParser] [23ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"EQUATION: \\\\(x^3 + 7 = 12\\\\)\\n\\nSOLUTION: \\nSubtracting 7 from both sides, we get:\\n\\\\(x^3 = 5\\\\)\\n\\nTaking the cube root of both sides, we find:\\n\\\\(x = \\\\sqrt[3]{5}\\\\)\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [2.19s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"EQUATION: \\\\(x^3 + 7 = 12\\\\)\\n\\nSOLUTION: \\nSubtracting 7 from both sides, we get:\\n\\\\(x^3 = 5\\\\)\\n\\nTaking the cube root of both sides, we find:\\n\\\\(x = \\\\sqrt[3]{5}\\\\)\"\n",
      "}\n",
      "EQUATION: \\(x^3 + 7 = 12\\)\n",
      "\n",
      "SOLUTION: \n",
      "Subtracting 7 from both sides, we get:\n",
      "\\(x^3 = 5\\)\n",
      "\n",
      "Taking the cube root of both sides, we find:\n",
      "\\(x = \\sqrt[3]{5}\\)\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Write out the following equation using algebraic symbols then solve it. Use the format\\n\\nEQUATION:...\\nSOLUTION:...\\n\\n\"),\n",
    "    (\"human\", \"{equation_statement}\")\n",
    "])\n",
    "model = ChatOpenAI(temperature=0)\n",
    "runnable = (\n",
    "    {\"equation_statement\": RunnablePassthrough()} | prompt | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但有时候，我们想要在这个序列中的某一步向模型传递一些额外的参数，而这些参数并不是前一步输出的结果，也不是用户输入的一部分。这时候就可以使用 `RunnablePassthrough()` 来将这些常量参数传递给模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用`model.bind(stop=\"SOLUTION\")`，将一个名为 `stop` 的参数绑定到 `model` 可运行对象上，并传递值 \"SOLUTION\"。这样，模型在生成响应时，看到\"SOLUTION\"后就会停止响应，即求解等式后停止。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQUATION: x^3 + 7 = 12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runnable = (\n",
    "    {\"equation_statement\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model.bind(stop=\"SOLUTION\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，通过`bind`可以在不改变`Prompt`的情况下，在序列中的不同步骤中灵活地传递参数，修改模型的运行方式。这样的设计使得处理复杂的操作序列更加简洁和灵活。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附加OpenAI函数\n",
    "绑定的一个特别有用的应用是将OpenAI函数附加到兼容的OpenAI模型上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = {\n",
    "    \"name\": \"solver\",\n",
    "    \"description\": \"Formulates and solves an equation\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"equation\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The algebraic expression of the equation\",\n",
    "            },\n",
    "            \"solution\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The solution to the equation\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"equation\", \"solution\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'arguments': '{\\n\"equation\": \"x^3 + 7 = 12\",\\n\"solution\": \"x = ∛5\"\\n}',\n",
       "  'name': 'solver'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need gpt-4 to solve this one correctly\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Write out the following equation using algebraic symbols then solve it.\",\n",
    "        ),\n",
    "        (\"human\", \"{equation_statement}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-4\", temperature=0).bind(\n",
    "    function_call={\"name\": \"solver\"}, functions=[function]\n",
    ")\n",
    "runnable = {\"equation_statement\": RunnablePassthrough()} | prompt | model\n",
    "res = runnable.invoke(\"x raised to the third plus seven equals 12\")\n",
    "res.additional_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 附加OpenAI工具\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\").bind(tools=tools)\n",
    "res = model.invoke(\"What's the weather in SF, NYC and LA?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_calls': [{'id': 'call_LQMw4NLOJTLfYNhuVEPmmDr5',\n",
       "   'function': {'arguments': '{\"location\": \"San Francisco, CA\", \"unit\": \"celsius\"}',\n",
       "    'name': 'get_current_weather'},\n",
       "   'type': 'function'},\n",
       "  {'id': 'call_t1CIVo0HlGu12U4HdIEgCxtN',\n",
       "   'function': {'arguments': '{\"location\": \"New York, NY\", \"unit\": \"celsius\"}',\n",
       "    'name': 'get_current_weather'},\n",
       "   'type': 'function'},\n",
       "  {'id': 'call_LbO65il3Ft0512X4wke7nHmA',\n",
       "   'function': {'arguments': '{\"location\": \"Los Angeles, CA\", \"unit\": \"celsius\"}',\n",
       "    'name': 'get_current_weather'},\n",
       "   'type': 'function'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.additional_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableBinding 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Parrot', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 14, 'total_tokens': 16}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-de6af5ca-be8e-4f51-8346-555a666ba7ad-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBinding\n",
    "model = ChatOpenAI(temperature=0)\n",
    "runnable_binding = RunnableBinding(\n",
    "    bound=model,\n",
    "    kwargs={'stop': ['-']} # <-- Note the additional kwargs\n",
    ")\n",
    "runnable_binding.invoke('Say \"Parrot-MAGIC\"') # Should return `Parrot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置和自定义chain\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
