{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "ä»£ç†çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨è¯­è¨€æ¨¡å‹æ¥é€‰æ‹©è¦é‡‡å–çš„ä¸€ç³»åˆ—è¡ŒåŠ¨ã€‚åœ¨é“¾ä¸­ï¼Œä¸€ç³»åˆ—åŠ¨ä½œæ˜¯ç¡¬ç¼–ç çš„(ç”¨ä»£ç )ã€‚åœ¨ä»£ç†ä¸­ï¼Œè¯­è¨€æ¨¡å‹è¢«ç”¨ä½œæ¨ç†å¼•æ“ï¼Œä»¥ç¡®å®šä»¥ä½•ç§é¡ºåºé‡‡å–å“ªäº›æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: python-dotenv in /slurm/home/yrd/shaolab/daiyizheng/.conda/envs/langechain/lib/python3.10/site-packages (0.21.1)\n",
      "Collecting python-dotenv\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 0.21.1\n",
      "    Uninstalling python-dotenv-0.21.1:\n",
      "      Successfully uninstalled python-dotenv-0.21.1\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "è¦å¿«é€Ÿå¼€å§‹ä¸Agentsï¼Œè¯·æŸ¥çœ‹è¿™ä¸ªå…¥é—¨æŒ‡å—ã€‚è¿™åŒ…æ‹¬åˆå§‹åŒ–Agentã€åˆ›å»ºå·¥å…·å’Œæ·»åŠ å†…å­˜ç­‰åŸºç¡€çŸ¥è¯†ã€‚\n",
    "\n",
    "ä¸ºäº†æ›´å¥½åœ°ç†è§£Agentæ¡†æ¶ï¼Œè®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå…·æœ‰ä¸¤ä¸ªå·¥å…·çš„ä»£ç†:ä¸€ä¸ªç”¨äºåœ¨çº¿æŸ¥æ‰¾ï¼Œå¦ä¸€ä¸ªç”¨äºæŸ¥æ‰¾æˆ‘ä»¬åŠ è½½åˆ°ç´¢å¼•ä¸­çš„ç‰¹å®šæ•°æ®ã€‚\n",
    "\n",
    "è¿™å°†å‡è®¾ä½ æœ‰LLMå’Œæ£€ç´¢çš„çŸ¥è¯†ï¼Œæ‰€ä»¥å¦‚æœä½ è¿˜æ²¡æœ‰ç ”ç©¶è¿‡è¿™äº›éƒ¨åˆ†ï¼Œå»ºè®®ä½ è¿™æ ·åšã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: LangSmith\n",
    "\n",
    "æ ¹æ®å®šä¹‰ï¼ŒAgentåœ¨è¿”å›é¢å‘ç”¨æˆ·çš„è¾“å‡ºä¹‹å‰ï¼Œé‡‡å–ä¸€ä¸ªè‡ªç¡®å®šçš„ã€ä¾èµ–äºè¾“å…¥çš„æ­¥éª¤åºåˆ—ã€‚è¿™ä½¿å¾—è°ƒè¯•è¿™äº›ç³»ç»Ÿç‰¹åˆ«æ£˜æ‰‹ï¼Œå¯è§‚å¯Ÿæ€§ç‰¹åˆ«é‡è¦ã€‚LangSmithåœ¨è¿™ç§æƒ…å†µä¸‹ç‰¹åˆ«æœ‰ç”¨ã€‚\n",
    "\n",
    "å½“ä½¿ç”¨LangChainæ„å»ºæ—¶ï¼Œæ‰€æœ‰æ­¥éª¤éƒ½ä¼šè‡ªåŠ¨åœ¨LangSmithä¸­è¿›è¡Œè·Ÿè¸ªã€‚è¦è®¾ç½®LangSmithï¼Œæˆ‘ä»¬åªéœ€è¦è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š\n",
    "\n",
    "```bash\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_API_KEY=\"<your-api-key>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®šä¹‰å·¥å…·\n",
    "æˆ‘ä»¬é¦–å…ˆéœ€è¦åˆ›å»ºæˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„å·¥å…·ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸¤ä¸ªå·¥å…·:Tavily(ç”¨äºåœ¨çº¿æœç´¢)ï¼Œç„¶åæ˜¯æˆ‘ä»¬å°†åˆ›å»ºçš„æœ¬åœ°ç´¢å¼•çš„æ£€ç´¢å™¨\n",
    "#### Tavily\n",
    "æˆ‘ä»¬åœ¨LangChainä¸­æœ‰ä¸€ä¸ªå†…ç½®çš„å·¥å…·ï¼Œå¯ä»¥è½»æ¾åœ°ä½¿ç”¨Tavilyæœç´¢å¼•æ“ä½œä¸ºå·¥å…·ã€‚æ³¨æ„ï¼Œè¿™éœ€è¦ä¸€ä¸ªAPIå¯†é’¥â€”â€”å®ƒä»¬æœ‰ä¸€ä¸ªå…è´¹çš„å±‚ï¼Œä½†æ˜¯å¦‚æœä½ æ²¡æœ‰ä¸€ä¸ªæˆ–è€…ä¸æƒ³åˆ›å»ºä¸€ä¸ªï¼Œä½ å¯ä»¥å¿½ç•¥è¿™ä¸ªæ­¥éª¤ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"HTTPError('502 Server Error: Bad Gateway for url: https://api.tavily.com/search')\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = TavilySearchResults()\n",
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever\n",
    "æˆ‘ä»¬è¿˜å°†åœ¨æˆ‘ä»¬è‡ªå·±çš„ä¸€äº›æ•°æ®ä¸Šåˆ›å»ºä¸€ä¸ªæ£€ç´¢å™¨ã€‚æœ‰å…³è¿™é‡Œæ¯ä¸ªæ­¥éª¤çš„æ›´æ·±å…¥è§£é‡Šï¼Œè¯·å‚é˜…æœ¬èŠ‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "ç°åœ¨æˆ‘ä»¬å·²ç»åˆ›å»ºäº†è¿™ä¸¤ä¸ªå·¥å…·ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªå°†åœ¨ä¸‹æ¸¸ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the agent\n",
    "æ—¢ç„¶å·²ç»å®šä¹‰äº†å·¥å…·ï¼Œå°±å¯ä»¥åˆ›å»ºä»£ç†äº†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨OpenAI Functionsä»£ç†â€”æœ‰å…³è¿™ç§ç±»å‹çš„ä»£ç†ä»¥åŠå…¶ä»–é€‰é¡¹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æœ¬æŒ‡å—ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬é€‰æ‹©æˆ‘ä»¬æƒ³è¦å¼•å¯¼ä»£ç†çš„LLMã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€‰æ‹©è¦ç”¨æ¥å¼•å¯¼ä»£ç†çš„æç¤ºç¬¦ã€‚å¦‚æœæ‚¨æƒ³æŸ¥çœ‹æ­¤æç¤ºçš„å†…å®¹å¹¶è®¿é—®LangSmithï¼Œå¯ä»¥è½¬åˆ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨LLMã€æç¤ºç¬¦å’Œå·¥å…·åˆå§‹åŒ–Agentã€‚ä»£ç†è´Ÿè´£æ¥æ”¶è¾“å…¥å¹¶å†³å®šé‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼ŒAgentä¸æ‰§è¡Œè¿™äº›æ“ä½œâ€”â€”è¿™æ˜¯ç”±AgentExecutorå®Œæˆçš„(ä¸‹ä¸€æ­¥)ã€‚æœ‰å…³å¦‚ä½•è€ƒè™‘è¿™äº›ç»„ä»¶çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[æˆ‘ä»¬çš„æ¦‚å¿µæŒ‡å—](https://python.langchain.com/v0.1/docs/modules/agents/concepts/)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€åï¼Œæˆ‘ä»¬å°†Agent(å¤§è„‘)ä¸AgentExecutorå†…éƒ¨çš„å·¥å…·(å®ƒå°†é‡å¤è°ƒç”¨ä»£ç†å’Œæ‰§è¡Œå·¥å…·)ç»“åˆèµ·æ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the agent\n",
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥åœ¨å‡ ä¸ªæŸ¥è¯¢ä¸Šè¿è¡Œä»£ç†äº†!è¯·æ³¨æ„ï¼Œç›®å‰è¿™äº›éƒ½æ˜¯æ— çŠ¶æ€æŸ¥è¯¢(å®ƒä¸ä¼šè®°ä½ä»¥å‰çš„äº¤äº’)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmithâ€‹PythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API keyâ€‹To create an API key head to the Settings page. Then click Create API Key.3. Set up your environmentâ€‹Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first traceâ€‹We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
      "\n",
      "score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.\n",
      "\n",
      "\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, ensuring that you can ship quickly and with confidence. Here are some steps to get started with LangSmith for testing purposes:\n",
      "\n",
      "1. Install LangSmith using Python or TypeScript:\n",
      "   - Python: `pip install -U langsmith`\n",
      "   - TypeScript: `yarn add langchain langsmith`\n",
      "\n",
      "2. Create an API key:\n",
      "   - Head to the Settings page and click on Create API Key.\n",
      "\n",
      "3. Set up your environment:\n",
      "   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and `OPENAI_API_KEY`.\n",
      "\n",
      "4. Log your first trace:\n",
      "   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing your application.\n",
      "\n",
      "By following these steps and utilizing LangSmith's features, you can effectively test and evaluate your applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': \"LangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, ensuring that you can ship quickly and with confidence. Here are some steps to get started with LangSmith for testing purposes:\\n\\n1. Install LangSmith using Python or TypeScript:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on Create API Key.\\n\\n3. Set up your environment:\\n   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and `OPENAI_API_KEY`.\\n\\n4. Log your first trace:\\n   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing your application.\\n\\nBy following these steps and utilizing LangSmith's features, you can effectively test and evaluate your applications.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mHTTPError('502 Server Error: Bad Gateway for url: https://api.tavily.com/search')\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "responded: I encountered an issue while trying to retrieve the weather information for San Francisco. Let me try again.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mHTTPError('502 Server Error: Bad Gateway for url: https://api.tavily.com/search')\u001b[0m\u001b[32;1m\u001b[1;3mI apologize for the inconvenience, but it seems there is a technical issue preventing me from retrieving the weather information for San Francisco at the moment. Is there anything else I can assist you with?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': 'I apologize for the inconvenience, but it seems there is a technical issue preventing me from retrieving the weather information for San Francisco at the moment. Is there anything else I can assist you with?'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in memory\n",
    "å¦‚å‰æ‰€è¿°ï¼Œè¯¥ä»£ç†æ˜¯æ— çŠ¶æ€çš„ã€‚è¿™æ„å‘³ç€å®ƒä¸è®°å¾—ä»¥å‰çš„äº¤äº’ã€‚ä¸ºäº†ç»™å®ƒå†…å­˜ï¼Œæˆ‘ä»¬éœ€è¦ä¼ é€’ä¹‹å‰çš„èŠå¤©è®°å½•ã€‚æ³¨æ„:ç”±äºæˆ‘ä»¬ä½¿ç”¨çš„æç¤ºç¬¦ï¼Œå®ƒéœ€è¦è¢«ç§°ä¸ºèŠå¤©è®°å½•ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„æç¤ºç¬¦ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ”¹å˜é‡å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is bob',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob. How can I help you, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Bob. How can I help you, Bob?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬æƒ³è¦è‡ªåŠ¨è·Ÿè¸ªè¿™äº›æ¶ˆæ¯ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶å°è£…åœ¨   `RunnableWithMessageHistory`ä¸­ã€‚æœ‰å…³å¦‚ä½•ä½¿ç”¨å®ƒçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æœ¬æŒ‡å—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob! How can I assist you, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob! How can I assist you, Bob?'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom agent\n",
    "æœ¬æ‰‹å†Œå°†ä»‹ç»å¦‚ä½•åˆ›å»ºæ‚¨è‡ªå·±çš„è‡ªå®šä¹‰Agentã€‚\n",
    "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨OpenAIå·¥å…·è°ƒç”¨æ¥åˆ›å»ºè¿™ä¸ªä»£ç†ã€‚è¿™é€šå¸¸æ˜¯åˆ›å»ºä»£ç†çš„æœ€å¯é çš„æ–¹æ³•ã€‚æˆ‘ä»¬å°†é¦–å…ˆåˆ›å»ºå®ƒæ²¡æœ‰å†…å­˜ï¼Œä½†æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•æ·»åŠ å†…å­˜ã€‚å¯¹è¯éœ€è¦è®°å¿†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the LLM\n",
    "é¦–å…ˆï¼Œè®©æˆ‘ä»¬åŠ è½½å°†è¦ç”¨æ¥æ§åˆ¶Agentçš„è¯­è¨€æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€äº›è¦ä½¿ç”¨çš„å·¥å…·ã€‚è®©æˆ‘ä»¬ç¼–å†™ä¸€ä¸ªéå¸¸ç®€å•çš„Pythonå‡½æ•°æ¥è®¡ç®—ä¼ å…¥çš„å•è¯çš„é•¿åº¦\n",
    "\n",
    "æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨çš„å‡½æ•°docstringéå¸¸é‡è¦ã€‚åœ¨è¿™é‡Œé˜…è¯»æ›´å¤šå…³äºä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™ç§æƒ…å†µçš„ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "get_word_length.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt\n",
    "ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºæç¤ºç¬¦ã€‚å› ä¸ºOpenAIå‡½æ•°è°ƒç”¨é’ˆå¯¹å·¥å…·ä½¿ç”¨è¿›è¡Œäº†å¾®è°ƒï¼Œæ‰€ä»¥æˆ‘ä»¬å‡ ä¹ä¸éœ€è¦ä»»ä½•å…³äºå¦‚ä½•æ¨ç†æˆ–å¦‚ä½•è¾“å‡ºæ ¼å¼çš„è¯´æ˜ã€‚æˆ‘ä»¬åªæœ‰ä¸¤ä¸ªè¾“å…¥å˜é‡`:input`å’Œ`agent_scratchpad.input`åº”è¯¥æ˜¯åŒ…å«ç”¨æˆ·ç›®æ ‡çš„å­—ç¬¦ä¸²ã€‚`agent_scratchpad`æ˜¯ä¸€ä¸ªæ¶ˆæ¯åºåˆ—ï¼Œå…¶ä¸­åŒ…å«ä»¥å‰çš„Agentå·¥å…·è°ƒç”¨å’Œç›¸åº”çš„å·¥å…·è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bind tools to LLM\n",
    "Agentå¦‚ä½•çŸ¥é“å®ƒå¯ä»¥ä½¿ç”¨å“ªäº›å·¥å…·\n",
    "\n",
    "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¾èµ–äºOpenAIå·¥å…·è°ƒç”¨llmï¼Œå®ƒå°†å·¥å…·ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„å‚æ•°ï¼Œå¹¶ç»è¿‡ä¸“é—¨è®­ç»ƒï¼ŒçŸ¥é“ä½•æ—¶è°ƒç”¨è¿™äº›å·¥å…·ã€‚\n",
    "\n",
    "ä¸ºäº†å°†æˆ‘ä»¬çš„å·¥å…·ä¼ é€’ç»™Agentï¼Œæˆ‘ä»¬åªéœ€è¦å°†å®ƒä»¬æ ¼å¼åŒ–ä¸ºOpenAIå·¥å…·æ ¼å¼å¹¶å°†å®ƒä»¬ä¼ é€’ç»™æˆ‘ä»¬çš„æ¨¡å‹ã€‚(é€šè¿‡`bind`å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿æ¯æ¬¡è°ƒç”¨æ¨¡å‹æ—¶éƒ½ä¼ å…¥å‡½æ•°ã€‚)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Agent\n",
    "å°†è¿™äº›ç¢ç‰‡æ”¾åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥åˆ›å»ºAgentã€‚æˆ‘ä»¬å°†å¯¼å…¥ä¸¤ä¸ªæœ€åä¸€ä¸ªå®ç”¨ç¨‹åºåŠŸèƒ½ï¼šç”¨äºæ ¼å¼åŒ–ä¸­é—´æ­¥éª¤ï¼ˆAgentæ“ä½œï¼Œå·¥å…·è¾“å‡ºå¯¹ï¼‰çš„ç»„ä»¶ï¼Œä»¥è¾“å…¥å¯ä»¥å‘é€åˆ°æ¨¡å‹çš„è¾“å…¥æ¶ˆæ¯ï¼Œä»¥åŠå°†è¾“å‡ºæ¶ˆæ¯è½¬æ¢ä¸ºAgentæ“ä½œ/Agenté¥°é¢çš„ç»„ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'eudca'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"eudca\" has 5 letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-677cac1b-9d8e-412b-baa2-389f065086be', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'index': 0}])], tool_call_id='call_LnrHGcIohbUXNP3rNQa7tDSY')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-677cac1b-9d8e-412b-baa2-389f065086be', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'index': 0}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-677cac1b-9d8e-412b-baa2-389f065086be', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'index': 0}])], tool_call_id='call_LnrHGcIohbUXNP3rNQa7tDSY'), observation=5)],\n",
       "  'messages': [FunctionMessage(content='5', name='get_word_length')]},\n",
       " {'output': 'The word \"eudca\" has 5 letters.',\n",
       "  'messages': [AIMessage(content='The word \"eudca\" has 5 letters.')]}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"How many letters in the word eudca\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding memory\n",
    "å¤ªæ£’äº†ï¼Œæˆ‘ä»¬æœ‰ç»çºªäººäº†!ç„¶è€Œï¼Œè¿™ä¸ªä»£ç†æ˜¯æ— çŠ¶æ€çš„â€”â€”å®ƒä¸è®°å¾—ä»»ä½•å…³äºå…ˆå‰äº¤äº’çš„ä¿¡æ¯ã€‚è¿™æ„å‘³ç€ä½ ä¸èƒ½è½»æ˜“åœ°é—®åç»­é—®é¢˜ã€‚è®©æˆ‘ä»¬é€šè¿‡æ·»åŠ å†…å­˜æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\n",
    "\n",
    "ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦åšä¸¤ä»¶äº‹\n",
    "- åœ¨æç¤ºä¸­ä¸ºå†…å­˜å˜é‡æ·»åŠ ä¸€ä¸ªä½ç½®\n",
    "- è·Ÿè¸ªèŠå¤©è®°å½•\n",
    "\n",
    "é¦–å…ˆï¼Œè®©æˆ‘ä»¬åœ¨æç¤ºç¬¦ä¸­ä¸ºå†…å­˜æ·»åŠ ä¸€ä¸ªä½ç½®ã€‚æˆ‘ä»¬é€šè¿‡ä¸ºå¸¦æœ‰`chat_history`é”®çš„æ¶ˆæ¯æ·»åŠ å ä½ç¬¦æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æ³¨æ„ï¼Œæˆ‘ä»¬å°†å…¶æ”¾åœ¨æ–°ç”¨æˆ·è¾“å…¥çš„ä¸Šæ–¹(ä»¥éµå¾ªå¯¹è¯æµ)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"educa\" has 5 letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\"Educa\" is not a common English word. It seems to be a variation or abbreviation of the word \"education.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'is that a real word?',\n",
       " 'chat_history': [HumanMessage(content='how many letters in the word educa?'),\n",
       "  AIMessage(content='The word \"educa\" has 5 letters.')],\n",
       " 'output': '\"Educa\" is not a common English word. It seems to be a variation or abbreviation of the word \"education.\"'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = \"how many letters in the word educa?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "Streamingæ˜¯LLMåº”ç”¨ç¨‹åºçš„é‡è¦UXè€ƒè™‘å› ç´ ï¼Œä»£ç†ä¹Ÿä¸ä¾‹å¤–ã€‚ä½¿ç”¨ä»£ç†è¿›è¡Œæµå¤„ç†å˜å¾—æ›´åŠ å¤æ‚ï¼Œå› ä¸ºå®ƒä¸ä»…æ˜¯æ‚¨æƒ³è¦æµå¼ä¼ è¾“çš„æœ€ç»ˆç­”æ¡ˆçš„ä»¤ç‰Œï¼Œè€Œä¸”æ‚¨å¯èƒ½è¿˜æƒ³è¦æµå¼ä¼ è¾“ä»£ç†æ‰€é‡‡å–çš„ä¸­é—´æ­¥éª¤ã€‚\n",
    "\n",
    "æˆ‘ä»¬çš„Agentå°†ä½¿ç”¨å·¥å…·APIå¯¹å·¥å…·è¿›è¡Œè°ƒç”¨\n",
    "1. `where_cat_is_hiding`è¿”å›çŒ«è—èº«çš„ä½ç½®\n",
    "2. `get_items` åˆ—å‡ºå¯ä»¥åœ¨ç‰¹å®šä½ç½®æ‰¾åˆ°çš„é¡¹ç›®\n",
    "\n",
    "è¿™äº›å·¥å…·å°†å…è®¸æˆ‘ä»¬åœ¨æ›´æœ‰è¶£çš„æƒ…å†µä¸‹æ¢ç´¢æµï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒAgentå°†ä¸å¾—ä¸ä½¿ç”¨è¿™ä¸¤ç§å·¥å…·æ¥å›ç­”ä¸€äº›é—®é¢˜(ä¾‹å¦‚ï¼Œå›ç­”é—®é¢˜`what items are located where the cat is hiding?`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model\n",
    "æ³¨æ„æˆ‘ä»¬åœ¨LLMä¸Šè®¾ç½®äº†`streaming=True`ã€‚è¿™å°†å…è®¸æˆ‘ä»¬ä½¿ç”¨æµäº‹ä»¶APIä»Agentä¸­ä¼ è¾“ä»¤ç‰Œã€‚æ—§ç‰ˆæœ¬çš„LangChainéœ€è¦è¿™æ ·åšã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools\n",
    "æˆ‘ä»¬å®šä¹‰äº†ä¸¤ä¸ªå·¥å…·ï¼Œå®ƒä»¬ä¾èµ–äºèŠå¤©æ¨¡å‹æ¥ç”Ÿæˆè¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "@tool\n",
    "async def where_cat_is_hiding() -> str:\n",
    "    \"\"\"Where is the cat hiding right now?\"\"\"\n",
    "    return random.choice([\"under the bed\", \"on the shelf\"])\n",
    "\n",
    "\n",
    "@tool\n",
    "async def get_items(place: str) -> str:\n",
    "    \"\"\"Use this tool to look up which items are in the given place.\"\"\"\n",
    "    if \"bed\" in place:  # For under the bed\n",
    "        return \"socks, shoes and dust bunnies\"\n",
    "    if \"shelf\" in place:  # For 'shelf'\n",
    "        return \"books, penciles and pictures\"\n",
    "    else:  # if the agent decides to ask about a different place\n",
    "        return \"cat snacks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on the shelf'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await where_cat_is_hiding.ainvoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'books, penciles and pictures'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await get_items.ainvoke({\"place\": \"shelf\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the agent\n",
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åˆå§‹åŒ–OpenAIå·¥å…·ä»£ç†ã€‚\n",
    "\n",
    "> è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨`\"run_name\"=\"Agent\"`å°†`Agent`ä¸æˆ‘ä»¬çš„`Agent`å…³è”èµ·æ¥ã€‚æˆ‘ä»¬å°†åœ¨ç¨åçš„`astream_events`APIä¸­ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "print(prompt.messages) #-- to see the prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_items, where_cat_is_hiding]\n",
    "agent = create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n",
    "    {\"run_name\": \"Agent\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stream Intermediate Steps\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨`AgentExecutor`çš„`.stream`æ–¹æ³•å¯¹ä»£ç†çš„ä¸­é—´æ­¥éª¤è¿›è¡Œæµå¤„ç†ã€‚        \n",
    "`stream`çš„è¾“å‡ºåœ¨(åŠ¨ä½œã€è§‚å¯Ÿ)å¯¹ä¹‹é—´äº¤æ›¿è¿›è¡Œï¼Œå¦‚æœä»£ç†å®ç°äº†å…¶ç›®æ ‡ï¼Œæœ€åä»¥ç­”æ¡ˆç»“æŸã€‚\n",
    "\n",
    "çœ‹èµ·æ¥åƒè¿™æ ·ï¼š\n",
    "1. actions output\n",
    "2. observations output\n",
    "3. actions output\n",
    "4. observations output\n",
    "(ç»§ç»­ç›´åˆ°è¾¾åˆ°ç›®æ ‡)\n",
    "ç„¶åï¼Œå¦‚æœè¾¾åˆ°æœ€ç»ˆç›®æ ‡ï¼ŒAgentå°†è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚è¿™äº›äº§å‡ºçš„å†…å®¹æ€»ç»“åœ¨è¿™é‡Œ\n",
    "\n",
    "è¾“å‡º | å†…å®¹\n",
    "-- | --\n",
    "Actions | `actions` `agentaction`æˆ–å­ç±»ï¼Œ`messages`èŠå¤©æ¶ˆæ¯å¯¹åº”åŠ¨ä½œè°ƒç”¨\n",
    "Observations | `step` ä»£ç†åˆ°ç›®å‰ä¸ºæ­¢æ‰€åšçš„äº‹æƒ…çš„å†å²è®°å½•ï¼ŒåŒ…æ‹¬å½“å‰æ“ä½œåŠå…¶è§‚å¯Ÿã€å¸¦æœ‰å‡½æ•°è°ƒç”¨ç»“æœçš„`message`èŠå¤©æ¶ˆæ¯(ä¹Ÿç§°ä¸ºè§‚å¯Ÿ)\n",
    "Final answer | `output` `AgentFinish`ï¼Œ`messages`ä¸èŠå¤©æ¶ˆæ¯æœ€ç»ˆè¾“å‡º\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb å•å…ƒæ ¼ 67\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpprint\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m chunks \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhat\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms items are located where the cat is hiding?\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     chunks\u001b[39m.\u001b[39mappend(chunk)\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4698\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4692\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream\u001b[39m(\n\u001b[1;32m   4693\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4694\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4695\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4696\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4697\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4698\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream(\n\u001b[1;32m   4699\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4701\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4702\u001b[0m     ):\n\u001b[1;32m   4703\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Note: We use `pprint` to print only to depth 1, it makes it easier to see the output from a high level, before digging in.\n",
    "import pprint\n",
    "\n",
    "chunks = []\n",
    "\n",
    "async for chunk in agent_executor.astream(\n",
    "    {\"input\": \"what's items are located where the cat is hiding?\"}\n",
    "):\n",
    "    chunks.append(chunk)\n",
    "    print(\"------\")\n",
    "    pprint.pprint(chunk, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Messages\n",
    "\n",
    "æ‚¨å¯ä»¥ä»è¾“å‡ºè®¿é—®åº•å±‚æ¶ˆæ¯ã€‚åœ¨ä¸èŠå¤©åº”ç”¨ç¨‹åºä¸€èµ·å·¥ä½œæ—¶ï¼Œä½¿ç”¨æ¶ˆæ¯ä¼šå¾ˆå¥½â€”â€”å› ä¸ºä¸€åˆ‡éƒ½æ˜¯æ¶ˆæ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0][\"actions\"]\n",
    "for chunk in chunks:\n",
    "    print(chunk[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using AgentAction/Observation\n",
    "è¾“å‡ºè¿˜åœ¨`actions`å’Œ`steps`ä¸­åŒ…å«æ›´ä¸°å¯Œçš„ç»“æ„åŒ–ä¿¡æ¯ï¼Œè¿™åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½å¾ˆæœ‰ç”¨ï¼Œä½†ä¹Ÿå¯èƒ½æ›´éš¾è§£æã€‚\n",
    "\n",
    "æ³¨æ„:`AgentFinish`ä½œä¸ºæµæ–¹æ³•çš„ä¸€éƒ¨åˆ†ä¸å¯ç”¨ã€‚å¦‚æœè¿™æ˜¯ä½ æƒ³è¦æ·»åŠ çš„ä¸œè¥¿ï¼Œè¯·åœ¨githubä¸Šå¼€å§‹è®¨è®ºå¹¶è§£é‡Šä¸ºä»€ä¹ˆéœ€è¦å®ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb å•å…ƒæ ¼ 71\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhat\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms items are located where the cat is hiding?\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Agent Action\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mactions\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m chunk:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m chunk[\u001b[39m\"\u001b[39m\u001b[39mactions\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4698\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4692\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream\u001b[39m(\n\u001b[1;32m   4693\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4694\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4695\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4696\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4697\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4698\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream(\n\u001b[1;32m   4699\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4701\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4702\u001b[0m     ):\n\u001b[1;32m   4703\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "async for chunk in agent_executor.astream(\n",
    "    {\"input\": \"what's items are located where the cat is hiding?\"}\n",
    "):\n",
    "    # Agent Action\n",
    "    if \"actions\" in chunk:\n",
    "        for action in chunk[\"actions\"]:\n",
    "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
    "    # Observation\n",
    "    elif \"steps\" in chunk:\n",
    "        for step in chunk[\"steps\"]:\n",
    "            print(f\"Tool Result: `{step.observation}`\")\n",
    "    # Final result\n",
    "    elif \"output\" in chunk:\n",
    "        print(f'Final Output: {chunk[\"output\"]}')\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Streaming With Events\n",
    "å¦‚æœStreamingçš„é»˜è®¤è¡Œä¸ºä¸é€‚åˆæ‚¨çš„åº”ç”¨ç¨‹åºï¼Œè¯·ä½¿ç”¨Streamingäº‹ä»¶API(ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨éœ€è¦Streamingæ¥è‡ªAgentçš„å•ä¸ªä»¤ç‰Œæˆ–å·¥å…·ä¸­å‘ç”Ÿçš„è¡¨é¢æ­¥éª¤)ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬ä½¿ç”¨æ­¤APIæ¥æµå¼ä¼ è¾“ä»¥ä¸‹äº‹ä»¶ï¼š\n",
    "1. Agentä»è¾“å…¥å¼€å§‹\n",
    "2. Toolä»è¾“å…¥å¼€å§‹\n",
    "3. Toolè¾“å‡ºç»“æŸ\n",
    "4. é€ä¸ªä»¤ç‰ŒStream Agentçš„æœ€ç»ˆå›ç­”\n",
    "5. Agentç»“æŸè¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: Agent with input: {'input': 'where is the cat hiding? what items are in that location?'}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb å•å…ƒæ ¼ 73\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream_events(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhere is the cat hiding? what items are in that location?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mv1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     kind \u001b[39m=\u001b[39m event[\u001b[39m\"\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_chain_start\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4711\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream_events\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4705\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream_events\u001b[39m(\n\u001b[1;32m   4706\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4707\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4708\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4709\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4710\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[StreamEvent]:\n\u001b[0;32m-> 4711\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream_events(\n\u001b[1;32m   4712\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m   4713\u001b[0m     ):\n\u001b[1;32m   4714\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1137\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m root_name \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_name())\n\u001b[1;32m   1135\u001b[0m \u001b[39m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m log \u001b[39min\u001b[39;00m _astream_log_implementation(  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m   1140\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m   1141\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m   1142\u001b[0m     diff\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1143\u001b[0m     with_streamed_output_list\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1144\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1145\u001b[0m ):\n\u001b[1;32m   1146\u001b[0m     run_log \u001b[39m=\u001b[39m run_log \u001b[39m+\u001b[39m log\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m   1149\u001b[0m         \u001b[39m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:616\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     \u001b[39m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m         \u001b[39mawait\u001b[39;00m task\n\u001b[1;32m    617\u001b[0m     \u001b[39mexcept\u001b[39;00m asyncio\u001b[39m.\u001b[39mCancelledError:\n\u001b[1;32m    618\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:570\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    567\u001b[0m prev_final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m runnable\u001b[39m.\u001b[39mastream(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    571\u001b[0m     prev_final_output \u001b[39m=\u001b[39m final_output\n\u001b[1;32m    572\u001b[0m     \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[39mif\u001b[39;00m run_id \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[39m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[39m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39m:=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_map_by_run_id\u001b[39m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "    version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stream Events from within Tools\n",
    "å¦‚æœæ‚¨çš„å·¥å…·åˆ©ç”¨äº†LangChainå¯è¿è¡Œå¯¹è±¡(ä¾‹å¦‚ï¼ŒLCELé“¾ï¼Œllmï¼Œæ£€ç´¢å™¨ç­‰)ï¼Œå¹¶ä¸”æ‚¨ä¹Ÿå¸Œæœ›ä»è¿™äº›å¯¹è±¡ä¸­æµå¼å¤„ç†äº‹ä»¶ï¼Œåˆ™éœ€è¦ç¡®ä¿å›è°ƒè¢«æ­£ç¡®ä¼ æ’­ã€‚\n",
    "\n",
    "ä¸ºäº†äº†è§£å¦‚ä½•ä¼ é€’å›è°ƒï¼Œè®©æˆ‘ä»¬é‡æ–°å®ç°`get_item`å·¥å…·ï¼Œä½¿å…¶ä½¿ç”¨LLMå¹¶å°†å›è°ƒä¼ é€’ç»™è¯¥LLMã€‚è¯·éšæ„å°†å…¶è°ƒæ•´åˆ°æ‚¨çš„ç”¨ä¾‹ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def get_items(place: str, callbacks: Callbacks) -> str:  # <--- Accept callbacks\n",
    "    \"\"\"Use this tool to look up which items are in the given place.\"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Can you tell me what kind of items i might find in the following place: '{place}'. \"\n",
    "                \"List at least 3 such items separating them by a comma. And include a brief description of each item..\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    chain = template | model.with_config(\n",
    "        {\n",
    "            \"run_name\": \"Get Items LLM\",\n",
    "            \"tags\": [\"tool_llm\"],\n",
    "            \"callbacks\": callbacks,  # <-- Propagate callbacks\n",
    "        }\n",
    "    )\n",
    "    chunks = [chunk async for chunk in chain.astream({\"place\": place})]\n",
    "    return \"\".join(chunk.content for chunk in chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬åˆå§‹åŒ–ä»£ç†ï¼Œå¹¶æŸ¥çœ‹æ–°çš„è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: Agent with input: {'input': 'where is the cat hiding? what items are in that location?'}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb å•å…ƒæ ¼ 77\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m agent \u001b[39m=\u001b[39m create_openai_tools_agent(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     model\u001b[39m.\u001b[39mwith_config({\u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39magent_llm\u001b[39m\u001b[39m\"\u001b[39m]}), tools, prompt\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m agent_executor \u001b[39m=\u001b[39m AgentExecutor(agent\u001b[39m=\u001b[39magent, tools\u001b[39m=\u001b[39mtools)\u001b[39m.\u001b[39mwith_config(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mAgent\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream_events(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhere is the cat hiding? what items are in that location?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mv1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m ):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     kind \u001b[39m=\u001b[39m event[\u001b[39m\"\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_chain_start\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4711\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream_events\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4705\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream_events\u001b[39m(\n\u001b[1;32m   4706\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4707\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4708\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4709\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4710\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[StreamEvent]:\n\u001b[0;32m-> 4711\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream_events(\n\u001b[1;32m   4712\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m   4713\u001b[0m     ):\n\u001b[1;32m   4714\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1137\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m root_name \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_name())\n\u001b[1;32m   1135\u001b[0m \u001b[39m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m log \u001b[39min\u001b[39;00m _astream_log_implementation(  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m   1140\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m   1141\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m   1142\u001b[0m     diff\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1143\u001b[0m     with_streamed_output_list\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1144\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1145\u001b[0m ):\n\u001b[1;32m   1146\u001b[0m     run_log \u001b[39m=\u001b[39m run_log \u001b[39m+\u001b[39m log\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m   1149\u001b[0m         \u001b[39m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:616\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     \u001b[39m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m         \u001b[39mawait\u001b[39;00m task\n\u001b[1;32m    617\u001b[0m     \u001b[39mexcept\u001b[39;00m asyncio\u001b[39m.\u001b[39mCancelledError:\n\u001b[1;32m    618\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:570\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    567\u001b[0m prev_final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m runnable\u001b[39m.\u001b[39mastream(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    571\u001b[0m     prev_final_output \u001b[39m=\u001b[39m final_output\n\u001b[1;32m    572\u001b[0m     \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[39mif\u001b[39;00m run_id \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[39m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[39m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39m:=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_map_by_run_id\u001b[39m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "# print(prompt.messages) -- to see the prompt\n",
    "tools = [get_items, where_cat_is_hiding]\n",
    "agent = create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n",
    "    {\"run_name\": \"Agent\"}\n",
    ")\n",
    "\n",
    "async for event in agent_executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "    version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other aproaches\n",
    "Using `astream_log`\n",
    "\n",
    "> æ³¨æ„:ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨`astream_log`APIã€‚è¯¥APIç”Ÿæˆæ‰§è¡ŒæœŸé—´å‘ç”Ÿçš„æ‰€æœ‰äº‹ä»¶çš„ç»†ç²’åº¦æ—¥å¿—ã€‚æ—¥å¿—æ ¼å¼åŸºäºJSONPatchæ ‡å‡†ã€‚å®ƒæ˜¯ç²’åº¦çš„ï¼Œä½†æ˜¯éœ€è¦åŠªåŠ›å»è§£æã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬åˆ›å»ºäº†`astream_events `APIã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': 'ea35335b-3df7-4341-9234-e314539b4f64',\n",
      "            'logs': {},\n",
      "            'name': 'Agent',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableSequence',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '91c6b9e5-e383-4ad0-99f1-b99ae7a8633c',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'start_time': '2024-05-23T09:20:41.946+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '713978ba-8a78-4214-9092-05333a26a581',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableAssign<agent_scratchpad>',\n",
      "            'start_time': '2024-05-23T09:20:41.959+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'input': 'where is the cat hiding? what items are in that '\n",
      "                     'location?',\n",
      "            'intermediate_steps': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'b21dac7e-46bf-4dc9-9c90-83347621af1b',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableParallel<agent_scratchpad>',\n",
      "            'start_time': '2024-05-23T09:20:41.965+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'f1b4b8ce-3dc7-42c7-a0e0-6c88ae62c9ef',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableLambda',\n",
      "            'start_time': '2024-05-23T09:20:41.969+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['map:key:agent_scratchpad'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/RunnableLambda/streamed_output/-', 'value': []})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'agent_scratchpad': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'agent_scratchpad': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/final_output',\n",
      "  'value': {'output': []}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/end_time',\n",
      "  'value': '2024-05-23T09:20:41.973+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/final_output',\n",
      "  'value': {'agent_scratchpad': []}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/end_time',\n",
      "  'value': '2024-05-23T09:20:41.974+00:00'})\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "async for chunk in agent_executor.astream_log(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "):\n",
    "    print(chunk)\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™å¯èƒ½éœ€è¦ä¸€äº›é€»è¾‘æ¥è·å¾—ä¸€ä¸ªå¯è¡Œçš„æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "----\n",
      "/logs/RunnableSequence\n",
      "{'id': '08193882-b394-47b8-b03b-32063d836694', 'name': 'RunnableSequence', 'type': 'chain', 'tags': [], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.498+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>\n",
      "{'id': 'b58ea2b0-77e7-4bcb-b687-ce3f251962b8', 'name': 'RunnableAssign<agent_scratchpad>', 'type': 'chain', 'tags': ['seq:step:1'], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.507+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/streamed_output/-\n",
      "{'input': 'where is the cat hiding? what items are in that location?', 'intermediate_steps': []}\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>\n",
      "{'id': '542efb1f-1758-4cbb-81a5-3b503e52279b', 'name': 'RunnableParallel<agent_scratchpad>', 'type': 'chain', 'tags': [], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.510+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableLambda\n",
      "{'id': 'bc31b80d-1535-4fec-9356-17cb25e777d0', 'name': 'RunnableLambda', 'type': 'chain', 'tags': ['map:key:agent_scratchpad'], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.512+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableLambda/streamed_output/-\n",
      "[]\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>/streamed_output/-\n",
      "{'agent_scratchpad': []}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/streamed_output/-\n",
      "{'input': 'where is the cat hiding? what items are in that location?', 'intermediate_steps': [], 'agent_scratchpad': []}\n",
      "----\n",
      "/logs/RunnableLambda/end_time\n",
      "2024-05-23T09:21:14.514+00:00\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>/end_time\n",
      "2024-05-23T09:21:14.515+00:00\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/end_time\n",
      "2024-05-23T09:21:14.516+00:00\n",
      "----\n",
      "/logs/ChatPromptTemplate\n",
      "{'id': '8e0214c2-9c5b-456b-910f-e24dabe88fa8', 'name': 'ChatPromptTemplate', 'type': 'prompt', 'tags': ['seq:step:2'], 'metadata': {'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, 'start_time': '2024-05-23T09:21:14.518+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/ChatPromptTemplate/end_time\n",
      "2024-05-23T09:21:14.521+00:00\n",
      "----\n",
      "/logs/ChatOpenAI\n",
      "{'id': '721aeb46-4694-4b7e-9928-b9256add2d9c', 'name': 'ChatOpenAI', 'type': 'llm', 'tags': ['seq:step:3', 'agent_llm'], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.523+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/ChatOpenAI/end_time\n",
      "2024-05-23T09:21:17.776+00:00\n",
      "----\n",
      "/logs/RunnableSequence/end_time\n",
      "2024-05-23T09:21:17.778+00:00\n",
      "----\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb å•å…ƒæ ¼ 81\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m path_status \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream_log(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhere is the cat hiding? what items are in that location?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m chunk\u001b[39m.\u001b[39mops:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mif\u001b[39;00m op[\u001b[39m\"\u001b[39m\u001b[39mop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39madd\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:914\u001b[0m, in \u001b[0;36mRunnable.astream_log\u001b[0;34m(self, input, config, diff, with_streamed_output_list, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m stream \u001b[39m=\u001b[39m LogStreamCallbackHandler(\n\u001b[1;32m    901\u001b[0m     auto_close\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    902\u001b[0m     include_names\u001b[39m=\u001b[39minclude_names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     _schema_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moriginal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    911\u001b[0m \u001b[39m# Mypy isn't resolving the overloads here\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m# Likely an issue b/c `self` is being passed through\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39m# and it's can't map it to Runnable[Input,Output]?\u001b[39;00m\n\u001b[0;32m--> 914\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m _astream_log_implementation(  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    915\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    916\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m    917\u001b[0m     config,\n\u001b[1;32m    918\u001b[0m     diff\u001b[39m=\u001b[39mdiff,\n\u001b[1;32m    919\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    920\u001b[0m     with_streamed_output_list\u001b[39m=\u001b[39mwith_streamed_output_list,\n\u001b[1;32m    921\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    922\u001b[0m ):\n\u001b[1;32m    923\u001b[0m     \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:616\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     \u001b[39m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m         \u001b[39mawait\u001b[39;00m task\n\u001b[1;32m    617\u001b[0m     \u001b[39mexcept\u001b[39;00m asyncio\u001b[39m.\u001b[39mCancelledError:\n\u001b[1;32m    618\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:570\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    567\u001b[0m prev_final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m runnable\u001b[39m.\u001b[39mastream(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    571\u001b[0m     prev_final_output \u001b[39m=\u001b[39m final_output\n\u001b[1;32m    572\u001b[0m     \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4698\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4692\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream\u001b[39m(\n\u001b[1;32m   4693\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4694\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4695\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4696\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4697\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4698\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream(\n\u001b[1;32m   4699\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4701\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4702\u001b[0m     ):\n\u001b[1;32m   4703\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[39mif\u001b[39;00m run_id \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[39m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[39m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39m:=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_map_by_run_id\u001b[39m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "path_status = {}\n",
    "async for chunk in agent_executor.astream_log(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "):\n",
    "    for op in chunk.ops:\n",
    "        if op[\"op\"] == \"add\":\n",
    "            if op[\"path\"] not in path_status:\n",
    "                path_status[op[\"path\"]] = op[\"value\"]\n",
    "            else:\n",
    "                path_status[op[\"path\"]] += op[\"value\"]\n",
    "    print(op[\"path\"])\n",
    "    print(path_status.get(op[\"path\"]))\n",
    "    print(\"----\")\n",
    "    i += 1\n",
    "    if i > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `callbacks (Legacy)`\n",
    "\n",
    "streaming çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å›è°ƒã€‚å¦‚æœæ‚¨è¿˜åœ¨ä½¿ç”¨æ—§ç‰ˆæœ¬çš„LangChainå¹¶ä¸”æ— æ³•å‡çº§ï¼Œè¿™å¯èƒ½ä¼šå¾ˆæœ‰ç”¨ã€‚\n",
    "\n",
    "ä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªæ¨èçš„æ–¹æ³•ï¼Œå› ä¸º\n",
    "1. å¯¹äºå¤§å¤šæ•°åº”ç”¨ç¨‹åºï¼Œæ‚¨éœ€è¦åˆ›å»ºä¸¤ä¸ªworkerï¼Œå°†å›è°ƒå†™å…¥é˜Ÿåˆ—ï¼Œå¹¶è®©å¦ä¸€ä¸ªworkerä»é˜Ÿåˆ—ä¸­è¯»å–(å³ï¼Œå®ç°æ­¤å·¥ä½œå­˜åœ¨éšè—çš„å¤æ‚æ€§)ã€‚\n",
    "2. ç»“æŸäº‹ä»¶å¯èƒ½ç¼ºå°‘ä¸€äº›å…ƒæ•°æ®(ä¾‹å¦‚ï¼Œè¿è¡Œåç§°)ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨éœ€è¦é¢å¤–çš„å…ƒæ•°æ®ï¼Œæ‚¨åº”è¯¥ä»BaseTracerè€Œä¸æ˜¯AsyncCallbackHandlerç»§æ‰¿ï¼Œä»¥ä»è¿è¡Œ(ä¹Ÿç§°ä¸ºè·Ÿè¸ª)ä¸­è·å–ç›¸å…³ä¿¡æ¯ï¼Œæˆ–è€…æ ¹æ®è¿è¡Œidè‡ªå·±å®ç°èšåˆé€»è¾‘ã€‚\n",
    "3. æœ‰ä¸ä¸€è‡´çš„è¡Œä¸ºä¸å›è°ƒ(ä¾‹å¦‚ï¼Œå¦‚ä½•è¾“å…¥å’Œè¾“å‡ºç¼–ç )å–å†³äºä½ éœ€è¦è§£å†³çš„å›è°ƒç±»å‹ã€‚\n",
    "\n",
    "ä¸ºäº†ä¾¿äºè¯´æ˜ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢å®ç°äº†ä¸€ä¸ªå›è°ƒï¼Œè¯¥å›è°ƒæ˜¾ç¤ºäº†å¦‚ä½•é€ä¸ªä»¤ç‰Œè·å–æµã€‚æ‚¨å¯ä»¥æ ¹æ®åº”ç”¨ç¨‹åºçš„éœ€è¦éšæ„å®ç°å…¶ä»–å›è°ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, TypeVar, Union\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain_core.callbacks.base import AsyncCallbackHandler\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import ChatGenerationChunk, GenerationChunk, LLMResult\n",
    "\n",
    "# Here is a custom handler that will print the tokens to stdout.\n",
    "# Instead of printing to stdout you can send the data elsewhere; e.g., to a streaming API response\n",
    "\n",
    "\n",
    "class TokenByTokenHandler(AsyncCallbackHandler):\n",
    "    def __init__(self, tags_of_interest: List[str]) -> None:\n",
    "        \"\"\"A custom call back handler.\n",
    "\n",
    "        Args:\n",
    "            tags_of_interest: Only LLM tokens from models with these tags will be\n",
    "                              printed.\n",
    "        \"\"\"\n",
    "        self.tags_of_interest = tags_of_interest\n",
    "\n",
    "    async def on_chain_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        inputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when chain starts running.\"\"\"\n",
    "        print(\"on chain start: \")\n",
    "        print(inputs)\n",
    "\n",
    "    async def on_chain_end(\n",
    "        self,\n",
    "        outputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when chain ends running.\"\"\"\n",
    "        print(\"On chain end\")\n",
    "        print(outputs)\n",
    "\n",
    "    async def on_chat_model_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        messages: List[List[BaseMessage]],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when a chat model starts running.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if overlap_tags:\n",
    "            print(\",\".join(overlap_tags), end=\": \", flush=True)\n",
    "\n",
    "    def on_tool_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        input_str: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        inputs: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when tool starts running.\"\"\"\n",
    "        print(\"Tool start\")\n",
    "        print(serialized)\n",
    "\n",
    "    def on_tool_end(\n",
    "        self,\n",
    "        output: Any,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when tool ends running.\"\"\"\n",
    "        print(\"Tool end\")\n",
    "        print(str(output))\n",
    "\n",
    "    async def on_llm_end(\n",
    "        self,\n",
    "        response: LLMResult,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when LLM ends running.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if overlap_tags:\n",
    "            # Who can argue with beauty?\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "    def get_overlap_tags(self, tags: Optional[List[str]]) -> List[str]:\n",
    "        \"\"\"Check for overlap with filtered tags.\"\"\"\n",
    "        if not tags:\n",
    "            return []\n",
    "        return sorted(set(tags or []) & set(self.tags_of_interest or []))\n",
    "\n",
    "    async def on_llm_new_token(\n",
    "        self,\n",
    "        token: str,\n",
    "        *,\n",
    "        chunk: Optional[Union[GenerationChunk, ChatGenerationChunk]] = None,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if token and overlap_tags:\n",
    "            print(token, end=\"|\", flush=True)\n",
    "\n",
    "\n",
    "handler = TokenByTokenHandler(tags_of_interest=[\"tool_llm\", \"agent_llm\"])\n",
    "\n",
    "result = await agent_executor.ainvoke(\n",
    "    {\"input\": \"where is the cat hiding and what items can be found there?\"},\n",
    "    {\"callbacks\": [handler]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å°†Agentä½œä¸ºè¿­ä»£å™¨è¿è¡Œ\n",
    "å¯ä»¥å°†ä»£ç†ä½œä¸ºè¿­ä»£å™¨è¿è¡Œï¼Œä»¥ä¾¿æ ¹æ®éœ€è¦æ·»åŠ äººå·¥å¾ªç¯æ£€æŸ¥ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
