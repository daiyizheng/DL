{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "代理的核心思想是使用语言模型来选择要采取的一系列行动。在链中，一系列动作是硬编码的(用代码)。在代理中，语言模型被用作推理引擎，以确定以何种顺序采取哪些操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: python-dotenv in /slurm/home/yrd/shaolab/daiyizheng/.conda/envs/langechain/lib/python3.10/site-packages (0.21.1)\n",
      "Collecting python-dotenv\n",
      "  Using cached https://mirrors.aliyun.com/pypi/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 0.21.1\n",
      "    Uninstalling python-dotenv-0.21.1:\n",
      "      Successfully uninstalled python-dotenv-0.21.1\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "要快速开始与Agents，请查看这个入门指南。这包括初始化Agent、创建工具和添加内存等基础知识。\n",
    "\n",
    "为了更好地理解Agent框架，让我们构建一个具有两个工具的代理:一个用于在线查找，另一个用于查找我们加载到索引中的特定数据。\n",
    "\n",
    "这将假设你有LLM和检索的知识，所以如果你还没有研究过这些部分，建议你这样做。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: LangSmith\n",
    "\n",
    "根据定义，Agent在返回面向用户的输出之前，采取一个自确定的、依赖于输入的步骤序列。这使得调试这些系统特别棘手，可观察性特别重要。LangSmith在这种情况下特别有用。\n",
    "\n",
    "当使用LangChain构建时，所有步骤都会自动在LangSmith中进行跟踪。要设置LangSmith，我们只需要设置以下环境变量：\n",
    "\n",
    "```bash\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_API_KEY=\"<your-api-key>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义工具\n",
    "我们首先需要创建我们想要使用的工具。我们将使用两个工具:Tavily(用于在线搜索)，然后是我们将创建的本地索引的检索器\n",
    "#### Tavily\n",
    "我们在LangChain中有一个内置的工具，可以轻松地使用Tavily搜索引擎作为工具。注意，这需要一个API密钥——它们有一个免费的层，但是如果你没有一个或者不想创建一个，你可以忽略这个步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"HTTPError('502 Server Error: Bad Gateway for url: https://api.tavily.com/search')\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = TavilySearchResults()\n",
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever\n",
    "我们还将在我们自己的一些数据上创建一个检索器。有关这里每个步骤的更深入解释，请参阅本节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "现在我们已经创建了这两个工具，我们可以创建一个将在下游使用的工具列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the agent\n",
    "既然已经定义了工具，就可以创建代理了。我们将使用OpenAI Functions代理—有关这种类型的代理以及其他选项的更多信息，请参阅本指南。\n",
    "\n",
    "首先，我们选择我们想要引导代理的LLM。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们选择要用来引导代理的提示符。如果您想查看此提示的内容并访问LangSmith，可以转到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们可以用LLM、提示符和工具初始化Agent。代理负责接收输入并决定采取什么行动。至关重要的是，Agent不执行这些操作——这是由AgentExecutor完成的(下一步)。有关如何考虑这些组件的更多信息，请参阅[我们的概念指南](https://python.langchain.com/v0.1/docs/modules/agents/concepts/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们将Agent(大脑)与AgentExecutor内部的工具(它将重复调用代理和执行工具)结合起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the agent\n",
    "现在我们可以在几个查询上运行代理了!请注意，目前这些都是无状态查询(它不会记住以前的交互)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith​PythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key​To create an API key head to the Settings page. Then click Create API Key.3. Set up your environment​Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace​We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
      "\n",
      "score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?You can leave detailed feedback on GitHub.NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n",
      "\n",
      "\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, ensuring that you can ship quickly and with confidence. Here are some steps to get started with LangSmith for testing purposes:\n",
      "\n",
      "1. Install LangSmith using Python or TypeScript:\n",
      "   - Python: `pip install -U langsmith`\n",
      "   - TypeScript: `yarn add langchain langsmith`\n",
      "\n",
      "2. Create an API key:\n",
      "   - Head to the Settings page and click on Create API Key.\n",
      "\n",
      "3. Set up your environment:\n",
      "   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and `OPENAI_API_KEY`.\n",
      "\n",
      "4. Log your first trace:\n",
      "   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing your application.\n",
      "\n",
      "By following these steps and utilizing LangSmith's features, you can effectively test and evaluate your applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': \"LangSmith can help with testing by providing a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, ensuring that you can ship quickly and with confidence. Here are some steps to get started with LangSmith for testing purposes:\\n\\n1. Install LangSmith using Python or TypeScript:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langchain langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on Create API Key.\\n\\n3. Set up your environment:\\n   - Export the necessary environment variables like `LANGCHAIN_TRACING_V2`, `LANGCHAIN_API_KEY`, and `OPENAI_API_KEY`.\\n\\n4. Log your first trace:\\n   - LangSmith provides multiple ways to log traces. You can log your first trace to start testing your application.\\n\\nBy following these steps and utilizing LangSmith's features, you can effectively test and evaluate your applications.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mHTTPError('502 Server Error: Bad Gateway for url: https://api.tavily.com/search')\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "responded: I encountered an issue while trying to retrieve the weather information for San Francisco. Let me try again.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mHTTPError('502 Server Error: Bad Gateway for url: https://api.tavily.com/search')\u001b[0m\u001b[32;1m\u001b[1;3mI apologize for the inconvenience, but it seems there is a technical issue preventing me from retrieving the weather information for San Francisco at the moment. Is there anything else I can assist you with?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': 'I apologize for the inconvenience, but it seems there is a technical issue preventing me from retrieving the weather information for San Francisco at the moment. Is there anything else I can assist you with?'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in memory\n",
    "如前所述，该代理是无状态的。这意味着它不记得以前的交互。为了给它内存，我们需要传递之前的聊天记录。注意:由于我们使用的提示符，它需要被称为聊天记录。如果我们使用不同的提示符，我们可以更改变量名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is bob',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob. How can I help you, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Bob. How can I help you, Bob?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们想要自动跟踪这些消息，我们可以将其封装在   `RunnableWithMessageHistory`中。有关如何使用它的更多信息，请参阅本指南。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob! How can I assist you, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob! How can I assist you, Bob?'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom agent\n",
    "本手册将介绍如何创建您自己的自定义Agent。\n",
    "在这个例子中，我们将使用OpenAI工具调用来创建这个代理。这通常是创建代理的最可靠的方法。我们将首先创建它没有内存，但我们将展示如何添加内存。对话需要记忆。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the LLM\n",
    "首先，让我们加载将要用来控制Agent的语言模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools\n",
    "\n",
    "接下来，让我们定义一些要使用的工具。让我们编写一个非常简单的Python函数来计算传入的单词的长度\n",
    "\n",
    "注意，这里我们使用的函数docstring非常重要。在这里阅读更多关于为什么会出现这种情况的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "get_word_length.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt\n",
    "现在让我们创建提示符。因为OpenAI函数调用针对工具使用进行了微调，所以我们几乎不需要任何关于如何推理或如何输出格式的说明。我们只有两个输入变量`:input`和`agent_scratchpad.input`应该是包含用户目标的字符串。`agent_scratchpad`是一个消息序列，其中包含以前的Agent工具调用和相应的工具输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bind tools to LLM\n",
    "Agent如何知道它可以使用哪些工具\n",
    "\n",
    "在这种情况下，我们依赖于OpenAI工具调用llm，它将工具作为一个单独的参数，并经过专门训练，知道何时调用这些工具。\n",
    "\n",
    "为了将我们的工具传递给Agent，我们只需要将它们格式化为OpenAI工具格式并将它们传递给我们的模型。(通过`bind`函数，我们可以确保每次调用模型时都传入函数。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Agent\n",
    "将这些碎片放在一起，我们现在可以创建Agent。我们将导入两个最后一个实用程序功能：用于格式化中间步骤（Agent操作，工具输出对）的组件，以输入可以发送到模型的输入消息，以及将输出消息转换为Agent操作/Agent饰面的组件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'eudca'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"eudca\" has 5 letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-677cac1b-9d8e-412b-baa2-389f065086be', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'index': 0}])], tool_call_id='call_LnrHGcIohbUXNP3rNQa7tDSY')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-677cac1b-9d8e-412b-baa2-389f065086be', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'index': 0}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'function': {'arguments': '{\"word\":\"eudca\"}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-677cac1b-9d8e-412b-baa2-389f065086be', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\"word\":\"eudca\"}', 'id': 'call_LnrHGcIohbUXNP3rNQa7tDSY', 'index': 0}])], tool_call_id='call_LnrHGcIohbUXNP3rNQa7tDSY'), observation=5)],\n",
       "  'messages': [FunctionMessage(content='5', name='get_word_length')]},\n",
       " {'output': 'The word \"eudca\" has 5 letters.',\n",
       "  'messages': [AIMessage(content='The word \"eudca\" has 5 letters.')]}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(agent_executor.stream({\"input\": \"How many letters in the word eudca\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding memory\n",
    "太棒了，我们有经纪人了!然而，这个代理是无状态的——它不记得任何关于先前交互的信息。这意味着你不能轻易地问后续问题。让我们通过添加内存来解决这个问题。\n",
    "\n",
    "为了做到这一点，我们需要做两件事\n",
    "- 在提示中为内存变量添加一个位置\n",
    "- 跟踪聊天记录\n",
    "\n",
    "首先，让我们在提示符中为内存添加一个位置。我们通过为带有`chat_history`键的消息添加占位符来实现这一点。注意，我们将其放在新用户输入的上方(以遵循对话流)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'educa'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThe word \"educa\" has 5 letters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\"Educa\" is not a common English word. It seems to be a variation or abbreviation of the word \"education.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'is that a real word?',\n",
       " 'chat_history': [HumanMessage(content='how many letters in the word educa?'),\n",
       "  AIMessage(content='The word \"educa\" has 5 letters.')],\n",
       " 'output': '\"Educa\" is not a common English word. It seems to be a variation or abbreviation of the word \"education.\"'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = \"how many letters in the word educa?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "Streaming是LLM应用程序的重要UX考虑因素，代理也不例外。使用代理进行流处理变得更加复杂，因为它不仅是您想要流式传输的最终答案的令牌，而且您可能还想要流式传输代理所采取的中间步骤。\n",
    "\n",
    "我们的Agent将使用工具API对工具进行调用\n",
    "1. `where_cat_is_hiding`返回猫藏身的位置\n",
    "2. `get_items` 列出可以在特定位置找到的项目\n",
    "\n",
    "这些工具将允许我们在更有趣的情况下探索流，在这种情况下，Agent将不得不使用这两种工具来回答一些问题(例如，回答问题`what items are located where the cat is hiding?`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model\n",
    "注意我们在LLM上设置了`streaming=True`。这将允许我们使用流事件API从Agent中传输令牌。旧版本的LangChain需要这样做。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools\n",
    "我们定义了两个工具，它们依赖于聊天模型来生成输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "@tool\n",
    "async def where_cat_is_hiding() -> str:\n",
    "    \"\"\"Where is the cat hiding right now?\"\"\"\n",
    "    return random.choice([\"under the bed\", \"on the shelf\"])\n",
    "\n",
    "\n",
    "@tool\n",
    "async def get_items(place: str) -> str:\n",
    "    \"\"\"Use this tool to look up which items are in the given place.\"\"\"\n",
    "    if \"bed\" in place:  # For under the bed\n",
    "        return \"socks, shoes and dust bunnies\"\n",
    "    if \"shelf\" in place:  # For 'shelf'\n",
    "        return \"books, penciles and pictures\"\n",
    "    else:  # if the agent decides to ask about a different place\n",
    "        return \"cat snacks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on the shelf'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await where_cat_is_hiding.ainvoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'books, penciles and pictures'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await get_items.ainvoke({\"place\": \"shelf\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the agent\n",
    "在这里，我们将初始化OpenAI工具代理。\n",
    "\n",
    "> 请注意，我们使用`\"run_name\"=\"Agent\"`将`Agent`与我们的`Agent`关联起来。我们将在稍后的`astream_events`API中使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "print(prompt.messages) #-- to see the prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_items, where_cat_is_hiding]\n",
    "agent = create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n",
    "    {\"run_name\": \"Agent\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stream Intermediate Steps\n",
    "我们将使用`AgentExecutor`的`.stream`方法对代理的中间步骤进行流处理。        \n",
    "`stream`的输出在(动作、观察)对之间交替进行，如果代理实现了其目标，最后以答案结束。\n",
    "\n",
    "看起来像这样：\n",
    "1. actions output\n",
    "2. observations output\n",
    "3. actions output\n",
    "4. observations output\n",
    "(继续直到达到目标)\n",
    "然后，如果达到最终目标，Agent将输出最终答案。这些产出的内容总结在这里\n",
    "\n",
    "输出 | 内容\n",
    "-- | --\n",
    "Actions | `actions` `agentaction`或子类，`messages`聊天消息对应动作调用\n",
    "Observations | `step` 代理到目前为止所做的事情的历史记录，包括当前操作及其观察、带有函数调用结果的`message`聊天消息(也称为观察)\n",
    "Final answer | `output` `AgentFinish`，`messages`与聊天消息最终输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb 单元格 67\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpprint\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m chunks \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhat\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms items are located where the cat is hiding?\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     chunks\u001b[39m.\u001b[39mappend(chunk)\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4698\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4692\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream\u001b[39m(\n\u001b[1;32m   4693\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4694\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4695\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4696\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4697\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4698\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream(\n\u001b[1;32m   4699\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4701\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4702\u001b[0m     ):\n\u001b[1;32m   4703\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Note: We use `pprint` to print only to depth 1, it makes it easier to see the output from a high level, before digging in.\n",
    "import pprint\n",
    "\n",
    "chunks = []\n",
    "\n",
    "async for chunk in agent_executor.astream(\n",
    "    {\"input\": \"what's items are located where the cat is hiding?\"}\n",
    "):\n",
    "    chunks.append(chunk)\n",
    "    print(\"------\")\n",
    "    pprint.pprint(chunk, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Messages\n",
    "\n",
    "您可以从输出访问底层消息。在与聊天应用程序一起工作时，使用消息会很好——因为一切都是消息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0][\"actions\"]\n",
    "for chunk in chunks:\n",
    "    print(chunk[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using AgentAction/Observation\n",
    "输出还在`actions`和`steps`中包含更丰富的结构化信息，这在某些情况下可能很有用，但也可能更难解析。\n",
    "\n",
    "注意:`AgentFinish`作为流方法的一部分不可用。如果这是你想要添加的东西，请在github上开始讨论并解释为什么需要它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb 单元格 71\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhat\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms items are located where the cat is hiding?\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Agent Action\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mactions\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m chunk:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m chunk[\u001b[39m\"\u001b[39m\u001b[39mactions\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4698\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4692\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream\u001b[39m(\n\u001b[1;32m   4693\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4694\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4695\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4696\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4697\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4698\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream(\n\u001b[1;32m   4699\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4701\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4702\u001b[0m     ):\n\u001b[1;32m   4703\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "async for chunk in agent_executor.astream(\n",
    "    {\"input\": \"what's items are located where the cat is hiding?\"}\n",
    "):\n",
    "    # Agent Action\n",
    "    if \"actions\" in chunk:\n",
    "        for action in chunk[\"actions\"]:\n",
    "            print(f\"Calling Tool: `{action.tool}` with input `{action.tool_input}`\")\n",
    "    # Observation\n",
    "    elif \"steps\" in chunk:\n",
    "        for step in chunk[\"steps\"]:\n",
    "            print(f\"Tool Result: `{step.observation}`\")\n",
    "    # Final result\n",
    "    elif \"output\" in chunk:\n",
    "        print(f'Final Output: {chunk[\"output\"]}')\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Streaming With Events\n",
    "如果Streaming的默认行为不适合您的应用程序，请使用Streaming事件API(例如，如果您需要Streaming来自Agent的单个令牌或工具中发生的表面步骤)。\n",
    "\n",
    "让我们使用此API来流式传输以下事件：\n",
    "1. Agent从输入开始\n",
    "2. Tool从输入开始\n",
    "3. Tool输出结束\n",
    "4. 逐个令牌Stream Agent的最终回答\n",
    "5. Agent结束输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: Agent with input: {'input': 'where is the cat hiding? what items are in that location?'}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb 单元格 73\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream_events(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhere is the cat hiding? what items are in that location?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mv1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     kind \u001b[39m=\u001b[39m event[\u001b[39m\"\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_chain_start\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4711\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream_events\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4705\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream_events\u001b[39m(\n\u001b[1;32m   4706\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4707\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4708\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4709\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4710\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[StreamEvent]:\n\u001b[0;32m-> 4711\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream_events(\n\u001b[1;32m   4712\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m   4713\u001b[0m     ):\n\u001b[1;32m   4714\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1137\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m root_name \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_name())\n\u001b[1;32m   1135\u001b[0m \u001b[39m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m log \u001b[39min\u001b[39;00m _astream_log_implementation(  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m   1140\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m   1141\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m   1142\u001b[0m     diff\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1143\u001b[0m     with_streamed_output_list\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1144\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1145\u001b[0m ):\n\u001b[1;32m   1146\u001b[0m     run_log \u001b[39m=\u001b[39m run_log \u001b[39m+\u001b[39m log\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m   1149\u001b[0m         \u001b[39m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:616\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     \u001b[39m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m         \u001b[39mawait\u001b[39;00m task\n\u001b[1;32m    617\u001b[0m     \u001b[39mexcept\u001b[39;00m asyncio\u001b[39m.\u001b[39mCancelledError:\n\u001b[1;32m    618\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:570\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    567\u001b[0m prev_final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m runnable\u001b[39m.\u001b[39mastream(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    571\u001b[0m     prev_final_output \u001b[39m=\u001b[39m final_output\n\u001b[1;32m    572\u001b[0m     \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[39mif\u001b[39;00m run_id \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[39m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[39m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39m:=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_map_by_run_id\u001b[39m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "    version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stream Events from within Tools\n",
    "如果您的工具利用了LangChain可运行对象(例如，LCEL链，llm，检索器等)，并且您也希望从这些对象中流式处理事件，则需要确保回调被正确传播。\n",
    "\n",
    "为了了解如何传递回调，让我们重新实现`get_item`工具，使其使用LLM并将回调传递给该LLM。请随意将其调整到您的用例中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def get_items(place: str, callbacks: Callbacks) -> str:  # <--- Accept callbacks\n",
    "    \"\"\"Use this tool to look up which items are in the given place.\"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Can you tell me what kind of items i might find in the following place: '{place}'. \"\n",
    "                \"List at least 3 such items separating them by a comma. And include a brief description of each item..\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    chain = template | model.with_config(\n",
    "        {\n",
    "            \"run_name\": \"Get Items LLM\",\n",
    "            \"tags\": [\"tool_llm\"],\n",
    "            \"callbacks\": callbacks,  # <-- Propagate callbacks\n",
    "        }\n",
    "    )\n",
    "    chunks = [chunk async for chunk in chain.astream({\"place\": place})]\n",
    "    return \"\".join(chunk.content for chunk in chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们初始化代理，并查看新的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: Agent with input: {'input': 'where is the cat hiding? what items are in that location?'}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb 单元格 77\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m agent \u001b[39m=\u001b[39m create_openai_tools_agent(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     model\u001b[39m.\u001b[39mwith_config({\u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39magent_llm\u001b[39m\u001b[39m\"\u001b[39m]}), tools, prompt\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m agent_executor \u001b[39m=\u001b[39m AgentExecutor(agent\u001b[39m=\u001b[39magent, tools\u001b[39m=\u001b[39mtools)\u001b[39m.\u001b[39mwith_config(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mAgent\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream_events(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhere is the cat hiding? what items are in that location?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mv1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m ):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     kind \u001b[39m=\u001b[39m event[\u001b[39m\"\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y210sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_chain_start\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4711\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream_events\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4705\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream_events\u001b[39m(\n\u001b[1;32m   4706\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4707\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4708\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4709\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4710\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[StreamEvent]:\n\u001b[0;32m-> 4711\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream_events(\n\u001b[1;32m   4712\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m   4713\u001b[0m     ):\n\u001b[1;32m   4714\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1137\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m root_name \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_name())\n\u001b[1;32m   1135\u001b[0m \u001b[39m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m log \u001b[39min\u001b[39;00m _astream_log_implementation(  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m   1140\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m   1141\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m   1142\u001b[0m     diff\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1143\u001b[0m     with_streamed_output_list\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1144\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1145\u001b[0m ):\n\u001b[1;32m   1146\u001b[0m     run_log \u001b[39m=\u001b[39m run_log \u001b[39m+\u001b[39m log\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m   1149\u001b[0m         \u001b[39m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:616\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     \u001b[39m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m         \u001b[39mawait\u001b[39;00m task\n\u001b[1;32m    617\u001b[0m     \u001b[39mexcept\u001b[39;00m asyncio\u001b[39m.\u001b[39mCancelledError:\n\u001b[1;32m    618\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:570\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    567\u001b[0m prev_final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m runnable\u001b[39m.\u001b[39mastream(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    571\u001b[0m     prev_final_output \u001b[39m=\u001b[39m final_output\n\u001b[1;32m    572\u001b[0m     \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[39mif\u001b[39;00m run_id \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[39m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[39m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39m:=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_map_by_run_id\u001b[39m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "# print(prompt.messages) -- to see the prompt\n",
    "tools = [get_items, where_cat_is_hiding]\n",
    "agent = create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n",
    "    {\"run_name\": \"Agent\"}\n",
    ")\n",
    "\n",
    "async for event in agent_executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "    version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other aproaches\n",
    "Using `astream_log`\n",
    "\n",
    "> 注意:你也可以使用`astream_log`API。该API生成执行期间发生的所有事件的细粒度日志。日志格式基于JSONPatch标准。它是粒度的，但是需要努力去解析。出于这个原因，我们创建了`astream_events `API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': 'ea35335b-3df7-4341-9234-e314539b4f64',\n",
      "            'logs': {},\n",
      "            'name': 'Agent',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableSequence',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '91c6b9e5-e383-4ad0-99f1-b99ae7a8633c',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'start_time': '2024-05-23T09:20:41.946+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '713978ba-8a78-4214-9092-05333a26a581',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableAssign<agent_scratchpad>',\n",
      "            'start_time': '2024-05-23T09:20:41.959+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'input': 'where is the cat hiding? what items are in that '\n",
      "                     'location?',\n",
      "            'intermediate_steps': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'b21dac7e-46bf-4dc9-9c90-83347621af1b',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableParallel<agent_scratchpad>',\n",
      "            'start_time': '2024-05-23T09:20:41.965+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'f1b4b8ce-3dc7-42c7-a0e0-6c88ae62c9ef',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableLambda',\n",
      "            'start_time': '2024-05-23T09:20:41.969+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['map:key:agent_scratchpad'],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/RunnableLambda/streamed_output/-', 'value': []})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'agent_scratchpad': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<agent_scratchpad>/streamed_output/-',\n",
      "  'value': {'agent_scratchpad': []}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/final_output',\n",
      "  'value': {'output': []}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/end_time',\n",
      "  'value': '2024-05-23T09:20:41.973+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/final_output',\n",
      "  'value': {'agent_scratchpad': []}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<agent_scratchpad>/end_time',\n",
      "  'value': '2024-05-23T09:20:41.974+00:00'})\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "async for chunk in agent_executor.astream_log(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "):\n",
    "    print(chunk)\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这可能需要一些逻辑来获得一个可行的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "----\n",
      "/logs/RunnableSequence\n",
      "{'id': '08193882-b394-47b8-b03b-32063d836694', 'name': 'RunnableSequence', 'type': 'chain', 'tags': [], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.498+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>\n",
      "{'id': 'b58ea2b0-77e7-4bcb-b687-ce3f251962b8', 'name': 'RunnableAssign<agent_scratchpad>', 'type': 'chain', 'tags': ['seq:step:1'], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.507+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/streamed_output/-\n",
      "{'input': 'where is the cat hiding? what items are in that location?', 'intermediate_steps': []}\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>\n",
      "{'id': '542efb1f-1758-4cbb-81a5-3b503e52279b', 'name': 'RunnableParallel<agent_scratchpad>', 'type': 'chain', 'tags': [], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.510+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableLambda\n",
      "{'id': 'bc31b80d-1535-4fec-9356-17cb25e777d0', 'name': 'RunnableLambda', 'type': 'chain', 'tags': ['map:key:agent_scratchpad'], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.512+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/RunnableLambda/streamed_output/-\n",
      "[]\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>/streamed_output/-\n",
      "{'agent_scratchpad': []}\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/streamed_output/-\n",
      "{'input': 'where is the cat hiding? what items are in that location?', 'intermediate_steps': [], 'agent_scratchpad': []}\n",
      "----\n",
      "/logs/RunnableLambda/end_time\n",
      "2024-05-23T09:21:14.514+00:00\n",
      "----\n",
      "/logs/RunnableParallel<agent_scratchpad>/end_time\n",
      "2024-05-23T09:21:14.515+00:00\n",
      "----\n",
      "/logs/RunnableAssign<agent_scratchpad>/end_time\n",
      "2024-05-23T09:21:14.516+00:00\n",
      "----\n",
      "/logs/ChatPromptTemplate\n",
      "{'id': '8e0214c2-9c5b-456b-910f-e24dabe88fa8', 'name': 'ChatPromptTemplate', 'type': 'prompt', 'tags': ['seq:step:2'], 'metadata': {'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, 'start_time': '2024-05-23T09:21:14.518+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/ChatPromptTemplate/end_time\n",
      "2024-05-23T09:21:14.521+00:00\n",
      "----\n",
      "/logs/ChatOpenAI\n",
      "{'id': '721aeb46-4694-4b7e-9928-b9256add2d9c', 'name': 'ChatOpenAI', 'type': 'llm', 'tags': ['seq:step:3', 'agent_llm'], 'metadata': {}, 'start_time': '2024-05-23T09:21:14.523+00:00', 'streamed_output': [], 'streamed_output_str': [], 'final_output': None, 'end_time': None}\n",
      "----\n",
      "/logs/ChatOpenAI/end_time\n",
      "2024-05-23T09:21:17.776+00:00\n",
      "----\n",
      "/logs/RunnableSequence/end_time\n",
      "2024-05-23T09:21:17.778+00:00\n",
      "----\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb 单元格 81\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m path_status \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m agent_executor\u001b[39m.\u001b[39mastream_log(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhere is the cat hiding? what items are in that location?\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m chunk\u001b[39m.\u001b[39mops:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba100_debug/slurm/home/yrd/shaolab/daiyizheng/github_project/DL/10-langchain/19-Agents.ipynb#Y221sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mif\u001b[39;00m op[\u001b[39m\"\u001b[39m\u001b[39mop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39madd\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:914\u001b[0m, in \u001b[0;36mRunnable.astream_log\u001b[0;34m(self, input, config, diff, with_streamed_output_list, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m stream \u001b[39m=\u001b[39m LogStreamCallbackHandler(\n\u001b[1;32m    901\u001b[0m     auto_close\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    902\u001b[0m     include_names\u001b[39m=\u001b[39minclude_names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     _schema_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moriginal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    911\u001b[0m \u001b[39m# Mypy isn't resolving the overloads here\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m# Likely an issue b/c `self` is being passed through\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39m# and it's can't map it to Runnable[Input,Output]?\u001b[39;00m\n\u001b[0;32m--> 914\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m _astream_log_implementation(  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    915\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    916\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m    917\u001b[0m     config,\n\u001b[1;32m    918\u001b[0m     diff\u001b[39m=\u001b[39mdiff,\n\u001b[1;32m    919\u001b[0m     stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    920\u001b[0m     with_streamed_output_list\u001b[39m=\u001b[39mwith_streamed_output_list,\n\u001b[1;32m    921\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    922\u001b[0m ):\n\u001b[1;32m    923\u001b[0m     \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:616\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     \u001b[39m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m         \u001b[39mawait\u001b[39;00m task\n\u001b[1;32m    617\u001b[0m     \u001b[39mexcept\u001b[39;00m asyncio\u001b[39m.\u001b[39mCancelledError:\n\u001b[1;32m    618\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:570\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    567\u001b[0m prev_final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m final_output: Optional[Output] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m runnable\u001b[39m.\u001b[39mastream(\u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    571\u001b[0m     prev_final_output \u001b[39m=\u001b[39m final_output\n\u001b[1;32m    572\u001b[0m     \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4698\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4692\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mastream\u001b[39m(\n\u001b[1;32m   4693\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4694\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   4695\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4696\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4697\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4698\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mastream(\n\u001b[1;32m   4699\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4701\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4702\u001b[0m     ):\n\u001b[1;32m   4703\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1592\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1582\u001b[0m iterator \u001b[39m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1583\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1584\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1591\u001b[0m )\n\u001b[0;32m-> 1592\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m   1593\u001b[0m     \u001b[39myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_executor\u001b[39m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[39m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[39m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[39m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:1303\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1302\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39maplan(\n\u001b[1;32m   1304\u001b[0m         intermediate_steps,\n\u001b[1;32m   1305\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[1;32m   1307\u001b[0m     )\n\u001b[1;32m   1308\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain/agents/agent.py:553\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunnable\u001b[39m.\u001b[39mastream(\n\u001b[1;32m    554\u001b[0m         inputs, config\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    555\u001b[0m     ):\n\u001b[1;32m    556\u001b[0m         \u001b[39mif\u001b[39;00m final_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m             final_output \u001b[39m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2900\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39minput_aiter\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2898\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39minput\u001b[39m\n\u001b[0;32m-> 2900\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matransform(input_aiter(), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2901\u001b[0m     \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2883\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   2878\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2879\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2880\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2881\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2882\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2883\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2884\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   2885\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atransform,\n\u001b[1;32m   2886\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m   2887\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2888\u001b[0m     ):\n\u001b[1;32m   2889\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1984\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1979\u001b[0m     chunk: Output \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mcreate_task(  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m         py_anext(iterator),  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m         context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m   1982\u001b[0m     )\n\u001b[1;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1984\u001b[0m     chunk \u001b[39m=\u001b[39m cast(Output, \u001b[39mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1985\u001b[0m \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[39mif\u001b[39;00m run_id \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[39m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[39m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39m:=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_map_by_run_id\u001b[39m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:2853\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m steps:\n\u001b[1;32m   2846\u001b[0m     final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   2847\u001b[0m         final_pipeline,\n\u001b[1;32m   2848\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m         ),\n\u001b[1;32m   2852\u001b[0m     )\n\u001b[0;32m-> 2853\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2854\u001b[0m     \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1316\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1313\u001b[0m final: Input\n\u001b[1;32m   1314\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1316\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m:\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1318\u001b[0m         final \u001b[39m=\u001b[39m adapt_first_streaming_chunk(chunk)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:4734\u001b[0m, in \u001b[0;36mRunnableBindingBase.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4728\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39matransform\u001b[39m(\n\u001b[1;32m   4729\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4730\u001b[0m     \u001b[39minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   4731\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   4732\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4733\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4734\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39matransform(\n\u001b[1;32m   4735\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m   4736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4737\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[1;32m   4738\u001b[0m     ):\n\u001b[1;32m   4739\u001b[0m         \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/runnables/base.py:1333\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1327\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed while trying to add together \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1328\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(final)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(chunk)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1329\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThese types should be addable for atransform to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1330\u001b[0m             )\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mastream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1334\u001b[0m         \u001b[39myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:315\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_end(\n\u001b[1;32m    318\u001b[0m         LLMResult(generations\u001b[39m=\u001b[39m[[generation]]),\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/langechain/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m             generation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\n\u001b[0;32m--> 309\u001b[0m     \u001b[39massert\u001b[39;00m generation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     \u001b[39mawait\u001b[39;00m run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[1;32m    312\u001b[0m         e,\n\u001b[1;32m    313\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []),\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "path_status = {}\n",
    "async for chunk in agent_executor.astream_log(\n",
    "    {\"input\": \"where is the cat hiding? what items are in that location?\"},\n",
    "):\n",
    "    for op in chunk.ops:\n",
    "        if op[\"op\"] == \"add\":\n",
    "            if op[\"path\"] not in path_status:\n",
    "                path_status[op[\"path\"]] = op[\"value\"]\n",
    "            else:\n",
    "                path_status[op[\"path\"]] += op[\"value\"]\n",
    "    print(op[\"path\"])\n",
    "    print(path_status.get(op[\"path\"]))\n",
    "    print(\"----\")\n",
    "    i += 1\n",
    "    if i > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `callbacks (Legacy)`\n",
    "\n",
    "streaming 的另一种方法是使用回调。如果您还在使用旧版本的LangChain并且无法升级，这可能会很有用。\n",
    "\n",
    "一般来说，这不是一个推荐的方法，因为\n",
    "1. 对于大多数应用程序，您需要创建两个worker，将回调写入队列，并让另一个worker从队列中读取(即，实现此工作存在隐藏的复杂性)。\n",
    "2. 结束事件可能缺少一些元数据(例如，运行名称)。因此，如果您需要额外的元数据，您应该从BaseTracer而不是AsyncCallbackHandler继承，以从运行(也称为跟踪)中获取相关信息，或者根据运行id自己实现聚合逻辑。\n",
    "3. 有不一致的行为与回调(例如，如何输入和输出编码)取决于你需要解决的回调类型。\n",
    "\n",
    "为了便于说明，我们在下面实现了一个回调，该回调显示了如何逐个令牌获取流。您可以根据应用程序的需要随意实现其他回调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, TypeVar, Union\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain_core.callbacks.base import AsyncCallbackHandler\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import ChatGenerationChunk, GenerationChunk, LLMResult\n",
    "\n",
    "# Here is a custom handler that will print the tokens to stdout.\n",
    "# Instead of printing to stdout you can send the data elsewhere; e.g., to a streaming API response\n",
    "\n",
    "\n",
    "class TokenByTokenHandler(AsyncCallbackHandler):\n",
    "    def __init__(self, tags_of_interest: List[str]) -> None:\n",
    "        \"\"\"A custom call back handler.\n",
    "\n",
    "        Args:\n",
    "            tags_of_interest: Only LLM tokens from models with these tags will be\n",
    "                              printed.\n",
    "        \"\"\"\n",
    "        self.tags_of_interest = tags_of_interest\n",
    "\n",
    "    async def on_chain_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        inputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when chain starts running.\"\"\"\n",
    "        print(\"on chain start: \")\n",
    "        print(inputs)\n",
    "\n",
    "    async def on_chain_end(\n",
    "        self,\n",
    "        outputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when chain ends running.\"\"\"\n",
    "        print(\"On chain end\")\n",
    "        print(outputs)\n",
    "\n",
    "    async def on_chat_model_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        messages: List[List[BaseMessage]],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when a chat model starts running.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if overlap_tags:\n",
    "            print(\",\".join(overlap_tags), end=\": \", flush=True)\n",
    "\n",
    "    def on_tool_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        input_str: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        inputs: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when tool starts running.\"\"\"\n",
    "        print(\"Tool start\")\n",
    "        print(serialized)\n",
    "\n",
    "    def on_tool_end(\n",
    "        self,\n",
    "        output: Any,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when tool ends running.\"\"\"\n",
    "        print(\"Tool end\")\n",
    "        print(str(output))\n",
    "\n",
    "    async def on_llm_end(\n",
    "        self,\n",
    "        response: LLMResult,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run when LLM ends running.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if overlap_tags:\n",
    "            # Who can argue with beauty?\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "    def get_overlap_tags(self, tags: Optional[List[str]]) -> List[str]:\n",
    "        \"\"\"Check for overlap with filtered tags.\"\"\"\n",
    "        if not tags:\n",
    "            return []\n",
    "        return sorted(set(tags or []) & set(self.tags_of_interest or []))\n",
    "\n",
    "    async def on_llm_new_token(\n",
    "        self,\n",
    "        token: str,\n",
    "        *,\n",
    "        chunk: Optional[Union[GenerationChunk, ChatGenerationChunk]] = None,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"\n",
    "        overlap_tags = self.get_overlap_tags(tags)\n",
    "\n",
    "        if token and overlap_tags:\n",
    "            print(token, end=\"|\", flush=True)\n",
    "\n",
    "\n",
    "handler = TokenByTokenHandler(tags_of_interest=[\"tool_llm\", \"agent_llm\"])\n",
    "\n",
    "result = await agent_executor.ainvoke(\n",
    "    {\"input\": \"where is the cat hiding and what items can be found there?\"},\n",
    "    {\"callbacks\": [handler]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将Agent作为迭代器运行\n",
    "可以将代理作为迭代器运行，以便根据需要添加人工循环检查。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
