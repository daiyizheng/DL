{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "在这里，我们将查看使用LangChain索引API的基本索引工作流。\n",
    "\n",
    "索引API允许您将来自任何源的文档加载到矢量存储中并保持同步。具体来说，它很有帮助\n",
    "- 避免将重复的内容写入vector存储\n",
    "- 避免重写未更改的内容\n",
    "- 避免在未更改的内容上重新计算嵌入\n",
    "\n",
    "所有这些都可以节省你的时间和金钱，并改善你的矢量搜索结果。       \n",
    "至关重要的是，索引API甚至可以处理相对于原始源文档已经经历了几个转换步骤(例如，通过文本分块)的文档。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "LangChain索引使用记录管理器(`RecordManager`)来跟踪写入矢量存储的文档。\n",
    "\n",
    "索引内容时，计算每个文档的哈希值，并将以下信息存储在记录管理器中\n",
    "- 文档散列(页面内容和元数据的散列)\n",
    "- 写入时间\n",
    "- 每个文档的源id应该在其元数据中包含信息，以便我们确定该文档的最终来源\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除模式\n",
    "将文档索引到矢量存储时，可能会删除矢量存储中的一些现有文档。在某些情况下，您可能希望删除与正在索引的新文档来自相同来源的所有现有文档。在其他情况下，您可能希望批量删除所有现有文档。索引API删除模式允许您选择所需的行为\n",
    "表格\n",
    "| 清理方式 | 减少重复内容 | 可并行性 | 清理已删除的源文档 | 清理源文档和/或派生文档的突变 | 清理时间 |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |\n",
    "| None | ✅ | ✅ | ❌ | ❌ | - |\n",
    "| 增量式 | ✅ | ✅ | ❌ | ✅ | 连续地 |\n",
    "| 完整 | ✅ | ❌ | ✅ | ✅ | 索引结束时 |\n",
    "\n",
    "None不做任何自动清理，允许用户手动清理旧内容。\n",
    "增量和完整提供以下自动清理：\n",
    "- 如果源文档或派生文档的内容发生了变化，增量模式或完整模式都将清除(删除)以前版本的内容。\n",
    "- 如果源文档已被删除(意味着它不包括在当前索引的文档中)，则完全清理模式将正确地从矢量存储中删除它，但增量模式不会。\n",
    "\n",
    "当内容发生变化(例如，源PDF文件被修改)时，在索引期间会有一段时间，新旧版本都可能返回给用户。这发生在新内容写入之后，但在旧版本被删除之前。\n",
    "- 增量 索引最大限度地减少了这段时间，因为它能够在写入时连续地进行清理。\n",
    "- 完整 模式在所有批写入后进行清理。\n",
    "\n",
    "**要求**\n",
    "1. 不要与预先填充了独立于索引API的内容的存储一起使用，因为记录管理器将不知道以前已经插入了记录。  \n",
    "2. 仅支持LangChain `vectorstore`   \n",
    "   1. 通过id添加文档(添加带有ids参数的文档方法)   \n",
    "   2. 按id删除(带id参数的删除方法)  \n",
    "\n",
    "\n",
    "兼容Vectorstores:AnalyticDB, AstraDB, AzureCosmosDBVectorSearch, AzureSearch, AwaDB, Bagel, Cassandra, Chroma, CouchbaseVectorStore, DashVector, DatabricksVectorSearch, DeepLake, Dingo, ElasticVectorSearch, ElasticsearchStore, FAISS, HanaDB, LanceDB, Milvus, MyScale, OpenSearchVectorSearch, PGVector, Pinecone, Qdrant, Redis, Rockset, ScaNN, SupabaseVectorStore, SurrealDBStore, TimescaleVector, UpstashVectorStore, Vald, VDMS, Vearch, VespaStore, Weaviate, ZepVectorStore, TencentVectorDB, OpenSearchVectorSearch。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 警告\n",
    "记录管理器依赖于基于时间的机制来确定哪些内容可以被清理(当使用完全或增量清理模式时)。\n",
    "\n",
    "如果两个任务连续运行，并且第一个任务在时钟时间改变之前完成，那么第二个任务可能无法清理内容。\n",
    "\n",
    "由于以下原因，这在实际设置中不太可能成为问题\n",
    "- RecordManager使用更高分辨率的时间戳。\n",
    "- 在第一个任务和第二个任务运行之间需要更改数据，如果任务之间的时间间隔很短，则不太可能更改数据。\n",
    "- 索引任务通常需要几毫秒以上的时间。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.globals import set_debug\n",
    "import os\n",
    "load_dotenv(find_dotenv())\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_core.documents import Document\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化矢量存储并设置嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"test_index\"\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_url=\"http://192.168.26.200:9200\", index_name=\"test_index\", embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用适当的名称空间初始化记录管理器。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = f\"elasticsearch/{collection_name}\"\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace, db_url=\"sqlite:///record_manager_cache.sql\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用记录管理器之前创建一个模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_manager.create_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们索引一些测试文档\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})\n",
    "doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引到空vector存储区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clear():\n",
    "    \"\"\"Hacky helper method to clear content. See the `full` mode section to to understand why it works.\"\"\"\n",
    "    index([], record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`None`删除模式    \n",
    "这种模式不会自动清理旧版本的内容;但是，它仍然负责内容重复删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(\n",
    "    [doc1, doc1, doc1, doc1, doc1],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=None,\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次将跳过所有内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`incremental`删除模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(\n",
    "    [doc1, doc2],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次索引将导致两个文档都被跳过，同时也会跳过嵌入操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index([], record_manager, vectorstore, cleanup=\"incremental\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们改变一个文档，新版本将被写入，所有共享同一来源的旧版本将被删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_doc_2 = Document(page_content=\"puppy\", metadata={\"source\": \"doggy.txt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(\n",
    "    [changed_doc_2],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**full删除模式**\n",
    "\n",
    "在full模式下，用户应该将需要索引的全部内容传递给索引函数。\n",
    "任何没有传递给索引函数并且存在于vectorstore中的文档都将被删除\n",
    "此行为对于处理源文档的删除非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()\n",
    "all_docs = [doc1, doc2]\n",
    "index(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设有人删除了第一个文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_docs[0]\n",
    "all_docs\n",
    "\n",
    "index(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source\n",
    "元数据属性包含一个名为source的字段。该来源应该指向与给定文档相关的最终来源。\n",
    "\n",
    "例如，如果这些文档表示某个父文档的块，则两个文档的源应该相同并引用父文档。\n",
    "\n",
    "通常，应该始终指定源。如果您从不打算使用增量模式，并且由于某种原因无法正确指定源字段，则仅使用None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "doc1 = Document(\n",
    "    page_content=\"kitty kitty kitty kitty kitty\", metadata={\"source\": \"kitty.txt\"}\n",
    ")\n",
    "doc2 = Document(page_content=\"doggy doggy the doggy\", metadata={\"source\": \"doggy.txt\"})\n",
    "new_docs = CharacterTextSplitter(\n",
    "    separator=\"t\", keep_separator=True, chunk_size=12, chunk_overlap=2\n",
    ").split_documents([doc1, doc2])\n",
    "new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()\n",
    "\n",
    "index(\n",
    "    new_docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_doggy_docs = [\n",
    "    Document(page_content=\"woof woof\", metadata={\"source\": \"doggy.txt\"}),\n",
    "    Document(page_content=\"woof woof woof\", metadata={\"source\": \"doggy.txt\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(\n",
    "    changed_doggy_docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.similarity_search(\"dog\", k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with loaders\n",
    "索引可以接受文档的可迭代对象或其他任何加载器。\n",
    "\n",
    "注意:加载程序必须正确设置源密钥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "\n",
    "\n",
    "class MyCustomLoader(BaseLoader):\n",
    "    def lazy_load(self):\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"t\", keep_separator=True, chunk_size=12, chunk_overlap=2\n",
    "        )\n",
    "        docs = [\n",
    "            Document(page_content=\"woof woof\", metadata={\"source\": \"doggy.txt\"}),\n",
    "            Document(page_content=\"woof woof woof\", metadata={\"source\": \"doggy.txt\"}),\n",
    "        ]\n",
    "        yield from text_splitter.split_documents(docs)\n",
    "\n",
    "    def load(self):\n",
    "        return list(self.lazy_load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()\n",
    "\n",
    "loader = MyCustomLoader()\n",
    "\n",
    "loader.load()\n",
    "\n",
    "index(loader, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\n",
    "\n",
    "vectorstore.similarity_search(\"dog\", k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
