{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "在这里，我们将查看使用LangChain索引API的基本索引工作流。\n",
    "\n",
    "索引API允许您将来自任何源的文档加载到矢量存储中并保持同步。具体来说，它很有帮助\n",
    "- 避免将重复的内容写入vector存储\n",
    "- 避免重写未更改的内容\n",
    "- 避免在未更改的内容上重新计算嵌入\n",
    "\n",
    "所有这些都可以节省你的时间和金钱，并改善你的矢量搜索结果。       \n",
    "至关重要的是，索引API甚至可以处理相对于原始源文档已经经历了几个转换步骤(例如，通过文本分块)的文档。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "LangChain索引使用记录管理器(`RecordManager`)来跟踪写入矢量存储的文档。\n",
    "\n",
    "索引内容时，计算每个文档的哈希值，并将以下信息存储在记录管理器中\n",
    "- 文档散列(页面内容和元数据的散列)\n",
    "- 写入时间\n",
    "- 每个文档的源id应该在其元数据中包含信息，以便我们确定该文档的最终来源\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除模式\n",
    "将文档索引到矢量存储时，可能会删除矢量存储中的一些现有文档。在某些情况下，您可能希望删除与正在索引的新文档来自相同来源的所有现有文档。在其他情况下，您可能希望批量删除所有现有文档。索引API删除模式允许您选择所需的行为\n",
    "表格\n",
    "| 清理方式 | 减少重复内容 | 可并行性 | 清理已删除的源文档 | 清理源文档和/或派生文档的突变 | 清理时间 |\n",
    "| ----------- | ----------- |----------- |----------- |----------- |----------- |\n",
    "| None | ✅ | ✅ | ❌ | ❌ | - |\n",
    "| 增量式 | ✅ | ✅ | ❌ | ✅ | 连续地 |\n",
    "| 完整 | ✅ | ❌ | ✅ | ✅ | 索引结束时 |\n",
    "\n",
    "None不做任何自动清理，允许用户手动清理旧内容。\n",
    "增量和完整提供以下自动清理：\n",
    "- 如果源文档或派生文档的内容发生了变化，增量模式或完整模式都将清除(删除)以前版本的内容。\n",
    "- 如果源文档已被删除(意味着它不包括在当前索引的文档中)，则完全清理模式将正确地从矢量存储中删除它，但增量模式不会。\n",
    "\n",
    "当内容发生变化(例如，源PDF文件被修改)时，在索引期间会有一段时间，新旧版本都可能返回给用户。这发生在新内容写入之后，但在旧版本被删除之前。\n",
    "- 增量 索引最大限度地减少了这段时间，因为它能够在写入时连续地进行清理。\n",
    "- 完整 模式在所有批写入后进行清理。\n",
    "\n",
    "**要求**\n",
    "1. 不要与预先填充了独立于索引API的内容的存储一起使用，因为记录管理器将不知道以前已经插入了记录。  \n",
    "2. 仅支持LangChain `vectorstore`   \n",
    "   1. 通过id添加文档(添加带有ids参数的文档方法)   \n",
    "   2. 按id删除(带id参数的删除方法)  \n",
    "\n",
    "\n",
    "兼容Vectorstores:AnalyticDB, AstraDB, AzureCosmosDBVectorSearch, AzureSearch, AwaDB, Bagel, Cassandra, Chroma, CouchbaseVectorStore, DashVector, DatabricksVectorSearch, DeepLake, Dingo, ElasticVectorSearch, ElasticsearchStore, FAISS, HanaDB, LanceDB, Milvus, MyScale, OpenSearchVectorSearch, PGVector, Pinecone, Qdrant, Redis, Rockset, ScaNN, SupabaseVectorStore, SurrealDBStore, TimescaleVector, UpstashVectorStore, Vald, VDMS, Vearch, VespaStore, Weaviate, ZepVectorStore, TencentVectorDB, OpenSearchVectorSearch。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 警告\n",
    "记录管理器依赖于基于时间的机制来确定哪些内容可以被清理(当使用完全或增量清理模式时)。\n",
    "\n",
    "如果两个任务连续运行，并且第一个任务在时钟时间改变之前完成，那么第二个任务可能无法清理内容。\n",
    "\n",
    "由于以下原因，这在实际设置中不太可能成为问题\n",
    "- RecordManager使用更高分辨率的时间戳。\n",
    "- 在第一个任务和第二个任务运行之间需要更改数据，如果任务之间的时间间隔很短，则不太可能更改数据。\n",
    "- 索引任务通常需要几毫秒以上的时间。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.globals import set_debug\n",
    "import os\n",
    "load_dotenv(find_dotenv())\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_core.documents import Document\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化矢量存储并设置嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error connecting to Elasticsearch: The client noticed that the server is not Elasticsearch and we do not support this unknown product\n"
     ]
    },
    {
     "ename": "UnsupportedProductError",
     "evalue": "The client noticed that the server is not Elasticsearch and we do not support this unknown product",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedProductError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m collection_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m embedding \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m----> 5\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mElasticsearchStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mes_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://192.168.26.200:9200\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain_elasticsearch/vectorstores.py:616\u001b[0m, in \u001b[0;36mElasticsearchStore.__init__\u001b[0;34m(self, index_name, embedding, es_connection, es_url, es_cloud_id, es_user, es_api_key, es_password, vector_query_field, query_field, distance_strategy, strategy, es_params)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m es_connection\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m es_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m es_cloud_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mElasticsearchStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_elasticsearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mes_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcloud_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_cloud_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mes_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    626\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Either provide a pre-existing Elasticsearch connection, \\\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m        or valid credentials for creating a new connection.\"\"\"\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain_elasticsearch/vectorstores.py:669\u001b[0m, in \u001b[0;36mElasticsearchStore.connect_to_elasticsearch\u001b[0;34m(es_url, cloud_id, api_key, username, password, es_params)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError connecting to Elasticsearch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m es_client\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain_elasticsearch/vectorstores.py:666\u001b[0m, in \u001b[0;36mElasticsearchStore.connect_to_elasticsearch\u001b[0;34m(es_url, cloud_id, api_key, username, password, es_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m es_client \u001b[38;5;241m=\u001b[39m Elasticsearch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconnection_params)\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[43mes_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError connecting to Elasticsearch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:2460\u001b[0m, in \u001b[0;36mElasticsearch.info\u001b[0;34m(self, error_trace, filter_path, human, pretty)\u001b[0m\n\u001b[1;32m   2458\u001b[0m     __query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretty\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretty\n\u001b[1;32m   2459\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 2460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2461\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_request\u001b[39m(\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[1;32m    267\u001b[0m         method,\n\u001b[1;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[1;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[1;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[0;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:363\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[0;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# Otherwise we only raise an error on 2XX responses.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedProductError(\n\u001b[1;32m    364\u001b[0m             message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe client noticed that the server is not Elasticsearch \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand we do not support this unknown product\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m             ),\n\u001b[1;32m    368\u001b[0m             meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[1;32m    369\u001b[0m             body\u001b[38;5;241m=\u001b[39mresp_body,\n\u001b[1;32m    370\u001b[0m         )\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# 'Warning' headers should be reraised as 'ElasticsearchWarning'\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarning\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mheaders:\n",
      "\u001b[0;31mUnsupportedProductError\u001b[0m: The client noticed that the server is not Elasticsearch and we do not support this unknown product"
     ]
    }
   ],
   "source": [
    "collection_name = \"test_index\"\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_url=\"http://192.168.26.200:9200\", index_name=\"test_index\", embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用适当的名称空间初始化记录管理器。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = f\"elasticsearch/{collection_name}\"\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace, db_url=\"sqlite:///record_manager_cache.sql\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用记录管理器之前创建一个模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_manager.create_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们索引一些测试文档\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})\n",
    "doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引到空vector存储区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clear():\n",
    "    \"\"\"Hacky helper method to clear content. See the `full` mode section to to understand why it works.\"\"\"\n",
    "    index([], record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`None`删除模式    \n",
    "这种模式不会自动清理旧版本的内容;但是，它仍然负责内容重复删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(\n",
    "    [doc1, doc1, doc1, doc1, doc1],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=None,\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二次将跳过所有内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`incremental`删除模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(\n",
    "    [doc1, doc2],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次索引将导致两个文档都被跳过，同时也会跳过嵌入操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index([], record_manager, vectorstore, cleanup=\"incremental\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们改变一个文档，新版本将被写入，所有共享同一来源的旧版本将被删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_doc_2 = Document(page_content=\"puppy\", metadata={\"source\": \"doggy.txt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(\n",
    "    [changed_doc_2],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**full删除模式**\n",
    "\n",
    "在full模式下，用户应该将需要索引的全部内容传递给索引函数。\n",
    "任何没有传递给索引函数并且存在于vectorstore中的文档都将被删除\n",
    "此行为对于处理源文档的删除非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()\n",
    "all_docs = [doc1, doc2]\n",
    "index(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设有人删除了第一个文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_docs[0]\n",
    "all_docs\n",
    "\n",
    "index(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source\n",
    "元数据属性包含一个名为source的字段。该来源应该指向与给定文档相关的最终来源。\n",
    "\n",
    "例如，如果这些文档表示某个父文档的块，则两个文档的源应该相同并引用父文档。\n",
    "\n",
    "通常，应该始终指定源。如果您从不打算使用增量模式，并且由于某种原因无法正确指定源字段，则仅使用None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "doc1 = Document(\n",
    "    page_content=\"kitty kitty kitty kitty kitty\", metadata={\"source\": \"kitty.txt\"}\n",
    ")\n",
    "doc2 = Document(page_content=\"doggy doggy the doggy\", metadata={\"source\": \"doggy.txt\"})\n",
    "new_docs = CharacterTextSplitter(\n",
    "    separator=\"t\", keep_separator=True, chunk_size=12, chunk_overlap=2\n",
    ").split_documents([doc1, doc2])\n",
    "new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()\n",
    "\n",
    "index(\n",
    "    new_docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_doggy_docs = [\n",
    "    Document(page_content=\"woof woof\", metadata={\"source\": \"doggy.txt\"}),\n",
    "    Document(page_content=\"woof woof woof\", metadata={\"source\": \"doggy.txt\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index(\n",
    "    changed_doggy_docs,\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.similarity_search(\"dog\", k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with loaders\n",
    "索引可以接受文档的可迭代对象或其他任何加载器。\n",
    "\n",
    "注意:加载程序必须正确设置源密钥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "\n",
    "\n",
    "class MyCustomLoader(BaseLoader):\n",
    "    def lazy_load(self):\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"t\", keep_separator=True, chunk_size=12, chunk_overlap=2\n",
    "        )\n",
    "        docs = [\n",
    "            Document(page_content=\"woof woof\", metadata={\"source\": \"doggy.txt\"}),\n",
    "            Document(page_content=\"woof woof woof\", metadata={\"source\": \"doggy.txt\"}),\n",
    "        ]\n",
    "        yield from text_splitter.split_documents(docs)\n",
    "\n",
    "    def load(self):\n",
    "        return list(self.lazy_load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clear()\n",
    "\n",
    "loader = MyCustomLoader()\n",
    "\n",
    "loader.load()\n",
    "\n",
    "index(loader, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\n",
    "\n",
    "vectorstore.similarity_search(\"dog\", k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
