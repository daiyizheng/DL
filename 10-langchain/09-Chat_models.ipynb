{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Models\n",
    "\n",
    "聊天模型是语言模型的一种变体。虽然聊天模型在底层使用语言模型，但它们使用的界面略有不同。他们没有使用文本输入和文本输出API，而是使用聊天消息作为输入和输出的接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```python\n",
    "pip install -qU langchain-openai\n",
    "pip install -qU langchain-anthropic\n",
    "pip install -qU langchain-google-vertexai\n",
    "pip install -qU langchain-cohere\n",
    "pip install -qU langchain-fireworks\n",
    "pip install -qU langchain-mistralai\n",
    "pip install -qU langchain-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聊天模型界面基于消息而不是原始文本。LangChain目前支持的消息类型有`AIMessage`、`HumanMessage`、`SystemMessage`、`FunctionMessage`和`ChatMessage`。`ChatMessage`接受任意角色参数。大多数时候，你只需要处理`HumanMessage`, `AIMessage`和`SystemMessage`\n",
    "\n",
    "## LCEL\n",
    "聊天模型实现了` Runnable interface`，这是语言链表达语言(LCEL)的基本构建块。这意味着它们支持`invoke`, `ainvoke`, `stream`, `aststream`, `batch`,` abbatch`, `aststream`日志调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content=\"What is the purpose of model regularization?\"),\n",
    "]\n",
    "chat.invoke(messages)\n",
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "chat.batch([messages])\n",
    "await chat.ainvoke(messages)\n",
    "async for chunk in chat.astream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "async for chunk in chat.astream_log(messages):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate\n",
    "批处理调用，更丰富的输出您可以更进一步，使用`generate`为多组消息生成补全。这将返回带有附加`message`的`LLMResult`。除了返回的消息之外，这将包括关于每代的附加信息(例如完成原因)和关于完整API调用的附加信息(例如使用的令牌总数)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that translates English to French.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"I love programming.\"),\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that translates English to French.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"I love artificial intelligence.\"),\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 消息类型\n",
    "ChatModels将消息列表作为输入并返回一条消息。有几种不同类型的消息。所有消息都有一个`role`和一个`content`属性。`role`描述了谁的消息。对于不同的角色，LangChain有不同的消息类。`content`属性描述消息的内容。这可以是一些不同的事情\n",
    "- 字符串(大多数模型处理这种类型的内容)\n",
    "- 字典列表(用于多模式输入，其中字典包含有关输入类型和输入位置的信息)\n",
    "\n",
    "此外，消息还有一个`additional_kwargs`属性。在这里可以传递关于消息的附加信息。这主要用于特定于提供程序而非通用的输入参数。最著名的例子是OpenAI的`function_call `。\n",
    "- HumanMessage 这表示来自用户的消息。一般只由内容组成\n",
    "- AIMessage  这表示来自模型的消息。这可能会有`additional_kwargs ` -例如，如果使用OpenAI工具调用`tool_calls `。\n",
    "- SystemMessage 这表示一个系统消息，它告诉模型如何行为。这通常只包括内容。并不是每个模型都支持这一点。\n",
    "- FunctionMessage 这表示函数调用的结果。除了`role`和`content`之外，该消息还有一个name参数，该参数表示为产生此结果而调用的函数的名称。\n",
    "- ToolMessage 这表示工具调用的结果。为了匹配OpenAI的`function`和`tool`消息类型，这与`FunctionMessage`不同。除了`role`和`content`之外，该消息还有一个`tool_call_id `参数，该参数传递了为产生此结果而调用的工具的调用id。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "所有`chatmodel`都实现了`Runnable`接口，该接口与所有方法的默认实现一起提供。`Ainvoke`,`batch`, `abbatch`, `stream`, `astream`。这为所有`chatmodel`提供了对流的基本支持。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
