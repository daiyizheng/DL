{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain 入门范例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载.env文件中的环境变量\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本总结(Summarization)\n",
    "扔给LLM一段文本，让他给你生成总结可以说是最常见的场景之一了\n",
    "\n",
    "目前最火的应用应该是 chatPDF，可以利用langchain进行实现。\n",
    "### 1，短文本总结\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "llm = ChatOpenAI(temperature=0, \n",
    "                 model_name = 'gpt-3.5-turbo') # 初始化LLM模型\n",
    "\n",
    "# 创建模板\n",
    "template = \"\"\"\n",
    "%INSTRUCTIONS:\n",
    "Please summarize the following piece of text.\n",
    "Respond in a manner that a 5 year old would understand.\n",
    "\n",
    "%TEXT:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# 创建一个 Lang Chain Prompt 模板，稍后可以插入值\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Prompt Begin -------\n",
      "\n",
      "%INSTRUCTIONS:\n",
      "Please summarize the following piece of text.\n",
      "Respond in a manner that a 5 year old would understand.\n",
      "\n",
      "%TEXT:\n",
      "\n",
      "For the next 130 years, debate raged.\n",
      "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
      "“The problem is that when you look up close at the anatomy, it’s evocative of a lot of different things, but it’s diagnostic of nothing,” says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
      "“And it’s so damn big that when whenever someone says it’s something, everyone else’s hackles get up: ‘How could you have a lichen 20 feet tall?’”\n",
      "\n",
      "\n",
      "------- Prompt End -------\n"
     ]
    }
   ],
   "source": [
    "confusing_text = \"\"\"\n",
    "For the next 130 years, debate raged.\n",
    "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
    "“The problem is that when you look up close at the anatomy, it’s evocative of a lot of different things, but it’s diagnostic of nothing,” says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
    "“And it’s so damn big that when whenever someone says it’s something, everyone else’s hackles get up: ‘How could you have a lichen 20 feet tall?’”\n",
    "\"\"\"\n",
    "print (\"------- Prompt Begin -------\")\n",
    "# 打印模板内容\n",
    "final_prompt = prompt.format(text=confusing_text)\n",
    "print(final_prompt)\n",
    "\n",
    "print (\"------- Prompt End -------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"For a long time, scientists argued about what Prototaxites was. Some thought it was a lichen, some thought it was a fungus, and others thought it was a tree. The problem was that when they looked closely at it, it looked like different things but didn't match anything exactly. It was also really big, so people couldn't agree on what it was.\" response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 166, 'total_tokens': 243}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None} id='run-1df4ea55-c1d3-45ee-9891-f94f09a0c55f-0'\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(final_prompt)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2，长文本总结\n",
    "\n",
    "对于文本长度较短的文本我们可以直接这样执行summary操作\n",
    "\n",
    "但是对于文本长度超过lLM支持的max token size 时将会遇到困难\n",
    "\n",
    "Lang Chain 提供了开箱即用的工具解决长文本的问题：load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries Of Longer Text\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonderland\n",
      "Where is the wonderland I want to find it.——题记\n",
      "（一）\n",
      "“Wonderland”，很多人会把这个词翻译作“奇幻世界”之类的。但我，更爱把它称做“乐土”。\n",
      "人生只有一次。我奉信完全随心所欲、自由自在的人生。因此，我也一直，梦想着……不，幻想着，寻找到“乐土”。\n",
      "我觉得有一句来自东方古国的话很适合当我的座右铭——“人生得意须尽欢”。如果这唯一的人生都不能过得快乐，令自己满意，那还有什么意义呢？人生在世，重要的不是为别人留下些什么，而是能够在离开的时候潇洒一笑，说，我这一生过得无怨无悔。\n",
      "没错，我就是这\n"
     ]
    }
   ],
   "source": [
    "with open('data/wonderland.txt', 'r',encoding = 'utf-8') as file:\n",
    "    text = file.read() # 文章本身是爱丽丝梦游仙境\n",
    "\n",
    "# 打印小说的前285个字符\n",
    "print (text[:285])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5505 tokens in your file\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "\n",
    "print (f\"There are {num_tokens} tokens in your file\") \n",
    "# 全文一共4w8词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决长文本的方式无非是'chunking','splitting' 原文本为小的段落/分割部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You now have 2 docs intead of 1 piece of text\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], \n",
    "                                               chunk_size=4000, \n",
    "                                               chunk_overlap=350)\n",
    "# 虽然我使用的是 RecursiveCharacterTextSplitter，但是你也可以使用其他工具\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print (f\"You now have {len(docs)} docs intead of 1 piece of text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Wonderland\\nWhere is the wonderland I want to find it.——题记\\n（一）\\n“Wonderland”，很多人会把这个词翻译作“奇幻世界”之类的。但我，更爱把它称做“乐土”。\\n人生只有一次。我奉信完全随心所欲、自由自在的人生。因此，我也一直，梦想着……不，幻想着，寻找到“乐土”。\\n我觉得有一句来自东方古国的话很适合当我的座右铭——“人生得意须尽欢”。如果这唯一的人生都不能过得快乐，令自己满意，那还有什么意义呢？人生在世，重要的不是为别人留下些什么，而是能够在离开的时候潇洒一笑，说，我这一生过得无怨无悔。\\n没错，我就是这么一个自私的人。不过我一直认为这样很好。\\n曾经有那么一个人——跟我完全相反的一个人。他身上背负着来自家庭、来自社会各方面的压力和负担，但他从来没认为这些是应该抛弃的累赘，反而认为这是他的责任。\\n对，责任。他认为这是他必须承担的，是他生命的一部分。\\n哈哈，笑话。你看，他最后被那些责任压垮了哦。英年早逝，死因是劳累过度。这些都和我早就过世的“家人”一模一样。他们都是这样让我无法理解的人。如果人不能为自己而活……我实在是无法想象他们的那种人生。\\n我没有去他的葬礼，而是在他下葬之后的第二天去了公墓。我把从郊外采来，还带着露水的白色野百合放在他的墓碑前，然后就一屁股坐在了地上，舒舒服服地靠着他的墓碑。\\n那天天气不太好，空中飘着密密麻麻的雨丝。低气压也令人生厌，我觉得呼吸困难，鼻腔酸涩。公墓那边是这座濒临毁灭的城市中唯一一处还有点绿化的地方了。寥寥几棵种植在公墓外围的树上的叶子在雨中泛出鲜嫩的绿色，在风中沙沙地摇曳着。你看这世界上的人多不可理喻。明明就剩下这么一点环境还算可以的地方，却要留给已经不在了的人们。为什么……不能留给还在的人？\\n我胡乱抹了抹脸上的水，顺带着捋顺了在雨中凌乱不堪的一头杂毛。我的余光瞟到了让我感兴趣的东西。于是我转头盯着那人墓碑上的遗像发呆。\\n“你说，我以前从来没看过你的笑容。这唯一一次却是看到了你的遗像。”我禁不住笑了出来，“你说，要是你能像我一样只为自己而活的话，是不是就不会是现在这个样子了？”\\n那个人叫宇智波鼬。\\n其实……我也明白，只有这样的他才算是他。\\n不过他已经再也不能反驳我的话了。\\n（二）\\n宇智波鼬是我这辈子遇到的，唯一一个能跟我正常相处的人。啊，当然这种正常是我单方面的意见，我没有问过他。\\n之于他，我大概就什么都不是了。\\n第一次和他说话，是在一个荒凉的小公园——我经常去的一个地方。\\n那时候我和他都是小学生。只不过他非常优秀，而我……是那种和所有人都没办法相处，成绩也非常糟糕，还经常逃学的孩子。\\n那天我就是逃学去了公园里，随便在白纸上涂抹着色彩。一直到了黄昏，路灯接连亮起来的时候，不知道他为什么碰巧路过，然后又发现了我。\\n“在画画吗？”他背着巨大且沉重的书包凑到我身边问道。\\n“嗯……”我把最后一笔画上去，然后甩下画笔，饶有兴趣地看着他，“你确定要跟我说话？我可是伟大的精神病。”\\n“那些只是同学们胡乱说的。你只是不喜欢和人沟通吧？”他一本正经地回答道。\\n“哈，是真的哟。”我大笑着说道，顺手对着灰蒙蒙的天空竖过去一个标准的中指，“好学生怎么会这个时间在外面到处晃？看，遇上我这种人，你就不怕我一时冲动，杀了你吗？”\\n“你呢？为什么不回家？”他没有理会我的疯言疯语，执着地想要和我正常地沟通。\\n“我没有家啊。”看他一时也没有要走的意思，我便恢复了常态——如果我有那种东西的话，认真地回答道，“更何况我现在就是想要在这里画画。”\\n“那到了这种时间，也应该回住的地方好好休息了。”\\n“哦。”我敷衍着，继续把画上一些细节都认真地修改了一番。\\n“可以给我看看吗？”大概是没了话题，他提出了要看画的要求。\\n“当然。”我也就不再继续修改，直接把巨幅的画板抱起来，举给他看。\\n“很漂亮……但是……”他看到我的画之后立刻皱起了眉，清秀的眉目间随即多了一份不解。\\n“颜色太鲜艳？”我指了一下画上大片红色的纱帘，“还是你觉得葬礼只能用白啊黑啊这一类的颜色来描绘？”\\n他犹豫了一下，还是点了点头。\\n“我从来不理会那种世俗的规定之类的。反正人生就是追求‘畅快淋漓’四个字。我想怎么干自然就怎么干了。更何况……”我有点费力地把最表层的画掀起来，给他看里面一张张全部由暖色构成的画面，“我画画从来只用暖色。如果你一切都按照自己的意愿去做了，那便没什么事情是值得后悔的。没有后悔也就没有悲伤。没有悲伤又为什么要用冷色？”\\n“可是，你没有想过世界上有太多人身不由己吗？他们没法干自己想干的事情。”\\n“所以我不会做那种人。与其苟活，无法做自己想做的事情，不如直接去死。”\\n“啊？”他愣了一下，“那你背负的责任要怎么办？”\\n“我从来不认同‘责任’这种东西。没有任何人有权利指使我去做什么。”我坚定地说。\\n“是吗？”他当时只是苦笑。\\n后来，他选择的道路终究还是背负着责任一直到死。说到底，我和他就不是同一种人。嘛，反正人也有选择自己人生的权利，我也不好说他什么了。\\n（三）\\n我和他从那之后也没有怎么见过面，即使是见面，也不过是点头一个招呼。\\n唯一一次正儿八经的谈话好像是某一天早上在学校，我受不了老师一个劲儿的唠叨，管他借了作业。\\n反正也算是点头之交了，况且我也没有其他可以找的人。——我记得我当时是这么想的，丝毫没有所谓不好意思的感觉，大大咧咧地让他大致帮我讲一下那些题的思路。\\n我很笨。那些题怎么也不会。不过也可能是因为讲那些的时候我正在画画，或者索性没有在教室里呆着。\\n他没有不耐烦，一直认真地给我讲解着每个细节。结果即使是他那样优秀的学生，被我的思路拖着走了十分钟，立刻也混乱起来。\\n他挠挠头，又看了一遍自己的解法，好像更加迷糊起来，嘟哝着“奇怪”。\\n我笑得前仰后合，无视周围一圈异性射过来的怨念眼神，掐了掐鼬的脸蛋。\\n他怔了一下，然后选择了无视我的举动，继续琢磨那道题。\\n最后宇智波小朋友还是跑去找老师给他讲题了。\\n他走之后，刚才一直盯着我们看的讨厌女人们围上来，抱着手臂对我叫嚣。\\n什么“你不能跟宇智波同学黏在一起”，什么“你不可以和宇智波同学关系那么好”……一口一个宇智波同学，就好像他是她们什么人似的。\\n我挑了挑眉，竖起两根中指挨个儿比过去：\\n“我确实是跟他没关系。不过，什么时候轮到你们这些——哈，我不应该侮辱那个词的——你们这些混蛋说三道四？”\\n她们都气红了脸，班里的男生都拍桌子站起来，二活不说围上来，拉着我的领子把我摔倒在地。\\n那个早上我被将近二十个人围起来群殴，腿骨断了一根，外伤更是数不胜数。\\n我擦了擦嘴角的血迹，吐掉嘴里白花花的两颗牙，本来想站起来，后来发现实在做不到，就舒适地躺在地上，眯起眼睛看着那群揍我的家伙。\\n“混小子，还敢这么看着我们！”\\n“揍他！”\\n“他就一□！”\\n我捂着又一次被踢到的小腹，歪倒在一边使劲咳嗽着，缓过点劲儿来之后就笑得张狂：\\n“You are the son of the bitch.儿子女儿们早上好啊。哦，对了，你们的妈妈是谁我可不知道。你们得自己想办法打听去哟。”\\n后来我是不是又被他们揍了我也不知道。因为骂完这句话之后，我看到刚刚回来的宇智波鼬站在班门口脸色苍白。然后不知怎么的，我眼前一花就晕了过去。\\n醒来的时候我只看到医院的天花板雪白雪白，什么别的人都没有。\\n我在医院里躺了两个月，有护士看着，姑且没饿死。\\n出院之后我就没想再跟那该死的学校扯上关系，索性辍学，然后整日整夜地画画、卖画。\\n啊，说起来，之后我再也没有看到过宇智波鼬。\\n也许他只是因为不想和我这个麻烦人物扯上关系，也许他只是太优秀了根本没时间理睬我这个小人物。\\n总之，我对他的印象就停留在那个血腥的早上，他一张俊美的脸上，五官端正表情严肃，睁得大大的眼睛上面卷翘且密的睫毛在早上金黄色的阳光中流光溢彩。当时我看过去明明不是逆光，我却觉得他光芒万丈。\\n（四）\\n我一直感觉自己和这个世界没什么联系。他死了之后尤其让我有这种感觉。\\n我家人是早就因为过度操劳而死了。他们死前请一个“朋友”来当我的监护人。可惜他们遇人不淑。此人霸占了他们的遗产，然后就随我自生自灭。\\n于是我在这世上已经没了可以说话的人。\\n我靠着卖画倒是能挣够钱。这些年来我一直一边四处游历一边画画。反正这种生活也是我想要的。\\n但总是觉得有点寂寞。\\n中间几度在旁人的口中听到关于那个优秀的少年的消息。\\n有的时候我就在想，宇智波鼬为了家族考学去了其他城市，又一直为了光耀门楣而四处奔波奋斗工作。在这个过程中，他寂寞过吗？\\n不过他应该有很多朋友吧……虽然他也不一定有知己——毕竟像他那样能够做到负担起所有“责任”的人，终究还是少的。但是，他的普通朋友，能称得上伙伴的人应该是大有人在吧。\\n当然这说到底还是我的猜测罢了，我和他没有多么熟识，我也很难通过别人的话揣摩出关于他详细的情况。\\n又下酸雨了。我皱起了眉头，躲进旁边一家书店里避难。\\n外面铅灰色的天空变得诡异，尘土被雨水冲刷到大街上，堆出个近乎神祗的图形。这样看上去，倒像是神祗都变成了尘土。\\n说起来……最近变故时有发生。原因大概是这个世界越来越糟糕了。虽然经济极度繁荣，人与人的关系却是越来越远。各种各样的阴谋、悲剧层出不穷。能做到像他那样承担起全部的人和像我这样生活得随心所欲的人都近乎绝种。\\n其实我也没办法再继续随心所欲地活着了……因为各种各样的原因……\\n但是我还是执着地抱着寻找Wonderland的幻想。\\n即使这个世界上已经不存在所谓的乐土了。即使我已经被剥夺了寻找，甚至幻想的权利。\\n我不想放弃。\\n“W00-0000号，到检查身体的时间了。”一个冷淡的声音打断了我的思考。\\n我顿时觉得一股寒意顺着脊椎向上攀升。'),\n",
       " Document(page_content='又下酸雨了。我皱起了眉头，躲进旁边一家书店里避难。\\n外面铅灰色的天空变得诡异，尘土被雨水冲刷到大街上，堆出个近乎神祗的图形。这样看上去，倒像是神祗都变成了尘土。\\n说起来……最近变故时有发生。原因大概是这个世界越来越糟糕了。虽然经济极度繁荣，人与人的关系却是越来越远。各种各样的阴谋、悲剧层出不穷。能做到像他那样承担起全部的人和像我这样生活得随心所欲的人都近乎绝种。\\n其实我也没办法再继续随心所欲地活着了……因为各种各样的原因……\\n但是我还是执着地抱着寻找Wonderland的幻想。\\n即使这个世界上已经不存在所谓的乐土了。即使我已经被剥夺了寻找，甚至幻想的权利。\\n我不想放弃。\\n“W00-0000号，到检查身体的时间了。”一个冷淡的声音打断了我的思考。\\n我顿时觉得一股寒意顺着脊椎向上攀升。\\n我深呼吸了一下尽量平静下来，冲着声音传来的方向比过去一个极其标准的中指。\\n我没有转头去看那边的反应，而是盯着我最讨厌的白色的天花板发呆，一种无法平复的不安在骨子里不停地蔓延。\\n如果我能找到真正的Wonderland就好了……如果……\\n尾声\\n一个面目惨白，顶着一头鸡窝一样的紫罗兰色头发的男子用缠着铁链的手臂抱着画板靠在窗边。虽然隔着铁栅栏一样的窗户，不断地有浅黄色的阳光洒进来，但男子的画上却因为他的遮挡而布满了大片的阴影。\\n男子皱了皱眉，把几乎快要完成的作品扔到病床上，然后抬起两只被手铐制在一起的手，狠狠地抓了抓自己的头发，低声咒骂了几句，从窗边离开。\\n男子扔到床上的画上正中有一个俊秀的黑发少年，微皱着眉一脸严肃，深深的两道法令纹让他显得很成熟。少年的背后是一大片用金黄色涂抹开来的小麦田，以及落下一半的硕大太阳。\\n画面最上面被写了涂、涂了写的部分，现在有着一个花体的英文单词——\\n“Wonderland”。\\n现在无人不知无人不晓，Wonderland其实是一所非常有名的精神病院。\\n关于这所精神病院也有一些不太好的传闻……\\n当然，毕竟是收容疯子的地方，有不好的传闻也是应该的吧。更何况，Wonderland是全世界规模最大的……\\n那个只喜欢用暖色画画的男子，W00-0000号也是Wonderland中一名普通的病患。\\n后记\\n我不知道是不是有人像我一样，曾经执着地想要找到属于自己的一片乐土。我也不知道是不是有人真的成功地找到了。\\n现在我逐渐迷茫了。我甚至没办法肯定自己是不是还能坚持抱有去寻找乐土的幻想。\\nWho can tell me, where is the wonderland Who can tell me, if I can discover the wonderland…')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 lang chain\n",
    "# 使用 map_reduce的chain_type，这样可以将多个文档合并成一个\n",
    "chain = load_summarize_chain(llm=llm, \n",
    "                             chain_type='map_reduce') # verbose=True 展示运行日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The narrator reflects on their search for happiness and freedom in life, contrasting their carefree lifestyle with that of a responsible individual. They recall interactions with a talented classmate and explore themes of loneliness and the search for happiness in a troubled world. The story ends with a man in a mental hospital creating a painting of a young man labeled as a patient, questioning if anyone has truly found their own paradise.\n"
     ]
    }
   ],
   "source": [
    "# Use it. This will run through the 36 documents, summarize the chunks, then get a summary of the summary.\n",
    "# 典型的map reduce的思路去解决问题，将文章拆分成多个部分，再将多个部分分别进行 summarize，最后再进行 合并，对 summarys 进行 summary\n",
    "output = chain.run(docs)\n",
    "print (output)\n",
    "# Try yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二，文档问答(QA based Documents)\n",
    "\n",
    "为了确保LLM能够执行QA任务\n",
    "1. 需要向LLM传递能够让他参考的上下文信息\n",
    "2. 需要向LLM准确地传达我们的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1，短文本问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 4723 characters in that document\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('data/wonderland.txt', \n",
    "                    encoding='utf-8') # 载入一个长文本，我们还是使用爱丽丝漫游仙境这篇小说作为输入\n",
    "doc = loader.load()\n",
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将小说分割成多个部分\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, \n",
    "                                               chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 2 documents that have an average of 2,537 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "# 获取字符的总数，以便可以计算平均值\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 embedding 引擎\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Embed 文档，然后使用伪数据库将文档和原始文本结合起来\n",
    "# 这一步会向 OpenAI 发起 API 请求\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建QA-retrieval chain\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have enough information to determine what the author describes Alice following with.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What does the author describe the Alice following with?\"\n",
    "qa.run(query)\n",
    "# 这个过程中，检索器会去获取类似的文件部分，并结合你的问题让 LLM 进行推理，最后得到答案\n",
    "# 这一步还有很多可以细究的步骤，比如如何选择最佳的分割大小，如何选择最佳的 embedding 引擎，如何选择最佳的检索器等等\n",
    "# 同时也可以选择云端向量存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三，信息抽取(Extraction)\n",
    "\n",
    "Extraction是从一段文本中解析结构化数据的过程.\n",
    "\n",
    "通常与Extraction parser一起使用，以构建数据，以下是一些使用范例。\n",
    "\n",
    "1. 从句子中提取结构化行以插入数据库\n",
    "2. 从长文档中提取多行以插入数据库\n",
    "3. 从用户查询中提取参数以进行 API 调用\n",
    "4. 最近最火的 Extraction 库是 KOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1，手动格式转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0, \n",
    "                        model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Extraction\n",
    "instructions = \"\"\"\n",
    "You will be given a sentence with fruit names, extract those fruit names and assign an emoji to them\n",
    "Return the fruit name and emojis in a python dictionary\n",
    "\"\"\"\n",
    "\n",
    "fruit_names = \"\"\"\n",
    "Apple, Pear, this is an kiwi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Apple\": \"🍎\",\n",
      "    \"Pear\": \"🍐\",\n",
      "    \"kiwi\": \"🥝\"\n",
      "}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Make your prompt which combines the instructions w/ the fruit names\n",
    "prompt = (instructions + fruit_names)\n",
    "\n",
    "# Call the LLM\n",
    "output = chat_model([HumanMessage(content=prompt)])\n",
    "\n",
    "print (output.content)\n",
    "print (type(output.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': '🍎', 'Pear': '🍐', 'kiwi': '🥝'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "output_dict = eval(output.content) #利用python中的eval函数手动转换格式\n",
    "\n",
    "print (output_dict)\n",
    "print (type(output_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2，自动格式转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用langchain.output_parsers.StructuredOutputParser可以自动生成一个带有格式说明的提示。\n",
    "\n",
    "这样就不需要担心提示工程输出格式的问题了，将这部分完全交给 Lang Chain 来执行，将LLM的输出转化为 python 对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析输出并获取结构化的数据\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"artist\", description=\"The name of the musical artist\"),\n",
    "    ResponseSchema(name=\"song\", description=\"The name of the song that the artist plays\")\n",
    "]\n",
    "\n",
    "# 解析器将会把LLM的输出使用我定义的schema进行解析并返回期待的结构数据给我\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"artist\": string  // The name of the musical artist\n",
      "\t\"song\": string  // The name of the song that the artist plays\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个 Prompt 与之前我们构建 Chat Model 时 Prompt 不同\n",
    "# 这个 Prompt 是一个 ChatPromptTemplate，它会自动将我们的输出转化为 python 对象\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"Given a command from the user, extract the artist and song names \\n \\\n",
    "                                                    {format_instructions}\\n{user_prompt}\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a command from the user, extract the artist and song names \n",
      "                                                     The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"artist\": string  // The name of the musical artist\n",
      "\t\"song\": string  // The name of the song that the artist plays\n",
      "}\n",
      "```\n",
      "I really like So Young by Portugal. The Man\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Given a command from the user, extract the artist and song names \\n                                                     The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"artist\": string  // The name of the musical artist\\n\\t\"song\": string  // The name of the song that the artist plays\\n}\\n```\\nI really like So Young by Portugal. The Man')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_query = prompt.format_prompt(user_prompt=\"I really like So Young by Portugal. The Man\")\n",
    "print(artist_query.messages[0].content)\n",
    "print(\"--------------\")\n",
    "artist_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artist': 'Portugal. The Man', 'song': 'So Young'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "artist_output = chat_model(artist_query.to_messages())\n",
    "output = output_parser.parse(artist_output.content)\n",
    "\n",
    "print (output)\n",
    "print (type(output))\n",
    "# 这里要注意的是，因为我们使用的 turbo 模型，生成的结果并不一定是每次都一致的\n",
    "# 替换成gpt4模型可能是更好的选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Given a command from the user, extract the artist and song names \\n                                                     The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"artist\": string  // The name of the musical artist\\n\\t\"song\": string  // The name of the song that the artist plays\\n}\\n```\\nI really like So Young by Portugal. The Man')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_query.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四，结果评估(Evaluation)\n",
    "\n",
    "由于自然语言的不可预测性和可变性，评估LLM的输出是否正确有些困难，langchain 提供了一种方式帮助我们去解决这一难题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings, store, and retrieval\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Model and doc loader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "# Eval\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 4723 characters in that document\n"
     ]
    }
   ],
   "source": [
    "# 还是使用爱丽丝漫游仙境作为文本输入\n",
    "loader = TextLoader('data/wonderland.txt',encoding='utf-8')\n",
    "doc = loader.load()\n",
    "\n",
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings and docstore\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                    chain_type=\"stuff\", \n",
    "                                    retriever=docsearch.as_retriever(), \n",
    "                                    input_key=\"question\")\n",
    "# 注意这里的 input_key 参数，这个参数告诉了 chain 我的问题在字典中的哪个 key 里\n",
    "# 这样 chain 就会自动去找到问题并将其传递给 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answers = [\n",
    "    {'question' : \"Which animal give alice a instruction?\", 'answer' : 'rabbit'},\n",
    "    {'question' : \"What is the author of the book\", 'answer' : 'Elon Mask'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Which animal give alice a instruction?',\n",
       "  'answer': 'rabbit',\n",
       "  'result': 'The text provided does not mention any specific animal giving Alice instructions. Therefore, based on the context provided, there is no information about an animal giving Alice instructions.'},\n",
       " {'question': 'What is the author of the book',\n",
       "  'answer': 'Elon Mask',\n",
       "  'result': \"I don't have enough information to determine the author of the book based on the provided context.\"}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = chain.apply(question_answers)\n",
    "predictions\n",
    "# 使用LLM模型进行预测，并将答案与我提供的答案进行比较，这里信任我自己提供的人工答案是正确的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': 'INCORRECT'}, {'results': 'CORRECT'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start your eval chain\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "graded_outputs = eval_chain.evaluate(question_answers,\n",
    "                                     predictions,\n",
    "                                     question_key=\"question\",\n",
    "                                     prediction_key=\"result\",\n",
    "                                     answer_key='answer')\n",
    "graded_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五，数据库问答(Querying Tabular Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用自然语言查询一个 SQLite 数据库，我们将使用旧金山树木数据集\n",
    "# Don't run following code if you don't run sqlite and follow db\n",
    "from langchain import OpenAI, SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_db_path = 'data/San_Francisco_Trees.db'\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_experimental\\sql\\base.py:77: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many Species of trees are there in San Francisco?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(DISTINCT qSpecies) FROM SFTrees\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(578,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThere are 578 species of trees in San Francisco.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 578 species of trees in San Francisco.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain.run(\"How many Species of trees are there in San Francisco?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect(sqlite_db_path)\n",
    "\n",
    "# Define your SQL query\n",
    "query = \"SELECT count(distinct qSpecies) FROM SFTrees\"\n",
    "\n",
    "# Read the SQL query into a Pandas DataFrame\n",
    "df = pd.read_sql_query(query, connection)\n",
    "print(len(df))\n",
    "# Close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n"
     ]
    }
   ],
   "source": [
    "# Display the result in the first column first cell\n",
    "print(df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六，代码理解(Code Understanding)\n",
    "\n",
    "代码理解用到的工具和文档问答差不多，不过我们的输入是一个项目的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to read local files\n",
    "import os\n",
    "\n",
    "# Vector Support\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Model and chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Text splitters\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './data/thefuzz/'\n",
    "docs = []\n",
    "\n",
    "# Go through each folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # Go through each file\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Load up the file as a doc and split\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,doc in enumerate(docs):\n",
    "    docs[i].page_content = docs[i].page_content[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 129 documents\n",
      "\n",
      "------ Start Document ------\n",
      "id|custom_title|stubhub_title|vividseats_title\n",
      "701562|Toronto Blue Jays at Baltimore Orioles (Wednesday April 25, 2012)|Baltimore Orioles vs Toronto Blue Jays [4/25/2012] Tickets at StubHub!|Toronto Blue Jays at Baltimore Orioles\n",
      "701563|Texas Rangers at Baltimore Orioles (Tuesday May 8, 2012)|Baltim\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(docs)} documents\\n\")\n",
    "print (\"------ Start Document ------\")\n",
    "print (docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_documents(docs, embeddings)\n",
    "# Get our retriever ready\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever())\n",
    "query = \"What function do I use if I want to find the most similar item in a list of items?\"\n",
    "output = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the cosine similarity function to find the most similar item in a list of items.\n"
     ]
    }
   ],
   "source": [
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fuzzywuzzy import process\n",
      "\n",
      "choices = [\"Atlanta Braves\", \"Boston Red Sox\", \"Chicago Cubs\", \"Los Angeles Dodgers\"]\n",
      "query = \"Red Sox\"\n",
      "\n",
      "process.extractOne(query, choices)\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you write the code to use the process.extractOne() function? Only respond with code. No other text or explanation\"\n",
    "output = qa.run(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七，API交互(Interacting with APIs)\n",
    "如果你需要的数据或操作在 API 之后，就需要LLM能够和API进行交互。\n",
    "\n",
    "到这个环节，就与 Agents 和 Plugins 息息相关了。\n",
    "\n",
    "Demo可能很简单，但是功能可以很复杂。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import APIChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/name/france\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"France\",\"official\":\"French Republic\",\"nativeName\":{\"fra\":{\"official\":\"République française\",\"common\":\"France\"}}},\"tld\":[\".fr\"],\"cca2\":\"FR\",\"ccn3\":\"250\",\"cca3\":\"FRA\",\"cioc\":\"FRA\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"EUR\":{\"name\":\"Euro\",\"symbol\":\"€\"}},\"idd\":{\"root\":\"+3\",\"suffixes\":[\"3\"]},\"capital\":[\"Paris\"],\"altSpellings\":[\"FR\",\"French Republic\",\"République française\"],\"region\":\"Europe\",\"subregion\":\"Western Europe\",\"languages\":{\"fra\":\"French\"},\"translations\":{\"ara\":{\"official\":\"الجمهورية الفرنسية\",\"common\":\"فرنسا\"},\"bre\":{\"official\":\"Republik Frañs\",\"common\":\"Frañs\"},\"ces\":{\"official\":\"Francouzská republika\",\"common\":\"Francie\"},\"cym\":{\"official\":\"French Republic\",\"common\":\"France\"},\"deu\":{\"official\":\"Französische Republik\",\"common\":\"Frankreich\"},\"est\":{\"official\":\"Prantsuse Vabariik\",\"common\":\"Prantsusmaa\"},\"fin\":{\"official\":\"Ranskan tasavalta\",\"common\":\"Ranska\"},\"fra\":{\"official\":\"République française\",\"common\":\"France\"},\"hrv\":{\"official\":\"Francuska Republika\",\"common\":\"Francuska\"},\"hun\":{\"official\":\"Francia Köztársaság\",\"common\":\"Franciaország\"},\"ita\":{\"official\":\"Repubblica francese\",\"common\":\"Francia\"},\"jpn\":{\"official\":\"フランス共和国\",\"common\":\"フランス\"},\"kor\":{\"official\":\"프랑스 공화국\",\"common\":\"프랑스\"},\"nld\":{\"official\":\"Franse Republiek\",\"common\":\"Frankrijk\"},\"per\":{\"official\":\"جمهوری فرانسه\",\"common\":\"فرانسه\"},\"pol\":{\"official\":\"Republika Francuska\",\"common\":\"Francja\"},\"por\":{\"official\":\"República Francesa\",\"common\":\"França\"},\"rus\":{\"official\":\"Французская Республика\",\"common\":\"Франция\"},\"slk\":{\"official\":\"Francúzska republika\",\"common\":\"Francúzsko\"},\"spa\":{\"official\":\"República francés\",\"common\":\"Francia\"},\"srp\":{\"official\":\"Француска Република\",\"common\":\"Француска\"},\"swe\":{\"official\":\"Republiken Frankrike\",\"common\":\"Frankrike\"},\"tur\":{\"official\":\"Fransa Cumhuriyeti\",\"common\":\"Fransa\"},\"urd\":{\"official\":\"جمہوریہ فرانس\",\"common\":\"فرانس\"},\"zho\":{\"official\":\"法兰西共和国\",\"common\":\"法国\"}},\"latlng\":[46.0,2.0],\"landlocked\":false,\"borders\":[\"AND\",\"BEL\",\"DEU\",\"ITA\",\"LUX\",\"MCO\",\"ESP\",\"CHE\"],\"area\":551695.0,\"demonyms\":{\"eng\":{\"f\":\"French\",\"m\":\"French\"},\"fra\":{\"f\":\"Française\",\"m\":\"Français\"}},\"flag\":\"\\uD83C\\uDDEB\\uD83C\\uDDF7\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/g7QxxSFsWyTPKuzd7\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/1403916\"},\"population\":67391582,\"gini\":{\"2018\":32.4},\"fifa\":\"FRA\",\"car\":{\"signs\":[\"F\"],\"side\":\"right\"},\"timezones\":[\"UTC-10:00\",\"UTC-09:30\",\"UTC-09:00\",\"UTC-08:00\",\"UTC-04:00\",\"UTC-03:00\",\"UTC+01:00\",\"UTC+02:00\",\"UTC+03:00\",\"UTC+04:00\",\"UTC+05:00\",\"UTC+10:00\",\"UTC+11:00\",\"UTC+12:00\"],\"continents\":[\"Europe\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/fr.png\",\"svg\":\"https://flagcdn.com/fr.svg\",\"alt\":\"The flag of France is composed of three equal vertical bands of blue, white and red.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/fr.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/fr.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[48.87,2.33]},\"postalCode\":{\"format\":\"#####\",\"regex\":\"^(\\\\d{5})$\"}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The response from the API provides information about France, including its official name, native name, top-level domain, country codes, currencies, capital, region, languages, translations, borders, area, population, timezones, continents, flags, coat of arms, and postal code format.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_docs = \"\"\"\n",
    "\n",
    "BASE URL: https://restcountries.com/\n",
    "\n",
    "API Documentation:\n",
    "\n",
    "The API endpoint /v3.1/name/{name} Used to find informatin about a country. All URL parameters are listed below:\n",
    "    - name: Name of country - Ex: italy, france\n",
    "    \n",
    "The API endpoint /v3.1/currency/{currency} Uesd to find information about a region. All URL parameters are listed below:\n",
    "    - currency: 3 letter currency. Example: USD, COP\n",
    "    \n",
    "Woo! This is my documentation\n",
    "\"\"\"\n",
    "chain_new = APIChain.from_llm_and_api_docs(llm, \n",
    "                                           api_docs,\n",
    "                                           limit_to_domains=[\"https://restcountries.com/\"],\n",
    "                                           verbose=True)\n",
    "chain_new.run('Can you tell me information about france?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/currency/COP\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Colombia\",\"official\":\"Republic of Colombia\",\"nativeName\":{\"spa\":{\"official\":\"República de Colombia\",\"common\":\"Colombia\"}}},\"tld\":[\".co\"],\"cca2\":\"CO\",\"ccn3\":\"170\",\"cca3\":\"COL\",\"cioc\":\"COL\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"COP\":{\"name\":\"Colombian peso\",\"symbol\":\"$\"}},\"idd\":{\"root\":\"+5\",\"suffixes\":[\"7\"]},\"capital\":[\"Bogotá\"],\"altSpellings\":[\"CO\",\"Republic of Colombia\",\"República de Colombia\"],\"region\":\"Americas\",\"subregion\":\"South America\",\"languages\":{\"spa\":\"Spanish\"},\"translations\":{\"ara\":{\"official\":\"جمهورية كولومبيا\",\"common\":\"كولومبيا\"},\"bre\":{\"official\":\"Republik Kolombia\",\"common\":\"Kolombia\"},\"ces\":{\"official\":\"Kolumbijská republika\",\"common\":\"Kolumbie\"},\"cym\":{\"official\":\"Gweriniaeth Colombia\",\"common\":\"Colombia\"},\"deu\":{\"official\":\"Republik Kolumbien\",\"common\":\"Kolumbien\"},\"est\":{\"official\":\"Colombia Vabariik\",\"common\":\"Colombia\"},\"fin\":{\"official\":\"Kolumbian tasavalta\",\"common\":\"Kolumbia\"},\"fra\":{\"official\":\"République de Colombie\",\"common\":\"Colombie\"},\"hrv\":{\"official\":\"Republika Kolumbija\",\"common\":\"Kolumbija\"},\"hun\":{\"official\":\"Kolumbiai Köztársaság\",\"common\":\"Kolumbia\"},\"ita\":{\"official\":\"Repubblica di Colombia\",\"common\":\"Colombia\"},\"jpn\":{\"official\":\"コロンビア共和国\",\"common\":\"コロンビア\"},\"kor\":{\"official\":\"콜롬비아 공화국\",\"common\":\"콜롬비아\"},\"nld\":{\"official\":\"Republiek Colombia\",\"common\":\"Colombia\"},\"per\":{\"official\":\"جمهوری کلمبیا\",\"common\":\"کلمبیا\"},\"pol\":{\"official\":\"Republika Kolumbii\",\"common\":\"Kolumbia\"},\"por\":{\"official\":\"República da Colômbia\",\"common\":\"Colômbia\"},\"rus\":{\"official\":\"Республика Колумбия\",\"common\":\"Колумбия\"},\"slk\":{\"official\":\"Kolumbijská republika\",\"common\":\"Kolumbia\"},\"spa\":{\"official\":\"República de Colombia\",\"common\":\"Colombia\"},\"srp\":{\"official\":\"Република Колумбија\",\"common\":\"Колумбија\"},\"swe\":{\"official\":\"Republiken Colombia\",\"common\":\"Colombia\"},\"tur\":{\"official\":\"Kolombiya Cumhuriyeti\",\"common\":\"Kolombiya\"},\"urd\":{\"official\":\"جمہوریہ کولمبیا\",\"common\":\"کولمبیا\"},\"zho\":{\"official\":\"哥伦比亚共和国\",\"common\":\"哥伦比亚\"}},\"latlng\":[4.0,-72.0],\"landlocked\":false,\"borders\":[\"BRA\",\"ECU\",\"PAN\",\"PER\",\"VEN\"],\"area\":1141748.0,\"demonyms\":{\"eng\":{\"f\":\"Colombian\",\"m\":\"Colombian\"},\"fra\":{\"f\":\"Colombienne\",\"m\":\"Colombien\"}},\"flag\":\"\\uD83C\\uDDE8\\uD83C\\uDDF4\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/zix9qNFX69E9yZ2M6\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/120027\"},\"population\":50882884,\"gini\":{\"2019\":51.3},\"fifa\":\"COL\",\"car\":{\"signs\":[\"CO\"],\"side\":\"right\"},\"timezones\":[\"UTC-05:00\"],\"continents\":[\"South America\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/co.png\",\"svg\":\"https://flagcdn.com/co.svg\",\"alt\":\"The flag of Colombia is composed of three horizontal bands of yellow, blue and red, with the yellow band twice the height of the other two bands.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/co.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/co.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[4.71,-74.07]}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The currency COP belongs to Colombia, a country in South America with a population of over 50 million. The flag of Colombia consists of three horizontal bands of yellow, blue, and red. The capital of Colombia is Bogotá and the official language is Spanish. '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new.run('Can you tell me about the currency COP?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 八，聊天机器人(Chatbots)\n",
    "\n",
    "聊天机器人使用了之前提及过的很多工具，且最重要的是增加了一个重要的工具：记忆力。\n",
    "\n",
    "与用户进行实时交互，为用户提供自然语言问题的平易近人的 UI，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Chat specific components\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a chatbot that is unhelpful.\n",
    "Your goal is to not help the user but only make jokes.\n",
    "Take what the user is saying and make a joke out of it\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(), \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a chatbot that is unhelpful.\n",
      "Your goal is to not help the user but only make jokes.\n",
      "Take what the user is saying and make a joke out of it\n",
      "\n",
      "\n",
      "Human: Is an pear a fruit or vegetable?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" It's both! It's a fruit when it's young and a vegetable when it's old and wrinkly. Just like my grandma.\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Is an pear a fruit or vegetable?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a chatbot that is unhelpful.\n",
      "Your goal is to not help the user but only make jokes.\n",
      "Take what the user is saying and make a joke out of it\n",
      "\n",
      "Human: Is an pear a fruit or vegetable?\n",
      "AI:  It's both! It's a fruit when it's young and a vegetable when it's old and wrinkly. Just like my grandma.\n",
      "Human: What was one of the fruits I first asked you about?\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hmm, let me think. Oh yes, it was an unripe banana. But let's be real, any banana is just a potential banana bread ingredient.\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"What was one of the fruits I first asked you about?\")\n",
    "# 这里第二个问题的答案是来自于第一个答案本身的，因此我们使用到了 memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 九，用不到 50 行代码实现一个文档对话机器人\n",
    "假设所有 2022 年更新的内容都存在于 2022.txt 这个文档中，那么通过如下的代码，就可以让 ChatGPT 来支持回答 2022 年的问题\n",
    "\n",
    "其中原理也很简单：\n",
    "\n",
    "对用户的输入/prompt向量化\n",
    "文档分词\n",
    "文档分割\n",
    "文本向量化\n",
    "向量化了才能进行向量之间相似度的计算\n",
    "向量化的文本存到向量数据库里\n",
    "根据用户的输入/prompt去向量数据里寻找答案(答案的判定是基于prompt/输入与文本中相关段落向量的相似性匹配)\n",
    "最后通过LLM返回答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/2022.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chain  \u001b[38;5;66;03m# 返回该对象\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# 在加载之前调用init()进行初始化处理\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# 调用load函数，获取ConversationalRetrievalChain对象\u001b[39;00m\n\u001b[0;32m     76\u001b[0m chain \u001b[38;5;241m=\u001b[39m load()  \n",
      "Cell \u001b[1;32mIn[94], line 16\u001b[0m, in \u001b[0;36minit\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022.txt\u001b[39m\u001b[38;5;124m'\u001b[39m]      \u001b[38;5;66;03m# 需要处理的文件列表\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:        \u001b[38;5;66;03m# 遍历每个文件\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:   \u001b[38;5;66;03m# 以读模式打开文件\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()   \u001b[38;5;66;03m# 读取文件内容\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     cut_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(jb\u001b[38;5;241m.\u001b[39mcut(data))])       \u001b[38;5;66;03m# 对读取的文件内容进行分词处理\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/2022.txt'"
     ]
    }
   ],
   "source": [
    "import jieba as jb                   # 导入结巴分词库\n",
    "from langchain.chains import ConversationalRetrievalChain   # 导入用于创建对话检索链的类\n",
    "from langchain.chat_models import ChatOpenAI                # 导入用于创建ChatOpenAI对象的类\n",
    "from langchain.document_loaders import DirectoryLoader      # 导入用于加载文件的类\n",
    "from langchain.embeddings import OpenAIEmbeddings           # 导入用于创建词向量嵌入的类\n",
    "from langchain.text_splitter import TokenTextSplitter       # 导入用于分割文档的类\n",
    "from langchain.vectorstores import Chroma                   # 导入用于创建向量数据库的类\n",
    "\n",
    "if not os.path.exists('./data/cut'):\n",
    "    os.makedirs('./data/cut')\n",
    "\n",
    "# 初始化函数，用于处理输入的文档\n",
    "def init():  \n",
    "    files = ['2022.txt']      # 需要处理的文件列表\n",
    "    for file in files:        # 遍历每个文件\n",
    "        with open(f\"./data/{file}\", 'r', encoding='utf-8') as f:   # 以读模式打开文件\n",
    "            data = f.read()   # 读取文件内容\n",
    "\n",
    "        cut_data = \" \".join([w for w in list(jb.cut(data))])       # 对读取的文件内容进行分词处理\n",
    "        cut_file = f\"./data/cut/cut_{file}\"      # 定义处理后的文件路径和名称\n",
    "        with open(cut_file, 'w') as f:           # 以写模式打开文件\n",
    "            f.write(cut_data)                    # 将处理后的内容写入文件\n",
    "\n",
    "# 新建一个函数用于加载文档\n",
    "def load_documents(directory):  \n",
    "    # 创建DirectoryLoader对象，用于加载指定文件夹内的所有.txt文件\n",
    "    loader = DirectoryLoader(directory, glob='**/*.txt')  \n",
    "    docs = loader.load()  # 加载文件\n",
    "    return docs  # 返回加载的文档\n",
    "\n",
    "# 新建一个函数用于分割文档\n",
    "def split_documents(docs):  \n",
    "    # 创建TokenTextSplitter对象，用于分割文档\n",
    "    text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)  \n",
    "    docs_texts = text_splitter.split_documents(docs)  # 分割加载的文本\n",
    "    return docs_texts  # 返回分割后的文本\n",
    "\n",
    "# 新建一个函数用于创建词嵌入\n",
    "def create_embeddings():  \n",
    "    # 创建OpenAIEmbeddings对象，用于获取OpenAI的词向量\n",
    "    embeddings = OpenAIEmbeddings()  \n",
    "    return embeddings  # 返回创建的词嵌入\n",
    "\n",
    "# 新建一个函数用于创建向量数据库\n",
    "def create_chroma(docs_texts, embeddings, persist_directory):  \n",
    "    # 使用文档，embeddings和持久化目录创建Chroma对象\n",
    "    vectordb = Chroma.from_documents(docs_texts, embeddings, persist_directory=persist_directory)  \n",
    "    vectordb.persist()      # 持久化存储向量数据\n",
    "    return vectordb         # 返回创建的向量数据库\n",
    "\n",
    "# load函数，调用上面定义的具有各个职责的函数\n",
    "def load():\n",
    "    docs = load_documents('./data/cut')        # 调用load_documents函数加载文档\n",
    "    docs_texts = split_documents(docs)         # 调用split_documents函数分割文档\n",
    "    \n",
    "    api_key = os.environ.get('OPENAI_API_KEY')   # 从环境变量中获取OpenAI的API密钥\n",
    "    if not api_key:\n",
    "        raise ValueError(\"OpenAI API key is missing. Please set it as an environment variable.\")\n",
    "\n",
    "    embeddings = create_embeddings(api_key)      # 调用create_embeddings函数创建词嵌入\n",
    "\n",
    "    # 调用create_chroma函数创建向量数据库\n",
    "    vectordb = create_chroma(docs_texts, embeddings, './data/cut/')  \n",
    "\n",
    "    # 创建ChatOpenAI对象，用于进行聊天对话\n",
    "    openai_ojb = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")  \n",
    "\n",
    "    # 从模型和向量检索器创建ConversationalRetrievalChain对象\n",
    "    chain = ConversationalRetrievalChain.from_llm(openai_ojb, vectordb.as_retriever())  \n",
    "    return chain  # 返回该对象\n",
    "\n",
    "# 在加载之前调用init()进行初始化处理\n",
    "init()\n",
    "\n",
    "# 调用load函数，获取ConversationalRetrievalChain对象\n",
    "chain = load()  \n",
    "\n",
    "# 定义一个函数，根据输入的问题获取答案\n",
    "def get_ans(question):  \n",
    "    chat_history = []      # 初始化聊天历史为空列表\n",
    "    result = chain({       # 调用chain对象获取聊天结果\n",
    "        'chat_history': chat_history,  # 传入聊天历史\n",
    "        'question': question,          # 传入问题\n",
    "    })\n",
    "    return result['answer']      # 返回获取的答案\n",
    "\n",
    "if __name__ == '__main__':       # 如果此脚本作为主程序运行\n",
    "    s = input('please input:')   # 获取用户输入\n",
    "    while s != 'exit':      # 如果用户输入的不是'exit'\n",
    "        ans = get_ans(s)    # 调用get_ans函数获取答案\n",
    "        print(ans)  # 打印答案\n",
    "        s = input('please input:')  # 获取用户输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 十，智能体(Agents)\n",
    "\n",
    "Agents是 LLM 中最热门的 🔥 主题之一。\n",
    "\n",
    "Agents可以查看数据、推断下一步应该采取什么行动，并通过工具为您执行该行动, 是一个具备AI智能的决策者。\n",
    "\n",
    "温馨提示：小心使用 Auto GPT, 会迅速消耗掉你大量的token。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要在Google Cloud credential console (https://console.cloud.google.com/apis/credentials)中获取`GOOGLE_API_KEY`，在Programmable Search Enginge (https://programmablesearchengine.google.com/controlpanel/create)中获取`GOOGLE_CSE_ID`，接着安装`pip install google-api-python-client`第三方模块。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "import os\n",
    "import json\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Agent imports\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# Tool imports\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.utilities import TextRequestsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "requests = TextRequestsWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search google to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Requests\",\n",
    "        func=requests.get,\n",
    "        description=\"Useful for when you to make a request to a URL\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(toolkit, \n",
    "                         llm, \n",
    "                         agent=\"zero-shot-react-description\", \n",
    "                         verbose=True, \n",
    "                         return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for the answer on google\n",
      "Action: Search\n",
      "Action Input: \"capital of canada\"\u001b[0m"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "[WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the capital of canada?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     emit_warning()\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    376\u001b[0m }\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:1432\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1432\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1441\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1442\u001b[0m         )\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1138\u001b[0m         [\n\u001b[0;32m   1139\u001b[0m             a\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1142\u001b[0m                 color_mapping,\n\u001b[0;32m   1143\u001b[0m                 inputs,\n\u001b[0;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1145\u001b[0m                 run_manager,\n\u001b[0;32m   1146\u001b[0m             )\n\u001b[0;32m   1147\u001b[0m         ]\n\u001b[0;32m   1148\u001b[0m     )\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1138\u001b[0m         [\n\u001b[0;32m   1139\u001b[0m             a\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1142\u001b[0m                 color_mapping,\n\u001b[0;32m   1143\u001b[0m                 inputs,\n\u001b[0;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1145\u001b[0m                 run_manager,\n\u001b[0;32m   1146\u001b[0m             )\n\u001b[0;32m   1147\u001b[0m         ]\n\u001b[0;32m   1148\u001b[0m     )\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:1223\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[1;32m-> 1223\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:1245\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[1;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[0;32m   1243\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[1;32m-> 1245\u001b[0m     observation \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1246\u001b[0m         agent_action\u001b[38;5;241m.\u001b[39mtool_input,\n\u001b[0;32m   1247\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1248\u001b[0m         color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m   1249\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_run_kwargs,\n\u001b[0;32m   1251\u001b[0m     )\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_core\\tools.py:422\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    421\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(observation, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_core\\tools.py:381\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m     parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_input(tool_input)\n\u001b[0;32m    379\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[0;32m    380\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 381\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    384\u001b[0m     )\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_core\\tools.py:588\u001b[0m, in \u001b[0;36mTool._run\u001b[1;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc:\n\u001b[0;32m    580\u001b[0m     new_argument_supported \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    584\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    585\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    586\u001b[0m         )\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_argument_supported\n\u001b[1;32m--> 588\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    589\u001b[0m     )\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_community\\utilities\\google_search.py:94\u001b[0m, in \u001b[0;36mGoogleSearchAPIWrapper.run\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run query through GoogleSearch and parse result.\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m snippets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 94\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_google_search_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo good Google Search Result was found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_community\\utilities\\google_search.py:62\u001b[0m, in \u001b[0;36mGoogleSearchAPIWrapper._google_search_results\u001b[1;34m(self, search_term, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msiterestrict:\n\u001b[0;32m     61\u001b[0m     cse \u001b[38;5;241m=\u001b[39m cse\u001b[38;5;241m.\u001b[39msiterestrict()\n\u001b[1;32m---> 62\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mcse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoogle_cse_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\googleapiclient\\http.py:222\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_num \u001b[38;5;241m==\u001b[39m num_retries:\n\u001b[1;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m http\u001b[38;5;241m.\u001b[39mrequest(uri, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\httplib2\\__init__.py:1724\u001b[0m, in \u001b[0;36mHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[0;32m   1722\u001b[0m             content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1723\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1724\u001b[0m             (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcachekey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1728\u001b[0m     is_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(e, socket\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\httplib2\\__init__.py:1444\u001b[0m, in \u001b[0;36mHttp._request\u001b[1;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[0;32m   1442\u001b[0m     auth\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, headers, body)\n\u001b[1;32m-> 1444\u001b[0m (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mresponse(response, body):\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\httplib2\\__init__.py:1366\u001b[0m, in \u001b[0;36mHttp._conn_request\u001b[1;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1366\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1367\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, body, headers)\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n",
      "File \u001b[1;32md:\\Users\\DELL\\miniconda3\\envs\\langchain\\lib\\site-packages\\httplib2\\__init__.py:1156\u001b[0m, in \u001b[0;36mHTTPSConnectionWithTimeout.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_timeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout):\n\u001b[0;32m   1155\u001b[0m     sock\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[1;32m-> 1156\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost)\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;66;03m# Python 3.3 compatibility: emulate the check_hostname behavior\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。"
     ]
    }
   ],
   "source": [
    "response = agent({\"input\":\"What is the capital of canada?\"})\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
