{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "\n",
    "我们定义了两种归一化:`component` 和 `norm`。\n",
    "\n",
    "## 定义\n",
    "### component\n",
    "`component`归一化指的是每个分量值在1左右的张量。更准确地说，每个分量的二阶矩为1。\n",
    "\n",
    "$$\\left\\langle x_i^2\\right\\rangle=1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4033,  0.5957, -0.5576, -1.0190,  0.6011,  0.6808,  1.7108, -1.9956,\n",
       "         1.0042,  0.3201])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.randn(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norm\n",
    "`norm`归一化指的是范数接近1的张量\n",
    "\n",
    "$$\\|x\\| \\approx 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0219,  0.0773,  0.0598, -0.3819, -0.4355, -0.3116, -0.2310,  0.1102,\n",
       "        -0.2460, -0.0611])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(10) / 10**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "假设权重分布服从:\n",
    "\n",
    "$$\\begin{array}{r}\n",
    "\\left\\langle w_i\\right\\rangle=0 \\\\\n",
    "\\left\\langle w_i w_j\\right\\rangle=\\sigma^2 \\delta_{i j}\n",
    "\\end{array}$$\n",
    "\n",
    "这意味着$x \\cdot w$的前两个矩(因此均值和方差)只是$x$的第二个矩的函数\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\langle x \\cdot w\\rangle & =\\sum_i\\left\\langle x_i w_i\\right\\rangle=\\sum_i\\left\\langle x_i\\right\\rangle\\left\\langle w_i\\right\\rangle=0 \\\\\n",
    "\\left\\langle(x \\cdot w)^2\\right\\rangle & =\\sum_i \\sum_j\\left\\langle x_i w_i x_j w_j\\right\\rangle \\\\\n",
    "& =\\sum_i \\sum_j\\left\\langle x_i x_j\\right\\rangle\\left\\langle w_i w_j\\right\\rangle \\\\\n",
    "& =\\sigma^2 \\sum_i\\left\\langle x_i^2\\right\\rangle\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "您可以使用e3nn来检查函数或模块是否在初始化时被正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DYZ/dyz1/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/jit/_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "< x_i^2 > !~= 1.000000 for output irrep #0, 10x0e.Max componentwise error: 0.255908",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/DYZ/dyz1/learning/Open-Source-Framework/e3nn_tutorial/Normalization.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu/DYZ/dyz1/learning/Open-Source-Framework/e3nn_tutorial/Normalization.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39me3nn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtest\u001b[39;00m \u001b[39mimport\u001b[39;00m assert_normalized\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bubuntu/DYZ/dyz1/learning/Open-Source-Framework/e3nn_tutorial/Normalization.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39me3nn\u001b[39;00m \u001b[39mimport\u001b[39;00m o3\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bubuntu/DYZ/dyz1/learning/Open-Source-Framework/e3nn_tutorial/Normalization.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m assert_normalized(o3\u001b[39m.\u001b[39;49mLinear(\u001b[39m\"\u001b[39;49m\u001b[39m10x0e\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m10x0e\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.8/site-packages/e3nn/util/test.py:488\u001b[0m, in \u001b[0;36massert_normalized\u001b[0;34m(func, irreps_in, irreps_out, normalization, n_input, n_weight, weights, atol)\u001b[0m\n\u001b[1;32m    486\u001b[0m max_componentwise \u001b[39m=\u001b[39m (expected_square[ir_slice] \u001b[39m-\u001b[39m target)\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    487\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mTested normalization of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m: max componentwise error \u001b[39m\u001b[39m%.6f\u001b[39;00m\u001b[39m\"\u001b[39m, _logging_name(func), max_componentwise)\n\u001b[0;32m--> 488\u001b[0m \u001b[39massert\u001b[39;00m max_componentwise \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m atol, (\n\u001b[1;32m    489\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m< x_i^2 > !~= \u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m:\u001b[39;00m\u001b[39m.6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for output irrep #\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mirreps[i]\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMax componentwise error: \u001b[39m\u001b[39m{\u001b[39;00mmax_componentwise\u001b[39m:\u001b[39;00m\u001b[39m.6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: < x_i^2 > !~= 1.000000 for output irrep #0, 10x0e.Max componentwise error: 0.255908"
     ]
    }
   ],
   "source": [
    "from e3nn.util.test import assert_normalized\n",
    "from e3nn import o3\n",
    "assert_normalized(o3.Linear(\"10x0e\", \"10x0e\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbc91dbcb0051019ae97b751bde437ca7a1084c41c512133368dd180960dc485"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
